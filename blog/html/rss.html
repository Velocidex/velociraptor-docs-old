<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>Velociraptor</title>
        <link>https://docs.velociraptor.velocidex.com/blog/html/</link>
        <description>Hunting for evil - what Velociraptors do best!</description>
        <language>en-us</language>
        <pubDate>Sun, 10 Feb 2019 00:00:00 +1000</pubDate>
        
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2019/02/10/velociraptor_performance.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2019/02/10/velociraptor_performance.html</guid>
            <title><![CDATA[Velociraptor Performance]]></title>
            <description><![CDATA[<h1>Velociraptor Performance</h1>
<p>We are often asked how much resources does a Velociraptor deployment
use? How should one spec a machine for a Velociraptor deployment? We
have previously said that one of the reasons we developed Velociraptor
was to improve on the performance of GRR which was not scalable for
our use case.</p>
<p>We’ve been working with the team at Klein &amp; Co. on several intrusions
over the past several months, which are providing valuable
opportunities to deploy and test Velociraptor in a range of real world
investigation scenarios. Through this process, we’ve been able to
extend Velociraptor’s functionality and prove its performance on real
client networks.</p>
<p>I thought I would write a short blog post to show how Velociraptor
performed on such a recent engagement. In this engagement we deployed
Velociraptor on AWS and selectively pushed the client to around 600
machines running a mix of MacOS and Windows.</p>
<p>This post will hopefully give readers some idea of how scalable the
tool is and the typical workloads we run with it.</p>
<div id="more"> </div><div class="section" id="the-server">
<h2>The Server</h2>
<p>Since this is a smallish deployment we used a single VM with 32Gb of
RAM and 8 cores. This was definitely over speced for this job as most
of the time the server consumed less than 10% of one core:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">top - 06:26:13 up 29 days,  2:31,  5 users,  load average: 0.00, 0.01, 0.05</span>
<span class="go">Tasks: 214 total,   1 running, 213 sleeping,   0 stopped,   0 zombie</span>
<span class="gp">%</span>Cpu<span class="o">(</span>s<span class="o">)</span>:  <span class="m">0</span>.5 us,  <span class="m">0</span>.1 sy,  <span class="m">0</span>.0 ni, <span class="m">99</span>.4 id,  <span class="m">0</span>.0 wa,  <span class="m">0</span>.0 hi,  <span class="m">0</span>.0 si,  <span class="m">0</span>.0 st
<span class="go">KiB Mem:  32948060 total, 14877988 used, 18070072 free,   411192 buffers</span>
<span class="go">KiB Swap:        0 total,        0 used,        0 free. 13381224 cached Mem</span>

<span class="go">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span>
<span class="go">19334 root      20   0 1277924  94592  12616 S   3.0  0.3   9:11.03 ./velociraptor --config server.config.yaml frontend</span>
<span class="go">    8 root      20   0       0      0      0 S   0.3  0.0   7:16.30 [rcuos/0]</span>
</pre></div>
</div>
<p>You can see that the server consumed about 95mb when operating
normally and CPU usage was around 3% of one core.</p>
<p>For this engagement we knew that we would be collecting a lot of data
and so we specified a large 500gb volume.</p>
</div>
<div class="section" id="hunt-performance">
<h2>Hunt performance</h2>
<p>Velociraptor works by collecting “Artifacts” from clients. Artifacts
are simply encapsulated VQL queries which specify something to search
for on the endpoint. Without going into the details of this
engagement, we can say that we collected typical artifacts for a
DFIR/Forensic investigation engagement. In the following I want to
explore how well hunts performed for the following typical artifacts
in order of complexity:</p>
<ol class="arabic simple">
<li>Search the filesystem for a file glob.</li>
<li>Download the $MFT from the root filesystem.</li>
<li>Run a Yara scan over every file on all mounted filesystems.</li>
</ol>
<p>We ran these artifact collections over a large number of hosts
(between 400-500) that fell within the scope of our
engagement. Although the number of hosts is not huge, we hope to
demonstrate Velociraptor’s scalability.</p>
</div>
<div class="section" id="searching-for-a-file-glob">
<h2>Searching for a file glob</h2>
<p>One of the simplest and most common tasks in DFIR is to search the
filesystem for a glob based on filename. This requires traversing
directories and matching the filename based on the user specified
expression - for example, find all files with the extension <cite>*.exe</cite>
within the <cite>C:\Users</cite> directory.</p>
<p>Velociraptor can glob over the entire filesystem or over a limited set
of files. Typically a full filesystem glob can take some minutes on
the endpoint (it is equivalent to running the <cite>find</cite> unix command) and
touches every file. We typically try to limit the scope of the glob as
much as possible (e.g. only search system directories) but sometimes
it is nice to run a glob over all mounted filesystems to make sure we
don’t miss anything. In this case we opted for a full filesystem scan.</p>
<p>We searched the entire deployment using a hunt (The hunt is
constructed using the <cite>File Finder</cite> flow in the GUI) which just
launches the artifact collection. Therefore the horizontal distance
between the red and blue dot, in the graph below, represents the total
time taken by the host to collect the artifact.</p>
<img alt="../../../_images/FileNameSearch.svg" src="https://docs.velociraptor.velocidex.com/blog/html/_images/FileNameSearch.svg"/><p>The graph shows how many hosts were recruited into this hunt on the Y
axis. The X axis show the number of seconds since the hunt launch. The
red points indicate the time when clients started their collection,
while the blue dots indicate the time when the client completed the
artifact collection and the server saved its results.</p>
<p>The inset shows the same data but zoomed into the time origin.</p>
<p>Velociraptor improves and builds on the initial ideas implemented
within the GRR DFIR tool, and so it is interesting to compare this
graph to a typical graph produced by GRR’s hunt (reproduced from <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1742287613000285">this paper</a>).</p>
<img alt="../../../_images/grr_hunt.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/grr_hunt.png"/>
<p>The first noticeable difference is that Velociraptor clients complete
their collection much faster than GRR’s (the horizontal distance
between the red and blue dots represents the time between when the
collection is issued and the time it completes).</p>
<p>The main reason for this is that GRR’s communication protocol relies
on polling (by default every 10 minutes). Also, since hunting is so
resource intensive in GRR, the clients actually poll the hunt foreman
task every 30 minutes by default. This means that GRR clients
typically have to wait up to 30 minutes to run a hunt!</p>
<p>The second difference is the slope of the line around the start of the
hunt. GRR implements a hunt client rate - clients are recruited into
the hunt slowly (by default 20 per minute) in order to limit the load
on the frontends.  Unlike GRR, Velociraptor does not implement a hunt
rate since the Velociraptor frontend load is controlled by limiting
concurrency instead (more on this below).</p>
<p>This means that Velociraptor can deliver useful results within seconds
of the hunt starting. We see that this particular filename search
typically takes 25-30 seconds and we see about 200 clients completing
the hunt within this time consistently. The remaining clients are
probably not online and they receive the hunt as they join the
network. This makes Velociraptor hunts far more responsive and useful.</p>
<p>You might also notice a few outliers which spend a long time
collecting this artifact - these machines have probably been shutdown
or suspended while collecting this artifact.</p>
</div>
<div class="section" id="mft-download">
<h2>MFT Download</h2>
<p>A common technique is to examine the Master File Table (MFT) of an
NTFS volume. By forensically analyzing the MFT it is possible to
detect deleted files, time stomping and build a timeline of the system
using tools like
<a class="reference external" href="https://github.com/dkovar/analyzeMFT">analyseMFT.py</a> or
<a class="reference external" href="https://dmitrybrant.com/ntfswalker">ntfswalker</a> .</p>
<p>In this case we decided to collect the $MFT from all the Windows hosts
and post-process them offline. Typically the MFT is around 300-400mb
and could be larger. Therefore this artifact collection is about
performance downloading large quantities of data from multiple hosts
quickly.</p>
<p>Velociraptor can read the raw NTFS partition and therefore read the
<cite>$MFT</cite> file. We wrote the following artifact to just fetch the $MFT
file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Artifact.NTFS.MFT_puller</span>
<span class="l l-Scalar l-Scalar-Plain">description</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
   <span class="no">Uses an NTFS accessor to pull the $MFT</span>

<span class="l l-Scalar l-Scalar-Plain">parameters</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">path</span>
  <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">\\.\C:\$MFT</span>

<span class="l l-Scalar l-Scalar-Plain">sources</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">precondition</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">SELECT OS From info() where OS = 'windows'</span>
  <span class="l l-Scalar l-Scalar-Plain">queries</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">SELECT upload(file=path, accessor="ntfs") as Upload from scope()</span>
</pre></div>
</div>
<p>Here is the timing graph for this artifact collection:</p>
<img alt="../../../_images/MFTDownload.svg" src="https://docs.velociraptor.velocidex.com/blog/html/_images/MFTDownload.svg"/><p>This collection takes a lot longer on each host as clients are
uploading around 400mb each to the server, but our server was in the
cloud so it had fast bandwidth. Again we see the hosts that are
currently up being tasked within seconds, while as hosts come online
gradually we see them receiving the hunt and a few minutes later
uploading their $MFT file.</p>
<p>Was the frontend loaded at the time? I took a screenshot of <cite>top</cite> on
the server seconds after launching the hunt:</p>
<img alt="../../../_images/UploadingMFT.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/UploadingMFT.png"/>
<p>We can see that the CPU load is trivial (4.7%) but the major impact of
a heavy upload collection is the memory used (about 4.7gb - up from
about 100mb). The reason is that each client is posting a large buffer
of data (several mb) simultaneously. The server needs to buffer the
data before it can decrypt and process it which takes memory.</p>
<p>In order to limit the amount of memory used, Velociraptor limits the
total number of connections it is actively processing to 8-10
concurrent connections. By carefully managing concurrency we are able
to keep a limit on server memory use. We may lower the total memory
use by reducing the concurrency (and therefore maybe fit into a
smaller VM). Clients simply wait until the server is able to process
their uploaded buffers. If the server takes too long, the clients
automatically back off and retry to send the same buffer.</p>
</div>
<div class="section" id="yara-scan-over-the-entire-filesystem">
<h2>Yara scan over the entire filesystem</h2>
<p>The final example of a very intense artifact is to scan the entire
filesystem with a YARA rule. This not only requires traversing the
entire filesystem, but also opening each file and searching it.</p>
<p>One of the dangers with such a scan is that users will be negatively
impacted as their workstations start to read every file on disk! The
main resources a YARA scan consumes is disk IO and CPU load. Users
might complain and blame Velociraptor for their machine being slow
(disk IO may negatively affect performance much more than CPU load!).</p>
<p>However in this case, we don’t care how long we take to scan the
user’s system, as long as every file was scanned, and as long as the
endpoint is not overloaded and the user’s work is not
affected. Luckily Velociraptor allows us to specify the trade-off
between collection time and collection intensity.</p>
<div class="section" id="velociraptor-rate-limiting">
<h3>Velociraptor rate limiting</h3>
<p>Velociraptor controls client side load by rate limiting the client’s
VQL query. Each VQL plugin consumes an <cite>“operation”</cite> from the
throttler. We define an “operation” as a notional unit of work - the
heavier the VQL plugin’s work, the more operations are consumed. For
example for yara scanning, an operation is defined as 1mb of scanned
data, or a single file if the file is smaller.</p>
<p>When a user issues an artifact collection task, they may limit the
rate at which operations are performed by the client. The Velociraptor
agent then limits the operations to the specified rate. For example,
if the rate is 20 ops/sec then the client will scan less than 20mb per
seconds.</p>
<p>Other collections may run concurrently at different rates, though; The
client is not blocked while performing a single artifact
collection. This makes sense since we often need to collect a low
priority artifact slowly, but we do not want this to compromise rapid
response to that host.</p>
<p>For example, one of our targets was a server with large attached
storage. We ran the Yara scan over this system, scanning the first
100Mb of each file, at a rate of 50 ops/sec. In total we scanned 1.5Tb
of files and the scan took 14 hours (for a total scan rate of
30Mb/sec).</p>
<p>Velociraptor by default collects the <cite>Generic.Client.Stats</cite> artifact,
which samples the client’s CPU utilization and memory usage every 10
seconds. These samples are streamed to the server and form a record of
the client’s footprint on the endpoint. We can use this data to
visualize the effects of performing the yara scan on this host:</p>
<img alt="../../../_images/cpu_utilization.svg" src="https://docs.velociraptor.velocidex.com/blog/html/_images/cpu_utilization.svg"/><p>Above is the CPU usage on that particular server over the course of a
full day (24 hours). The 14 hour yara scan is clearly visible but at
no time is CPU utilization exceeding 30% of one core. With endpoint
disk IO limited to about 30mb/sec we have achieved a balance between
performance and endpoint load we are happy with.</p>
<img alt="../../../_images/YaraScanFull.svg" src="https://docs.velociraptor.velocidex.com/blog/html/_images/YaraScanFull.svg"/><p>We can see that most endpoints take approximately an hour to perform
this yara scan, but server load is minimal since the server simply
stores the results of the scans while doing minimal processing.</p>
</div>
</div>
<div class="section" id="conclusions">
<h2>Conclusions</h2>
<p>This post provides some typical numbers for Velociraptor performance
in typical DFIR engagements. We also covered some considerations and
trade-offs we must think about when issuing large artifact
collections. Readers can use these as a guideline in their own
deployments - please comment below about your
experiences. Velociraptor is under very active development and this
feedback is important to ensure we put in place the mechanisms to
account for more use cases.</p>
<div class="section" id="thanks">
<h3>Thanks</h3>
<p>We would like to thank the folk at <a class="reference external" href="https://www.kleinco.com.au/">Klein&amp;Con</a> for their wonderful
support and assistance in Velociraptor development.</p>
</div>
</div>
]]></description>
             <pubDate>Sun, 10 Feb 2019 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2019/02/09/velociraptor_python_api.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2019/02/09/velociraptor_python_api.html</guid>
            <title><![CDATA[Velociraptor Python API]]></title>
            <description><![CDATA[<h1>Velociraptor Python API</h1>
<p>Velociraptor is very good at collecting artifacts from
endpoints. However, in modern DFIR work, the actual collection is only
the first step of a much more involved process. Typically we want to
post process data using more advanced data mining tools (such as data
stacking). Velociraptor usually is only a part of a wider solution
which might include a SIEM and SOC integration.</p>
<p>In order to facilitate interoperability with other tools, Velociraptor
now offers an external API. The API is offered via gRPC so it can be
used in any language which gRPC supports (e.g. Java, C++, Python
etc). In this blog post we illustrate the Python API but any language
should work.</p>
<div id="more"> </div><div class="section" id="the-velociraptor-api-server">
<h2>The Velociraptor API Server</h2>
<p>The API server exposes an endpoint ready to accept gRPC
connections. By default the API server listen only on the loopback
interface (127.0.0.1) but it is easy to change to be externally
accessible if you need by changing the <cite>server.config.yaml</cite> file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">API</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">bind_address</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">127.0.0.1</span>
  <span class="l l-Scalar l-Scalar-Plain">bind_port</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">8001</span>
</pre></div>
</div>
<p>Client programs simply connect directly to this API and call gRPC
methods on it.</p>
<img alt="../../../_images/api_diagram.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/api_diagram.png"/>
<p>The connection is encrypted using TLS and authenticated using mutual
certificates. When we initially created the Velociraptor configuration
file, we created a CA certificate and embedded it in the
<cite>server.config.yaml</cite> file. It is this CA certificate which is used to
verify that the certificate each end presents was issued by the
Velociraptor CA.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you need to have extra security in your environment you
should keep the original <cite>server.config.yaml</cite> file generated
in an offline location, then deploy a redacted file (without
the CA.private_key value) on the server. This way api client
certificates can only be issued offline.</p>
</div>
<p>Before the client may connect to the API server they must have a
certificate issued by the Velociraptor CA. This is easy to generate:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor --config server.config.yaml <span class="se">\</span>
     config api_client --name Fred &gt; api_client.yaml
</pre></div>
</div>
<p>Will generate something like:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">ca_certificate</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
  <span class="no">-----BEGIN CERTIFICATE-----</span>
  <span class="no">MIIDITCCAgmgAwIBAgIRAI1oswXLBFqWVSYZx1VibMkwDQYJKoZIhvcNAQELBQAw</span>
  <span class="no">-----END CERTIFICATE-----</span>
<span class="l l-Scalar l-Scalar-Plain">client_cert</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
  <span class="no">-----BEGIN CERTIFICATE-----</span>
  <span class="no">2e1ftQuzHGD2XPquqfuVzL1rtEIA1tiC82L6smYbeOe0p4pqpsHN1sEDkdfhBA==</span>
  <span class="no">-----END CERTIFICATE-----</span>
<span class="l l-Scalar l-Scalar-Plain">client_private_key</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
  <span class="no">-----BEGIN RSA PRIVATE KEY-----</span>
  <span class="no">sVr9HvR2kBzM/3yVwvb752h0qDOYDfzLRENjA7dySeOgLtBSvd2gRg==</span>
  <span class="no">-----END RSA PRIVATE KEY-----</span>
<span class="l l-Scalar l-Scalar-Plain">api_connection_string</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">127.0.0.1:8001</span>
<span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Fred</span>
</pre></div>
</div>
<p>The certificate generated has a common name as specified by the
<cite>–name</cite> flag. This name will be logged in the server’s audit logs so
you can use this to keep track of which programs have access. This
file keeps both private key and certificate as well as the CA
certificate which must be used to authenticate the server in a single
file for convenience.</p>
</div>
<div class="section" id="using-the-api-from-python">
<h2>Using the API from Python</h2>
<p>Although the API exposes a bunch of functions used by the GUI, the
main function (which is not exposed through the GUI) is the <cite>Query()</cite>
method. This function simply executes one or more VQL queries, and
streams their results back to the caller.</p>
<p>The function requires an argument which is a protobuf of type
VQLCollectorArgs:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">VQLCollectorArgs</span><span class="p p-Indicator">:</span>
     <span class="l l-Scalar l-Scalar-Plain">env</span><span class="p p-Indicator">:</span>  <span class="l l-Scalar l-Scalar-Plain">list of VQLEnv(string key, string value)</span>
     <span class="l l-Scalar l-Scalar-Plain">Query</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">list of VQLRequest(string Name, string VQL)</span>
     <span class="l l-Scalar l-Scalar-Plain">max_row</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
     <span class="l l-Scalar l-Scalar-Plain">max_wait</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
     <span class="l l-Scalar l-Scalar-Plain">ops_per_second</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">float</span>
</pre></div>
</div>
<p>This very simple structure allows the caller to specify one or more
VQL queries to run. The call can set up environment variables prior to
the query execution. The max_row and max_wait parameters indicate how
many rows to return in a single result set and how long to wait for
additional rows before returning a result set.</p>
<p>The call simply executes the VQL queries and returns result sets as
VQLResponse protobufs:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">VQLResponse</span><span class="p p-Indicator">:</span>
   <span class="l l-Scalar l-Scalar-Plain">Response</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">json encoded string</span>
   <span class="l l-Scalar l-Scalar-Plain">Columns</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">list of string</span>
   <span class="l l-Scalar l-Scalar-Plain">total_rows</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">total number of rows in this packet</span>
</pre></div>
</div>
<p>The VQL query may return many responses - each represents a set of
rows. These responses may be returned over a long time, the API call
will simply wait until new responses are available. For example, the
VQL may represent an event query - i.e. watch for the occurrence of
some event in the system - in this case it will never actually
terminate, but keep streaming response packets.</p>
</div>
<div class="section" id="how-does-this-look-like-in-code">
<h2>How does this look like in code?</h2>
<p>The following will cover an example implementation in python. The
first step is to prepare credentials for making the gRPC call. We
parse the api_config yaml file and prepare a credential object:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">"api_client.yaml"</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
<span class="n">creds</span> <span class="o">=</span> <span class="n">grpc</span><span class="o">.</span><span class="n">ssl_channel_credentials</span><span class="p">(</span>
     <span class="n">root_certificates</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"ca_certificate"</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"utf8"</span><span class="p">),</span>
     <span class="n">private_key</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"client_private_key"</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"utf8"</span><span class="p">),</span>
     <span class="n">certificate_chain</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"client_cert"</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"utf8"</span><span class="p">))</span>

<span class="n">options</span> <span class="o">=</span> <span class="p">((</span><span class="s1">'grpc.ssl_target_name_override'</span><span class="p">,</span> <span class="s2">"VelociraptorServer"</span><span class="p">,),)</span>
</pre></div>
</div>
<p>Next we connect the channel to the API server:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="k">with</span> <span class="n">grpc</span><span class="o">.</span><span class="n">secure_channel</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"api_connection_string"</span><span class="p">],</span>
                         <span class="n">creds</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span> <span class="k">as</span> <span class="n">channel</span><span class="p">:</span>
    <span class="n">stub</span> <span class="o">=</span> <span class="n">api_pb2_grpc</span><span class="o">.</span><span class="n">APIStub</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
</pre></div>
</div>
<p>The stub is the object we use to make calls with. We can then issue
our call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">request</span> <span class="o">=</span> <span class="n">api_pb2</span><span class="o">.</span><span class="n">VQLCollectorArgs</span><span class="p">(</span>
         <span class="n">Query</span><span class="o">=</span><span class="p">[</span><span class="n">api_pb2</span><span class="o">.</span><span class="n">VQLRequest</span><span class="p">(</span>
             <span class="n">VQL</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
         <span class="p">)])</span>

<span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">stub</span><span class="o">.</span><span class="n">Query</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">Response</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
</pre></div>
</div>
<p>We issue the query and then just wait for the call to generate
response packets. Each packet may contain several rows which will all
be encoded as JSON in the Response field. Each row is simply a dict
with keys being the column names, and the values being possibly nested
dicts or simple data depending on the query.</p>
</div>
<div class="section" id="what-can-we-do-with-this">
<h2>What can we do with this?</h2>
<p>The Velociraptor API is deliberately open ended - meaning we do not
pose any limitations on what can be done with it. It is conceptually a
very simple API - just issue the query and look at the results,
however this makes it extremely powerful.</p>
<p>We already have a number of very useful server side VQL plugins you
can use. We also plan to add a number of other plugins in future -
this means that the Velociraptor API can easily be extended in a
backwards compatible way by simply adding new VQL plugins. New queries
can do more, without breaking existing queries.</p>
<div class="section" id="post-process-artifacts">
<h3>Post process artifacts</h3>
<p>This is the most common use case for the API. Velociraptor
deliberately does not do any post processing on the server - we don’t
want to slow the server down by making it do more work than necessary.</p>
<p>But sometimes users need to do some more with the results - for
example upload to an external system, check hashes against Virus
Total, and even initiate an active response like escalation or
disruption when something is detected.</p>
<p>In a recent engagement we needed to collect a large number of $MFT
files from many endpoints. We wanted to analyze these using external
tools like <cite>analyseMFT.py</cite>.</p>
<p>We wrote a simple artifact to collect the MFT:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Windows.Upload.MFT</span>
<span class="l l-Scalar l-Scalar-Plain">description</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
   <span class="no">Uses an NTFS accessor to pull the $MFT</span>

<span class="l l-Scalar l-Scalar-Plain">parameters</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">path</span>
    <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">\\.\C:\$MFT</span>

<span class="l l-Scalar l-Scalar-Plain">sources</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">precondition</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">SELECT OS From info() where OS = 'windows'</span>

    <span class="l l-Scalar l-Scalar-Plain">queries</span><span class="p p-Indicator">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">select upload(file=path, accessor="ntfs") as Upload from scope()</span>
</pre></div>
</div>
<p>We then created a hunt to collect this artifact from the machines of
interest. Once each $MFT file is uploaded we need to run
<cite>analyseMFT.py</cite> to parse it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">QUERY</span><span class="o">=</span><span class="s2">"""</span>
<span class="s2">  SELECT Flow,</span>
<span class="s2">         file_store(path=Flow.FlowContext.uploaded_files) as Files</span>
<span class="s2">  FROM  watch_monitoring(artifact='System.Flow.Completion')</span>
<span class="s2">  WHERE 'Windows.Upload.MFT' in Flow.FlowContext.artifacts</span>
<span class="s2">"""</span>

<span class="k">with</span> <span class="n">grpc</span><span class="o">.</span><span class="n">secure_channel</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"api_connection_string"</span><span class="p">],</span>
                         <span class="n">creds</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span> <span class="k">as</span> <span class="n">channel</span><span class="p">:</span>
    <span class="n">stub</span> <span class="o">=</span> <span class="n">api_pb2_grpc</span><span class="o">.</span><span class="n">APIStub</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
    <span class="n">request</span> <span class="o">=</span> <span class="n">api_pb2</span><span class="o">.</span><span class="n">VQLCollectorArgs</span><span class="p">(</span>
        <span class="n">Query</span><span class="o">=</span><span class="p">[</span><span class="n">api_pb2</span><span class="o">.</span><span class="n">VQLRequest</span><span class="p">(</span>
            <span class="n">VQL</span><span class="o">=</span><span class="n">QUERY</span><span class="p">,</span>
        <span class="p">)])</span>

    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">stub</span><span class="o">.</span><span class="n">Query</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">Response</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s2">"Files"</span><span class="p">]:</span>
                 <span class="n">subprocess</span><span class="o">.</span><span class="n">check_call</span><span class="p">(</span>
                    <span class="p">[</span><span class="s2">"analyseMFT.py"</span><span class="p">,</span> <span class="s2">"-f"</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span>
                     <span class="s2">"-o"</span><span class="p">,</span> <span class="n">file_name</span><span class="o">+</span><span class="s2">".analyzed"</span><span class="p">])</span>
</pre></div>
</div>
<p>The previous code sets up a watcher query which will receive every
completed flow on the server which collected the artifact
“Windows.Upload.MFT” (i.e. each completed flow will appear as a row to
the query).</p>
<p>We can have this program running in the background. We can then launch
a hunt collecting the artifact, and the program will automatically
process all the results from the hunt as soon as they occur. When new
machines are turned on they will receive the hunt, have their $MFT
collected and this program will immediately process that.</p>
<p>Each flow contains a list of files that were uploaded to it. The
<cite>file_store()</cite> VQL function reveals the server’s filesystem path where
the files actually reside. The server simply stores the uploaded files
on its filesystem since Velociraptor does not use a database
(everything is a file!).</p>
<p>The python code then proceeds to launch the <cite>analyseMFT.py</cite> script to
parse the <cite>$MFT</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The nice thing with this scheme is that the <cite>analyseMFT.py</cite> is
running in its own process and can be managed separately to the
main Velociraptor server (e.g. we can set its execution priority or
even run it on a separate machine). The Velociraptor server does
not actually need to wait for post processing nor will the post
processing affect its performance in any way. If the
<cite>analyseMFT.py</cite> script takes a long time, it will just fall behind
but it eventually will catch up. In the meantime, the Velociraptor
server will continue receiving the uploads regardless.</p>
</div>
<p>The above example sets up a watcher query to receive flow results in
real time, but you can also just process the results of a specific
hunt completely using a query like:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">Flow</span><span class="p">,</span> <span class="n">file_store</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">Flow</span><span class="p">.</span><span class="n">FlowContext</span><span class="p">.</span><span class="n">uploaded_files</span><span class="p">)</span> <span class="k">as</span> <span class="n">Files</span>
<span class="k">FROM</span> <span class="n">hunt_flows</span><span class="p">(</span><span class="n">hunt_id</span><span class="o">=</span><span class="n">huntId</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="conclusions">
<h2>Conclusions</h2>
<p>The Velociraptor python API opens up enormous possibilities for
automating Velociraptor and interfacing it with other
systems. Combining the power of VQL and the flexibility (and user
familiarity) of Python allows users to build upon Velociraptor in a
flexible and creative way. I am very excited to see what the community
will do with this feature - I can see integration with ELK, BigQuery
and other data analytic engines being a valuable use case.</p>
<p>Please share your experiences in the comments or on the mailing list
at <a class="reference external" href="mailto:velociraptor-discuss%40groups.google.com">velociraptor-discuss<span>@</span>groups<span>.</span>google<span>.</span>com</a>.</p>
</div>
]]></description>
             <pubDate>Sat, 09 Feb 2019 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/12/23/deploying_velociraptor_with_oauth_sso.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/12/23/deploying_velociraptor_with_oauth_sso.html</guid>
            <title><![CDATA[Deploying Velociraptor with OAuth SSO]]></title>
            <description><![CDATA[<h1>Deploying Velociraptor with OAuth SSO</h1>
<p>In the previous post we saw how to set up Velociraptor’s GUI over
SSL. This is great, but we still need to create users and assign them
passwords manually. The trouble with user account management is that
we can not enforce 2 factor authentication, or any password policies
or any of the usual enterprise requirements for user account
management. It is also difficult for users to remember yet another
password for a separate system, and so might make the password easily
guessable.</p>
<p>Most enterprise systems require an SSO mechanism to manage user
accounts and passwords. Manual user account management simply does not
scale!</p>
<p>In this post we discuss how to enable Google’s SSO authentication for
Velociraptor identity management.</p>
<div id="more"> </div><div class="section" id="oauth-identity-management">
<h2>OAuth Identity management</h2>
<p>Velociraptor can use Google’s oauth mechanism to verify a user’s
identity. This requires a user to authenticate to Google via their
usual mechanism - if their account requires 2 factor authentication,
then users need to log in this way.</p>
<p>Once the user authenticates to Google, they are redirected back into
the Velociraptor application with a token that allows the application
to request information about the user (for example, the username or
email address).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">OAuth is an authentication protocol. This means Velociraptor
can be pretty confident the user is who they claim they
are. This does not automatically grant them access to the
application! A Velociraptor administrator must still
manually grant them access before a user may log in.</p>
</div>
<p>Before we can use Google for Authentication, we need to register our
Velociraptor deployment as an OAuth App with Google. Unfortunately
Google is not known for having intuitive and easy to follow processes
so actually doing this is complicated and bounces through many
seemingly unrelated Google products and services. This post attempts
to document this process at it exists in this time.</p>
<p>For our example we assume that our server is located at
<a class="reference external" href="https://velociraptor.rekall-innovations.com">https://velociraptor.rekall-innovations.com</a> as we continue on from our
example in the last post (i.e. it is already configured to use SSL).</p>
</div>
<div class="section" id="registering-velociraptor-as-an-oauth-application">
<h2>Registering Velociraptor as an OAuth application</h2>
<p>The first step is to register Velociraptor as an OAuth app. We do this
by accessing the Google cloud console at
<a class="reference external" href="https://console.cloud.google.com">https://console.cloud.google.com</a> . You will need to set up a cloud
account first and create a cloud project. Although in this example we
do not necessarily need to host our application on Google cloud or
have anything to do with Google cloud, OAuth seems to exist within the
Google cloud product.</p>
<p>Our ultimate goal is to obtain OAuth credentials to give our
Velociraptor app, but we have to have a few things set up first. The
cloud console is fairly confusing so I usually use the search feature
to find exactly what I need. Searching for “oauth” at the search bar
indicates that it is under “APIs and Services”.</p>
<p>We need to set up the OAuth consent screen first - in which we give
our application a name to be presented to the user by the OAuth flow:</p>
<img alt="../../../_images/12.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/12.png"/>
<p>Further down we need to provide an authorized domain</p>
<img alt="../../../_images/22.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/22.png"/>
<p>In order to add an Authorized domain we need to <em>verify it</em>. Google’s
help pages explain it further:</p>
<div class="admonition-authorized-domains admonition">
<p class="first admonition-title">Authorized domains</p>
<p class="last">To protect you and your users, Google restricts your OAuth 2.0
application to using Authorized Domains. If you have verified the
domain with Google, you can use any Top Private Domain as an
Authorized Domain.</p>
</div>
<p>And this links to <a class="reference external" href="https://www.google.com/webmasters/tools/home">https://www.google.com/webmasters/tools/home</a> which
again seems completely unrelated to OAuth, Velociraptor or even a web
app (the web masters product is supposed to help sites increase their
search presence).</p>
<p>Within this product we now need to “Add a property”:</p>
<img alt="../../../_images/31.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/31.png"/>
<p>Hidden within the settings menu there is an option “Verification
Details” which allows you to verify that you own the domain. If you
purchased your domain from Google Domains then it should already be
verified - otherwise you can set some TXT records to prove you own the
domain.</p>
<img alt="../../../_images/4.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/4.png"/>
<p>After all this we can go back to the cloud console and Create
Credentials/OAuth client ID:</p>
<img alt="../../../_images/5.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/5.png"/>
<p>Now select “Web App” and we must set the “Authorized redirect URIs” to
<a class="reference external" href="https://velociraptor.rekall-innovations.com/auth/google/callback">https://velociraptor.rekall-innovations.com/auth/google/callback</a> -
This is the URL that successful OAuth authentication will direct
to. Velociraptor accepts this redirect and uses it to log the user on.</p>
<img alt="../../../_images/6.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/6.png"/>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The UI is a bit confusing here - you must press enter after
typing the redirect URL to have it registered <strong>before</strong> you
hit <em>Create</em> otherwise it misses that you typed it
completely. I spent some time stumped on this UI bug.</p>
</div>
<p>If all goes well the Google cloud console will give us a client ID and
a client secret. We can then copy those into the Velociraptor
configuration file under the GUI section:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">GUI</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">google_oauth_client_id</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1234xxxxxx.apps.googleusercontent.com</span>
  <span class="l l-Scalar l-Scalar-Plain">google_oauth_client_secret</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">qsadlkjhdaslkjasd</span>
  <span class="l l-Scalar l-Scalar-Plain">public_url</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">https://velociraptor.rekall-innovations.com/</span>

<span class="l l-Scalar l-Scalar-Plain">logging</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">output_directory</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/var/log/velociraptor/</span>
  <span class="l l-Scalar l-Scalar-Plain">separate_logs_per_component</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p>In the above config we also enabled logging (which is important for a
secure application!). The <cite>separate_logs_per_component</cite> option will
create a separate log file for the GUI, Frontend as well as important
Audit related events.</p>
<p>Now we can start the Velociraptor frontend:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor --config server.config.yaml frontend
</pre></div>
</div>
<p>Connecting using the browser goes through the familiar OAuth flow and
arrives at this Velociraptor screen:</p>
<img alt="../../../_images/7.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/7.png"/>
<p>The OAuth flow ensures the user’s identity is correct but does not
give them permission to log into Velociraptor. Note that having an
OAuth enabled application on the web allows anyone with a Google
identity to authenticate to the application but the user is still
required to be authorized. We can see the following in the Audit logs:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span/><span class="p">{</span>
  <span class="nt">"level"</span><span class="p">:</span> <span class="s2">"error"</span><span class="p">,</span>
  <span class="nt">"method"</span><span class="p">:</span> <span class="s2">"GET"</span><span class="p">,</span>
  <span class="nt">"msg"</span><span class="p">:</span> <span class="s2">"User rejected by GUI"</span><span class="p">,</span>
  <span class="nt">"remote"</span><span class="p">:</span> <span class="s2">"192.168.0.10:40570"</span><span class="p">,</span>
  <span class="nt">"time"</span><span class="p">:</span> <span class="s2">"2018-12-21T18:17:47+10:00"</span><span class="p">,</span>
  <span class="nt">"user"</span><span class="p">:</span> <span class="s2">"mike@velocidex.com"</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In order to authorize the user we must explicitly add them using the
velociraptor admin tool:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor --config ~/server.config.yaml user add mike@velocidex.com
Authentication will occur via Google - therefore no password needs to be set.
</pre></div>
</div>
<p>Note that this time, Velociraptor does not ask for a password at all,
since authentication occurs using Google’s SSO. If we hit refresh in
the browser we can now see the Velociraptor application:</p>
<img alt="../../../_images/8.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/8.png"/>
<p>We can see that the logged in user is authenticated by Google, and we
can also see their Google avatar at the top right for some more eye
candy :-).</p>
<div class="admonition-thanks admonition">
<p class="first admonition-title">Thanks</p>
<p class="last">Shouts to the folks from <a class="reference external" href="https://www.kleinco.com.au/">Klein &amp; Co</a> who sponsored this exciting
feature!.</p>
</div>
</div>
]]></description>
             <pubDate>Sun, 23 Dec 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/12/22/configuring_velociraptor_for_ssl.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/12/22/configuring_velociraptor_for_ssl.html</guid>
            <title><![CDATA[Configuring Velociraptor for SSL]]></title>
            <description><![CDATA[<h1>Configuring Velociraptor for SSL</h1>
<p>We have previously seen how to deploy a new Velociraptor server. For a
simple deployment we can have Velociraptor server and clients
provisioned in minutes.</p>
<p>Usually we deploy a specific Velociraptor deployment on our DFIR
engagements. We use cloud resources to provision the server and have
the clients connect to this cloud VM. A proper secure deployment of
Velociraptor will use SSL for securing both client communication and
protecting the web GUI.</p>
<p>In the past provisioning an SSL enabled web application was complex
and expensive - you had to create certificate signing requests,
interact with a CA. Pay for the certificates, then configure the
server. In particular you had to remember to renew the cert in 2 years
or your website suddenly broke!</p>
<p>Those days are over with the emergence of Lets Encrypt! and
autocert. These days applications can automatically provision their
own certificates. Velociraptor can manage its own certificates, fully
automatically - and then renew its certificates when the time comes
with no user intervention required.</p>
<p>In this blog post we will see how to configure a new Velociraptor
server in a cloud VM.</p>
<div id="more"> </div><div class="section" id="setting-up-a-domain">
<h2>Setting up a domain</h2>
<p>The first step in deploying an SSL enabled web application is to have
a domain name. SSL verifies the authenticity of a web site by its DNS
name.</p>
<p>We go over to Google Domains and buy a domain. In this post I will be
using the domain <cite>rekall-innovations.com</cite>.</p>
</div>
<div class="section" id="provisioning-a-virtual-machine">
<h2>Provisioning a Virtual Machine</h2>
<p>Next we provision an Ubuntu VM from any cloud provider. Depending on
your deployment size your VM should be large enough. An 8 or 16Gb VM
should be sufficient for around 5-10k clients. Additionally we will
need sufficient disk space to hold the data we will collect. We
recommend to start with a modest amount of storage and then either
backup data as it gets collected or increase the storage volume as
needed.</p>
<p>Our virtual machine will receive connections over ports 80
and 443.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When using SSL both the client communication <em>and</em> the GUI
are served over the same ports to benefit from SSL transport
encryption.</p>
</div>
<p>When we deploy our Virtual Machine we may choose either a static IP
address or allow the cloud provider to assign a dynamic IP address. We
typically choose a dynamic IP address and so we need to configure
Dynamic DNS.</p>
<p>Go to the Google Domains dashboard and create a new dynamic DNS for
your domain. In our example we will use
<cite>velociraptor.rekall-innovations.com</cite> as our endpoint address.</p>
<img alt="../../../_images/11.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/11.png"/>
<p>After the dynamic address is created, we can get the credentials for
updating the IP address.</p>
<img alt="../../../_images/21.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/21.png"/>
<p>Next we install ddclient on our VM. This will update our dynamic IP
address whenever the external interface changes. Configure the file
<cite>/etc/ddclient.conf</cite>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span/>protocol=dyndns2
use=web
server=domains.google.com
ssl=yes
login=X13342342XYZ
password='slk43521kj'
velociraptor.rekall-innovations.com
</pre></div>
</div>
<p>Next configure the service to start:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span/># Configuration for ddclient scripts
# generated from debconf on Tue Oct 23 20:25:23 AEST 2018
#
# /etc/default/ddclient

# Set to "true" if ddclient should be run every time DHCP client ('dhclient'
# from package isc-dhcp-client) updates the systems IP address.
run_dhclient="false"

# Set to "true" if ddclient should be run every time a new ppp connection is
# established. This might be useful, if you are using dial-on-demand.
run_ipup="false"

# Set to "true" if ddclient should run in daemon mode
# If this is changed to true, run_ipup and run_dhclient must be set to false.
run_daemon="true"

# Set the time interval between the updates of the dynamic DNS name in seconds.
# This option only takes effect if the ddclient runs in daemon mode.
daemon_interval="300"
</pre></div>
</div>
<p>Run dhclient and check that it updates the address correctly.</p>
</div>
<div class="section" id="id1">
<h2>Configuring Velociraptor for SSL</h2>
<p>Now comes the hard part! We need to configure Velociraptor to use
SSL. Edit the following in your <cite>server.config.yaml</cite> file (if you do
not have one yet you can generate one using <cite>velociraptor config
generate &gt; server.config.yaml</cite> ):</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">Client</span><span class="p p-Indicator">:</span>
   <span class="l l-Scalar l-Scalar-Plain">server_urls</span><span class="p p-Indicator">:</span>
   <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">https://velociraptor.rekall-innovations.com/</span>

<span class="l l-Scalar l-Scalar-Plain">autocert_domain</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">velociraptor.rekall-innovations.com</span>
<span class="l l-Scalar l-Scalar-Plain">autocert_cert_cache</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/velociraptor_cache/</span>
</pre></div>
</div>
<p>The <cite>autocert_domain</cite> parameter tells Velociraptor to provision its
own cert for this domain automatically. The certificates will be
stored in the directory specified by <cite>autocert_cert_cache</cite>.  You don’t
have to worry about rotating the certs, Velociraptor will
automatically renew them.</p>
<p>Obviously now the clients need to connect to the control channel over
SSL so we also need to direct the client’s <cite>server_urls</cite> parameter to
the SSL port.</p>
<p>Lets start the frontend (We need to start Velociraptor as root because
it must be able to bind to port 80 and 443):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ sudo velociraptor --config server.config.yaml frontend -v

<span class="o">[</span>INFO<span class="o">]</span> <span class="m">2018</span>-12-22T17:12:42+10:00 Loaded <span class="m">43</span> built in artifacts
<span class="o">[</span>INFO<span class="o">]</span> <span class="m">2018</span>-12-22T17:12:42+10:00 Increased open file limit to <span class="m">999999</span>
<span class="o">[</span>INFO<span class="o">]</span> <span class="m">2018</span>-12-22T17:12:42+10:00 Launched gRPC API server on <span class="m">127</span>.0.0.1:8888
<span class="o">[</span>INFO<span class="o">]</span> <span class="m">2018</span>-12-22T17:12:42+10:00 Autocert specified - will listen on ports <span class="m">443</span> and <span class="m">80</span>. I will ignore specified GUI port at <span class="m">8889</span>
<span class="o">[</span>INFO<span class="o">]</span> <span class="m">2018</span>-12-22T17:12:42+10:00 Autocert specified - will listen on ports <span class="m">443</span> and <span class="m">80</span>. I will ignore specified Frontend port at <span class="m">8889</span>
<span class="o">[</span>INFO<span class="o">]</span> <span class="m">2018</span>-12-22T17:12:42+10:00 Frontend is ready to handle client requests using HTTPS
</pre></div>
</div>
<p>If all goes well we now can point our browser to
<cite>https://velociraptor.rekall-innovations.com/</cite> and it should just
work. Don’t forget to provision a user and password using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor --config server.config.yaml user add mic
</pre></div>
</div>
</div>
<div class="section" id="notes">
<h2>Notes</h2>
<p>The autocert configuration is very easy to do but there are a few caveats:</p>
<ol class="arabic simple">
<li>Both ports 80 and 443 must be accessible over the web. This is
needed because Letsencrypt’s servers need to connect to our domain
name in order to verify our domain ownership.</li>
<li>It is not possible to change the ports from port 80 and 443 due to
limitations in Letsencrypt’s ACME protocol. This is why we can not
have more than one Velociraptor deployment on the same IP
currently.</li>
</ol>
<p>We have seen how easy it is to deploy secure Velociraptor servers. In
the next post we will discuss how to enhance security further by
deploying two factor authentication with Google’s Single Sign On (SSO).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This feature will be available in the upcoming 0.27
release. You can try it now by building from git head.</p>
</div>
</div>
]]></description>
             <pubDate>Sat, 22 Dec 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/12/11/velociraptor_interactive_shell.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/12/11/velociraptor_interactive_shell.html</guid>
            <title><![CDATA[Velociraptor Interactive Shell]]></title>
            <description><![CDATA[<h1>Velociraptor Interactive Shell</h1>
<p>One of the interesting new features in the latest release of
Velociraptor is an interactive shell. One can interact with the end
point over the standard Velociraptor communication mechanism - an
encrypted and authenticated channel.</p>
<p>This feature is implemented by utilizing the Velociraptor event
monitoring, server side VQL queries. This post explores how these
components come together to deliver a responsive, interactive
workflow.</p>
<div id="more"> </div><div class="section" id="endpoint-shell-access">
<h2>Endpoint shell access</h2>
<p>Although we generally try to avoid it, sometimes the easiest way to
extract certain information is to run a command and parse its
output. For example, consider the windows <cite>ipconfig</cite> command. It is
possible to extract this information using win32 apis but this
requires additional code to be written in the client. The <cite>ipconfig</cite>
command is guaranteed to be available. Soemtimes running a command and
parsing its output is the easiest option.</p>
<p>The GRR client has a client action which can run a command. However
that client action is restricted to run a whitelist of commands, since
GRR chose to prevent the running of arbitrary commands on the
endpoint. In practice, though it is difficult to add new commands to
the whitelist (and rebuild and deploy new clients that have the
updated whitelist). But users need to run arbitrary commands
(including their own third party tools) anyway. So in the GRR world,
most people use “python hacks” routinely to run arbitrary commands.</p>
<p>When we came to redesign Velociraptor we pondered if arbitrary command
execution should be included or not. To be sure, this is a dangerous
capability - effectively giving Velociraptor root level access on the
endpoint. In our experience restricting it in an arbitrary way (as was
done in GRR) is not useful because it is harder adapt to real incident
response needs (you hardly ever know in advance what is needed at 2am
in the morning when trying to triage an incident!).</p>
<p>Other endpoint monitoring tools also have a shell interface (For
example Carbon Black). It is understood that this feature is extremely
powerful, but it is necessary sometimes.</p>
<p>Velociraptor mitigates this risk in a few ways:</p>
<ol class="arabic simple">
<li>If an organization deems the ability to run arbitrary commands too
dangerous, they can completely disable this feature in the client’s
configuration.</li>
<li>Every shell command run by the client is audited and its output is
archived. Misuse can be easily detected and investigated.</li>
<li>This feature is considered high risk and it is not available via
the GUI. One must use the velociraptor binary on the server itself
to run the interactive shell.</li>
</ol>
</div>
<div class="section" id="interactive-shell">
<h2>Interactive Shell</h2>
<p>The interactive shell feature is accessed by issueing the shell
command to the velociraptor binary:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor --config ~/server.config.yaml shell C.7403676ab8664b2b
C.7403676ab8664b2b <span class="o">(</span>trek<span class="o">)</span> &gt;ls /
Running ls / on C.7403676ab8664b2b
Received response at <span class="m">2018</span>-12-11 <span class="m">13</span>:12:35 +1000 AEST - Return code <span class="m">0</span>

bin
boot
core
data
dev

C.7403676ab8664b2b <span class="o">(</span>trek<span class="o">)</span> &gt;id
Running id on C.7403676ab8664b2b
Received response at <span class="m">2018</span>-12-11 <span class="m">13</span>:13:05 +1000 AEST - Return code <span class="m">0</span>

<span class="nv">uid</span><span class="o">=</span><span class="m">1000</span><span class="o">(</span>mic<span class="o">)</span> <span class="nv">gid</span><span class="o">=</span><span class="m">1000</span><span class="o">(</span>mic<span class="o">)</span> <span class="nv">groups</span><span class="o">=</span><span class="m">1000</span><span class="o">(</span>mic<span class="o">)</span>,4<span class="o">(</span>adm<span class="o">)</span>,24<span class="o">(</span>cdrom<span class="o">)</span>,27<span class="o">(</span>sudo<span class="o">)</span>

C.7403676ab8664b2b <span class="o">(</span>trek<span class="o">)</span> &gt;whoami
Running whoami on C.7403676ab8664b2b
Received response at <span class="m">2018</span>-12-11 <span class="m">13</span>:13:10 +1000 AEST - Return code <span class="m">0</span>

mic
</pre></div>
</div>
<p>As you can see it is pretty straight forward - type a command, the
command is sent to the client, and the client responds with the
output.</p>
</div>
<div class="section" id="how-does-it-work">
<h2>How does it work?</h2>
<p>The main components are shown in the figure below. Note that the shell
process is a different process from the frontend:</p>
<img alt="../../../_images/interactive_shell_workflow.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/interactive_shell_workflow.png"/>
<p>The workflow starts when a user issues a command (for example “ls -l
/”) on the terminal. The shell process schedules a VQL query for the
client:</p>
<div class="highlight-psql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">now</span><span class="p">()</span> <span class="k">as</span> <span class="nb">Timestamp</span><span class="p">,</span> <span class="n">Argv</span><span class="p">,</span> <span class="k">Stdout</span><span class="p">,</span>
     <span class="n">Stderr</span><span class="p">,</span> <span class="n">ReturnCode</span> <span class="k">FROM</span> <span class="n">execve</span><span class="p">(</span><span class="n">argv</span><span class="o">=</span><span class="p">[</span><span class="s1">'ls'</span><span class="p">,</span> <span class="s1">'-l'</span><span class="p">,</span> <span class="s1">'/'</span><span class="p">])</span>
</pre></div>
</div>
<p>However, this query is scheduled as part of the monitoring flow -
which means it’s response will be sent and stored with the monitoring
logs. As soon as the shell process schedules the VQL query the
frontend is notified and the client is woken. Note that due to
Velociraptor’s near instantaneous communication protocol this causes
the client to run the command almost immediately.</p>
<p>The client executes the query which returns one or more rows
containing the Stdout of the process. The client will then send the
response to the server as a monitoring event. The frontend will then
append the event to a CSV file.</p>
<p>After sending the initial client query, the interactive shell process
will issue a watch VQL query to watch for the shell response:</p>
<div class="highlight-psql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">ReturnCode</span><span class="p">,</span> <span class="k">Stdout</span><span class="p">,</span> <span class="n">Stderr</span><span class="p">,</span> <span class="nb">Timestamp</span><span class="p">,</span> <span class="n">Argv</span>
<span class="k">FROM</span> <span class="n">watch_monitoring</span><span class="p">(</span><span class="n">client_id</span><span class="o">=</span><span class="n">ClientId</span><span class="p">,</span> <span class="n">artifact</span><span class="o">=</span><span class="s1">'Shell'</span><span class="p">)</span>
</pre></div>
</div>
<p>The process now blocks until this second query detects the response
arrived on the monitoring queue. Now we simply display the result and
go back to the interactive prompt.</p>
<p>Note that the interactive shell is implemented using the same basic
building blocks that Velociraptor offers:</p>
<ol class="arabic simple">
<li>Issuing client VQL queries.</li>
<li>Waking the client immediately gives instant results (no need for polling).</li>
<li>Utilizing the event monitoring flow to receive results from queries immediately.</li>
<li>Writing server side event queries to watch for new events, such as responses from the client.</li>
</ol>
<p>Note that the frontend is very simple and does no specific processing
of the interactive shell, the feature is implemented completely within
the interactive shell process itself. This design lowers the load on
the frontends since their job is very simple, but enables complex post
processing and interaction to tbe implemented by other processes.</p>
</div>
<div class="section" id="auditing">
<h2>Auditing</h2>
<p>We mentioned previously that running shell commands on endpoints is a
powerful feature and we need to audit its use closely. Since shell
command output is implemented via the monitored event queues it should
be obvious that we can monitor all such commands by simply watching
the Shell artifact event queue:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor query <span class="s2">"select * from watch_monitoring(artifact='Shell')"</span>
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">"Argv"</span>: <span class="s2">"\"{\\\"Argv\\\":[\\\"id\\\"]}\""</span>,
  <span class="s2">"Artifact"</span>: <span class="s2">"Shell"</span>,
  <span class="s2">"ClientId"</span>: <span class="s2">"C.7403676ab8664b2b"</span>,
  <span class="s2">"ReturnCode"</span>: <span class="s2">"0"</span>,
  <span class="s2">"Stderr"</span>: <span class="s2">"\"\""</span>,
  <span class="s2">"Stdout"</span>: <span class="s2">"\"uid=1000(mic) gid=1000(mic) groups=1000(mic)\\n\""</span>,
  <span class="s2">"Timestamp"</span>: <span class="s2">"1544499929"</span>
 <span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p>We can easily write an artifact that escalates any use of the
interactive shell by sending the admin an mail (See previous blog
post). This way we can see if someone missused the
feature. Alternatively we may simply archive the event queue CSV file
for long term auditing of any interactive shell use.</p>
</div>
]]></description>
             <pubDate>Tue, 11 Dec 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/12/10/server_side_vql_queries_and_events.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/12/10/server_side_vql_queries_and_events.html</guid>
            <title><![CDATA[Server side VQL queries and Escalation Events]]></title>
            <description><![CDATA[<h1>Server side VQL queries and Escalation Events</h1>
<p>Previously we have seen how Velociraptor collects information from end
points using Velociraptor artifacts. These artifacts encapsulate user
created queries using the Velociraptor Query Language (VQL). The power
of VQL is that it provides for a very flexible way of specifying
exactly what should be collected from the client and how - without
needing to modify client code or deploy new clients!</p>
<p>This is not the whole story though! It is also possible to run VQL
queries on the server side! Similarly server side Velociraptor
artifacts can be used to customize the operation of the server -
without modifying any code or redeploying the server components.</p>
<div id="more"> </div><div class="section" id="server-side-vql-queries">
<h2>Server Side VQL Queries.</h2>
<p>By now you are probably familiar with Velociraptor and VQL. We have
seen that it is possible to run a VQL query interactively from the
commandline. For example to find all processes matching the ‘gimp’:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor query <span class="se">\</span>
   <span class="s2">"SELECT Pid, Exe, Cmdline FROM pslist() WHERE Exe =~ 'gimp'"</span>
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">"Cmdline"</span>: <span class="s2">"gimp-2.10"</span>,
  <span class="s2">"Exe"</span>: <span class="s2">"/usr/bin/gimp-2.10"</span>,
  <span class="s2">"Pid"</span>: <span class="m">13207</span>
 <span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p>We have used this feature previously in order to perfect and test our
queries by interactively building the query as we go along.</p>
<p>However it is also possible to run queries on the server itself in
order to collect information about the server. There is nothing
special about this as such - it is simply that some VQL plugins are
able to operate on the server’s internal data store and therefore
provide a way to interact with the server via VQL queries.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Other endpoint monitoring tools export a rich API and even an API
client library to enable users to customize and control their
installation. For example, GRR expects users write python scripts
using the GRR client API library.</p>
<p class="last">Velociraptor’s approach is different - the functionality typically
available via APIs is made available to VQL queries via VQL plugins
(e.g. client information, flow information and results
collected). In this way the VQL itself forms an API with which one
controls the server and deployment. There is no need to write any
code - simply use existing VQL plugins in any combination that
makes sense to create new functionality - then encapsulates these
queries inside Velociraptor artifacts for reuse and sharing.</p>
</div>
<p>For example, to see all the clients and their hostnames:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor query <span class="se">\</span>
   <span class="s2">"SELECT os_info.fqdn as Hostname, client_id from clients()"</span> --format text
+-----------------+--------------------+
<span class="p">|</span>    Hostname     <span class="p">|</span>     client_id      <span class="p">|</span>
+-----------------+--------------------+
<span class="p">|</span> mic-Inspiron    <span class="p">|</span> C.772d16449719317f <span class="p">|</span>
<span class="p">|</span> TestComputer    <span class="p">|</span> C.11a3013cca8f826e <span class="p">|</span>
<span class="p">|</span> trek            <span class="p">|</span> C.952156a4b022ddee <span class="p">|</span>
<span class="p">|</span> DESKTOP-IOME2K5 <span class="p">|</span> C.c916a7e445eb0868 <span class="p">|</span>
+-----------------+--------------------+
SELECT os_info.fqdn AS Hostname,
client_id FROM clients<span class="o">()</span>
</pre></div>
</div>
<p>To inspect what flows were run on a client:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor query <span class="se">\</span>
   <span class="s2">"SELECT runner_args.creator, runner_args.flow_name, \</span>
<span class="s2">    runner_args.start_time FROM \</span>
<span class="s2">    flows(client_id='C.772d16449719317f')"</span>
<span class="o">[</span>
<span class="o">{</span>
  <span class="s2">"runner_args.creator"</span>: <span class="s2">""</span>,
  <span class="s2">"runner_args.flow_name"</span>: <span class="s2">"MonitoringFlow"</span>,
  <span class="s2">"runner_args.start_time"</span>: <span class="m">1544338661236625</span>
<span class="o">}</span>,
<span class="o">{</span>
  <span class="s2">"runner_args.creator"</span>: <span class="s2">"mic"</span>,
  <span class="s2">"runner_args.flow_name"</span>: <span class="s2">"VFSDownloadFile"</span>,
  <span class="s2">"runner_args.start_time"</span>: <span class="m">1544087705756469</span>
<span class="o">}</span>,
...
</pre></div>
</div>
</div>
<div class="section" id="client-event-monitoring">
<h2>Client Event Monitoring</h2>
<p>We have also previously seen that Velociraptor can collect event
streams from clients. For example, the client’s process execution logs
can be streamed to the server. Clients can also receive event queries
which forward selected events from the windows event logs.</p>
<p>When we covered those features in earlier blog posts, we stressed that
the Velociraptor server does not actually do anything with the client
events, other than save them to a file. The server just writes the
client’s events in simple Comma Separated files (CSV files) on the
server.</p>
<p>We mentioned that it is possible to import this file into another tool
(e.g. a spreadsheet or database) for post-processing. An alternative
is to perform post-processing with Velociraptor itself using server
side VQL queries.</p>
<p>For example, we can filter a client’s process execution log using a
VQL query:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor query <span class="s2">"SELECT * from monitoring(</span>
<span class="s2">      client_id='C.87b19dba006fcddb',</span>
<span class="s2">      artifact='Windows.Events.ProcessCreation')</span>
<span class="s2">    WHERE Name =~ '(?i)psexesvc' "</span>
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">"CommandLine"</span>: <span class="s2">"\"C:\\\\Windows\\\\PSEXESVC.exe\""</span>,
  <span class="s2">"Name"</span>: <span class="s2">"\"PSEXESVC.exe\""</span>,
  <span class="s2">"PID"</span>: <span class="s2">"452"</span>,
  <span class="s2">"PPID"</span>: <span class="s2">"512"</span>,
  <span class="s2">"Timestamp"</span>: <span class="s2">"\"2018-12-09T23:30:42-08:00\""</span>,
  <span class="s2">"artifact"</span>: <span class="s2">"Windows.Events.ProcessCreation"</span>,
  <span class="s2">"client_id"</span>: <span class="s2">"C.87b19dba006fcddb"</span>
 <span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p>The above query finds running instances of psexec’s service
component - a popular method of lateral movement and privilege
escalation.</p>
<p>This query uses the <cite>monitoring()</cite> VQL plugin which opens each of the
CSV event monitoring logs for the specified artifact on the server,
decodes the CSV file and emits all the rows within it into the VQL
Query. The rows are then filtered by applying the regular expression
to the name.</p>
</div>
<div class="section" id="server-side-event-queries">
<h2>Server side event queries</h2>
<p>VQL queries do not have to terminate at all. Some VQL plugins can run
indefinitely, emitting rows at random times - usually in response to
some events. These are called Event Queries since they never
terminate. We saw this property when monitoring the client - the above
<cite>Windows.Events.ProcessCreation</cite> artifact uses an event query which
emits a single row for each process execution on the end point.</p>
<p>However, we can also have Event Queries on the server. When used in
this way the query triggers in response to data collected by the
server of various clients.</p>
<p>For example, consider the above query to detect instances of <cite>psexec</cite>
executions. While we can detect this by filtering existing monitoring
event logs, it would be nice to be able to respond to such an event
dynamically.</p>
<p>One way is to repeatedly run the same query (say every minute) and
look for newly reported instances of <cite>psexec</cite> executions. But this
approach is not terribly efficient. A better approach is to install
a watcher on the monitoring event log:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor query <span class="s2">"SELECT * from watch_monitoring(</span>
<span class="s2">     client_id='C.87b19dba006fcddb',</span>
<span class="s2">     artifact='Windows.Events.ProcessCreation') where Name =~ '(?i)psexesvc' "</span>
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">"CommandLine"</span>: <span class="s2">"\"C:\\\\Windows\\\\PSEXESVC.exe\""</span>,
  <span class="s2">"Name"</span>: <span class="s2">"\"PSEXESVC.exe\""</span>,
  <span class="s2">"PID"</span>: <span class="s2">"4592"</span>,
  <span class="s2">"PPID"</span>: <span class="s2">"512"</span>,
  <span class="s2">"Timestamp"</span>: <span class="s2">"\"2018-12-10T01:18:06-08:00\""</span>,
  <span class="s2">"artifact"</span>: <span class="s2">"Windows.Events.ProcessCreation"</span>,
  <span class="s2">"client_id"</span>: <span class="s2">"C.87b19dba006fcddb"</span>
 <span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p>The watcher efficiently follows the monitoring CSV file to detect new
events. These events are then emitted into the VQL query and
subsequently filtered. When the query processes all rows in the file,
the plugin just sleeps and waits for the file to grow again. The
<cite>watch_monitoring()</cite> plugin essentially tails the CSV file as it is
being written. Note that due to the fact that log files are never
truncated and always grow, and that CSV file format is a simple, one
row per line format it is possible to both read and write to the same
file without locking. This makes following a growing log file
extremely efficient and safe - even from another process.</p>
</div>
<div class="section" id="responding-to-server-side-events">
<h2>Responding to server side events</h2>
<p>The previous query will return a row when psexec is run on the
client. This is a very suspicious event in our environment and we
would like to escalate this by sending us an email.</p>
<p>We can modify the above query to send an email for each event:</p>
<div class="highlight-psql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">foreach</span><span class="p">(</span>
   <span class="k">row</span><span class="o">=</span><span class="p">{</span>
     <span class="k">SELECT</span> <span class="o">*</span> <span class="k">from</span> <span class="n">watch_monitoring</span><span class="p">(</span>
       <span class="n">client_id</span><span class="o">=</span><span class="s1">'C.87b19dba006fcddb'</span><span class="p">,</span>
       <span class="n">artifact</span><span class="o">=</span><span class="s1">'Windows.Events.ProcessCreation'</span><span class="p">)</span>
    <span class="k">WHERE</span> <span class="k">Name</span> <span class="o">=~</span> <span class="s1">'(?i)psexesvc'</span>
   <span class="p">},</span>
   <span class="n">query</span><span class="o">=</span><span class="p">{</span>
     <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">mail</span><span class="p">(</span>
       <span class="k">to</span><span class="o">=</span><span class="s1">'admin@example.com'</span><span class="p">,</span>
       <span class="n">subject</span><span class="o">=</span><span class="s1">'PsExec launched on host'</span><span class="p">,</span>
       <span class="n">period</span><span class="o">=</span><span class="mf">60</span><span class="p">,</span>
       <span class="n">body</span><span class="o">=</span><span class="n">format</span><span class="p">(</span><span class="n">format</span><span class="o">=</span><span class="s1">'PsExec execution detected at %v: %v'</span><span class="p">,</span>
                   <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="nb">Timestamp</span><span class="p">,</span> <span class="n">Commandline</span><span class="p">])</span>
     <span class="p">)</span>
   <span class="p">})</span>
</pre></div>
</div>
<p>The query sends an email from each event emitted. The message body is
formatted using the <cite>format()</cite> VQL function and this includes
important information from the generated event. Note that the <cite>mail()</cite>
plugin restricts the frequency of mails to prevent triggering the mail
server’s spam filters. So if two psexec executions occur within 60
seconds we will only get one email.</p>
<p>In order for Velociraptor to be able to send mail you must configure
SMTP parameters in the server’s configuration file. The following
example uses gmail to send mails (other mail providers will have
similar authentication requirements).</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">Mail</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">server</span><span class="p p-Indicator">:</span> <span class="s">"smtp.gmail.com"</span>
  <span class="l l-Scalar l-Scalar-Plain">auth_username</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">someuser@gmail.com</span>
  <span class="l l-Scalar l-Scalar-Plain">auth_password</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">zldifhjsdflkjfsdlie</span>
</pre></div>
</div>
<p>The password in the configuration is an application specific password
obtained from
<a class="reference external" href="https://security.google.com/settings/security/apppasswords">https://security.google.com/settings/security/apppasswords</a></p>
<img alt="../../../_images/app_password.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/app_password.png"/>
</div>
<div class="section" id="tying-it-all-together-server-side-event-artifacts">
<h2>Tying it all together: Server Side Event Artifacts</h2>
<p>As always we really want to encapsulate VQL queries in artifact
definitions. This way we can design specific alerts, document them and
invoke them by name. Let us encapsulate the above queries in a new
artifact:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Server.Alerts.PsExec</span>
<span class="l l-Scalar l-Scalar-Plain">description</span><span class="p p-Indicator">:</span>  <span class="p p-Indicator">|</span>
   <span class="no">Send an email if execution of the psexec service was detected on any client.</span>

   <span class="no">Note this requires that the Windows.Event.ProcessCreation</span>
   <span class="no">monitoring artifact be collected.</span>

<span class="l l-Scalar l-Scalar-Plain">parameters</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">EmailAddress</span>
    <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">admin@example.com</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">MessageTemplate</span>
    <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
      <span class="no">PsExec execution detected at %v: %v for client %v</span>

<span class="l l-Scalar l-Scalar-Plain">sources</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">queries</span><span class="p p-Indicator">:</span>
     <span class="p p-Indicator">-</span> <span class="p p-Indicator">|</span>
       <span class="no">SELECT * FROM foreach(</span>
         <span class="no">row={</span>
           <span class="no">SELECT * from watch_monitoring(</span>
             <span class="no">artifact='Windows.Events.ProcessCreation')</span>
           <span class="no">WHERE Name =~ '(?i)psexesvc'</span>
         <span class="no">},</span>
         <span class="no">query={</span>
           <span class="no">SELECT * FROM mail(</span>
             <span class="no">to=EmailAddress,</span>
             <span class="no">subject='PsExec launched on host',</span>
             <span class="no">period=60,</span>
             <span class="no">body=format(</span>
               <span class="no">format=MessageTemplate,</span>
               <span class="no">args=[Timestamp, CommandLine, ClientId])</span>
          <span class="no">)</span>
       <span class="no">})</span>
</pre></div>
</div>
<p>We create a new directory called <cite>my_artifact_directory</cite> and store
that file inside as <cite>psexesvc.yaml</cite>. Now, on the server we invoke the
artifact collector and instruct it to also add our private artifacts:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor --definitions my_artifact_directory/ <span class="se">\</span>
    --config ~/server.config.yaml <span class="se">\</span>
    --format json <span class="se">\</span>
    artifacts collect Server.Alerts.PsExec
INFO:2018/12/10 <span class="m">21</span>:36:27 Loaded <span class="m">40</span> built in artifacts
INFO:2018/12/10 <span class="m">21</span>:36:27 Loading artifacts my_artifact_directory/
<span class="o">[][</span>
 <span class="o">{</span>
  <span class="s2">"To"</span>: <span class="o">[</span>
    <span class="s2">"admin@example.com"</span>
  <span class="o">]</span>,
  <span class="s2">"CC"</span>: null,
  <span class="s2">"Subject"</span>: <span class="s2">"PsExec launched on host"</span>,
  <span class="s2">"Body"</span>: <span class="s2">"PsExec execution detected at \"2018-12-10T03:36:49-08:00\": \"C:\\\\Windows\\\\PSEXESVC.exe\""</span>,
  <span class="s2">"Period"</span>: <span class="m">60</span>
 <span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
</div>
<div class="section" id="conclusions">
<h2>Conclusions</h2>
<p>This blog post demonstrates how VQL can be used on the server to
create a full featured incident response framework. Velociraptor does
not dictate a particular workflow, since all its actions are governed
by VQL queries and artifacts. Using the same basic building blocks,
users can fashion their own highly customized incident response
workflow. Here is a brainstorm of possible actions:</p>
<ol class="arabic simple">
<li>An artifact can be written to automatically collect a memory
capture if a certain event is detected.</li>
<li>Using the <cite>http_client()</cite> VQL plugin, when certain events are
detected on the server open a ticket automatically (using a SOAP or
JSON API).</li>
<li>If a particular event is detected, immediately shut the machine
down or quarantine it (by running shell commands on the compromised
host).</li>
</ol>
<p>The possibilities are truly endless. Comment below if you have more
interesting ideas and do not hesitate to contribute artifact
definitions to address your real world use cases.</p>
</div>
]]></description>
             <pubDate>Mon, 10 Dec 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/12/09/more_on_client_event_collection.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/12/09/more_on_client_event_collection.html</guid>
            <title><![CDATA[More on client event collection]]></title>
            <description><![CDATA[<h1>More on client event collection</h1>
<p>Previously we have seen that Velociraptor can monitor client events
using Event Artifacts. To recap, Event Artifacts are simply artifacts
which contain event VQL queries. Velociraptor’s VQL queries do not
have to terminate by themselves - instead VQL queries may run
indefinitely, trickling results over time.</p>
<p>This post takes another look at event queries and demonstrates how
these can be used to implement some interesting features.</p>
<div id="more"> </div><div class="section" id="periodic-event-queries">
<h2>Periodic Event queries</h2>
<p>The simplest kind of events are periodically generated events. These
are created using the <cite>clock()</cite> VQL plugin. This is a simple event
plugin which just emits a new row periodically.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor query <span class="s2">"select Unix from clock(period=5)"</span> --max_wait <span class="m">1</span>
<span class="o">[</span>
 <span class="o">{</span>
   <span class="s2">"Unix"</span>: <span class="m">1544339715</span>
 <span class="o">}</span>
<span class="o">][</span>
 <span class="o">{</span>
   <span class="s2">"Unix"</span>: <span class="m">1544339720</span>
 <span class="o">}</span>
<span class="o">]</span>^C
</pre></div>
</div>
<p>The query will never terminate, instead the <cite>clock()</cite> plugin will emit
a new timestamp every 5 seconds. Note the <cite>–max_wait</cite> flag which
tells Velociraptor to wait at least for 1 second in order to batch
rows before reporting them.</p>
<p>This query is not very interesting! Let’s do something more
interesting. GRR has a feature where each client sends its own CPU use
and memory footprint sampled every minutes to the server. This is a
really useful feature because it can be used to make sure the client’s
impact on the host’s performance is minimal.</p>
<p>Let us implement the same feature with a VQL query. What we want is to
measure the client’s footprint every minute and send that to the
server:</p>
<div class="highlight-psql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="o">*</span> <span class="k">from</span> <span class="n">foreach</span><span class="p">(</span>
 <span class="k">row</span><span class="o">=</span><span class="p">{</span>
   <span class="k">SELECT</span> <span class="n">UnixNano</span> <span class="k">FROM</span> <span class="n">clock</span><span class="p">(</span><span class="n">period</span><span class="o">=</span><span class="mf">60</span><span class="p">)</span>
 <span class="p">},</span>
 <span class="n">query</span><span class="o">=</span><span class="p">{</span>
   <span class="k">SELECT</span> <span class="n">UnixNano</span> <span class="o">/</span> <span class="mf">1000000000</span> <span class="k">as</span> <span class="nb">Timestamp</span><span class="p">,</span>
          <span class="n">Times</span><span class="mf">.</span><span class="k">user</span> <span class="o">+</span> <span class="n">Times</span><span class="mf">.</span><span class="k">system</span> <span class="k">as</span> <span class="n">CPU</span><span class="p">,</span>
          <span class="n">MemoryInfo</span><span class="mf">.</span><span class="n">RSS</span> <span class="k">as</span> <span class="n">RSS</span>
   <span class="k">FROM</span> <span class="n">pslist</span><span class="p">(</span><span class="n">pid</span><span class="o">=</span><span class="n">getpid</span><span class="p">())</span>
 <span class="p">})</span>
</pre></div>
</div>
<p>This query runs the <cite>clock()</cite> VQL plugin and for each row it emits, we
run the <cite>pslist()</cite> plugin, extracting the total CPU time (system +
user) used by our own pid (i.e. the Velociraptor client).</p>
<p>We can now encapsulate this query in an <a class="reference external" href="/blog/html/reference/artifacts.html#generic-client-stats">artifact</a> and collect it:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor artifacts collect Generic.Client.Stats --max_wait <span class="m">1</span> --format json
<span class="o">[][</span>
  <span class="o">{</span>
  <span class="s2">"CPU"</span>: <span class="m">0</span>.06999999999999999,
  <span class="s2">"RSS"</span>: <span class="m">18866176</span>,
  <span class="s2">"Timestamp"</span>: <span class="m">1544340582</span>.9939497
  <span class="o">}</span>
<span class="o">][</span>
  <span class="o">{</span>
  <span class="s2">"CPU"</span>: <span class="m">0</span>.09,
  <span class="s2">"RSS"</span>: <span class="m">18866176</span>,
  <span class="s2">"Timestamp"</span>: <span class="m">1544340602</span>.9944408
  <span class="o">}</span>
<span class="o">]</span>^C
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You must specify the –format json to be able to see the results
from event queries on the command line. Otherwise Velociraptor will
try to get all the results so it can format them in a table and
never return any results.</p>
</div>
</div>
<div class="section" id="installing-the-event-collector">
<h2>Installing the event collector.</h2>
<p>In order to have clients collect this event, we need to add the
artifact to the server. Simply add the YAML file into a directory on
the server and start the server with the –definitions flag. Then
simply add the event name to the Events clause of the server
configuration. When clients connect to the server they will
automatically start collecting these events and sending them to the
server:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>$ velociraptor --definitions path/to/my/artifacts/ frontend
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">Events</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">artifacts</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Generic.Client.Stats</span>
  <span class="l l-Scalar l-Scalar-Plain">version</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
</pre></div>
</div>
<p>Note that we do not need to redeploy any clients, modify any code or
recompile anything. We simply add the new artifact definition and
clients will automatically start monitoring and feeding back our
information.</p>
<p>The data is sent to the server where it is stored in a file (Events are stored in a unique file for each day).</p>
<p>For example, the path
<cite>/var/lib/velociraptor/clients/C.772d16449719317f/monitoring/Artifact%20Generic.Client.Stats/2018-12-10</cite>
stores all events collected from client id <cite>C.772d16449719317f</cite> for
the <cite>Generic.Client.Stats</cite> artifact on the day of <cite>2018-12-10</cite>.</p>
<p>In the next blog post we will demonstrate how these events can be post
processed and acted on. It is important to note that the Velociraptor
server does not interpret the collected monitoring events at all -
they are simply appended to the daily log file (which is a CSV file).</p>
<p>The CSV file can then be imported into basically any tool designed to
work with tabular data (e.g. spreadsheets, databases, BigQuery
etc). CSV is almost universally supported by all major systems.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span/>Timestamp,CPU,RSS
1544363561.8001275,14.91,18284544
1544363571.8002906,14.91,18284544
1544363581.8004665,14.920000000000002,18284544
1544363591.8007126,14.920000000000002,18284544
1544363601.8008528,14.920000000000002,18284544
</pre></div>
</div>
</div>
]]></description>
             <pubDate>Sun, 09 Dec 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/11/13/velociraptor_training_at_nzitf.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/11/13/velociraptor_training_at_nzitf.html</guid>
            <title><![CDATA[Velociraptor training at NZITF]]></title>
            <description><![CDATA[<h1>Velociraptor training at NZITF</h1>
<p>We are very excited to run this full day training workshop at the New
Zealand Internet Engineering Task Force (NZITF) conference.</p>
<div id="more"> </div><p>The training material can be downloaded here <a class="reference external" href="/resources/nzitf_velociraptor.pdf">“Velociraptor NZITF training”</a>.</p>
]]></description>
             <pubDate>Tue, 13 Nov 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/11/09/event_queries_and_endpoint_monitoring.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/11/09/event_queries_and_endpoint_monitoring.html</guid>
            <title><![CDATA[Event Queries and Endpoint Monitoring]]></title>
            <description><![CDATA[<h1>Event Queries and Endpoint Monitoring</h1>
<p>In previous posts we have seen how Velociraptor can run artifacts to
collect information from hosts. For example, we can collect WMI
queries, user accounts and files.</p>
<p>However it would be super awesome to be able to do this collection in
real time, as soon as an event of interest appears on the host, we
would like to have that collected on the server. This post describes
the new event monitoring framework and shows how Velociraptor can
collect things such as event logs, process execution and more in real
time.</p>
<div id="more"> </div><p>Why monitor endpoint events? Recording end point event information on
the server gives a bunch of advantages. For one, the server keeps a
record of historical events, which makes going back to search for
these easy as part of an incident response activity.</p>
<p>For example, Velociraptor can keep a running log of process execution
events for all clients, on the server. If a particular executable is
suspected to be malicious, we can now go back and search for the
execution of that process in the past on the infected machine (for
establishing the time of infection), as well as search the entire
deployment base for the same binary execution to be able identify
lateral movement and wider compromises.</p>
<div class="section" id="how-are-events-monitored">
<h2>How are events monitored?</h2>
<p>Velociraptor relies heavily on VQL queries. A VQL query typically
produces a single table of multiple rows. For example, the query:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">Name</span><span class="p">,</span> <span class="n">CommandLine</span> <span class="k">FROM</span> <span class="n">pslist</span><span class="p">()</span>
</pre></div>
</div>
<p>Returns a single row of all running processes, and then returns.</p>
<p>However, VQL queries do not have to terminate at all. If the VQL
plugin they are calling does not terminate, the VQL query will
continue to run and pass events in partial results to the VQL caller.</p>
<p>Event queries are just regular VQL queries which do not terminate
(unless cancelled) returning rows whenever an event is generated.</p>
<img alt="../../../_images/1.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/1.png"/>
<p>Consider the parse_evtx() plugin. This plugin parses an event log file
and returns all events in it. We can then filter events and return
specific events of interest. The following query returns all the
service installation events and terminates:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe query "SELECT EventData, System.TimeCreated.SystemTime from</span>
<span class="go">   parse_evtx(filename='c:/windows/system32/winevt/logs/system.evtx') where</span>
<span class="go">   System.EventId.value = '7045'"</span>
<span class="go">[</span>
<span class="go"> {</span>
<span class="go">  "EventData": {</span>
<span class="go">   "AccountName": "",</span>
<span class="go">   "ImagePath": "system32\\DRIVERS\\VBoxGuest.sys",</span>
<span class="go">   "ServiceName": "VirtualBox Guest Driver",</span>
<span class="go">   "ServiceType": "kernel mode driver",</span>
<span class="go">   "StartType": "boot start"</span>
<span class="go">  },</span>
<span class="go">  "System.TimeCreated.SystemTime": "2018-11-10T06:32:34Z"</span>
<span class="go"> }</span>
<span class="go">]</span>
</pre></div>
</div>
<p>The query specifically looks at the 7045 event <a class="reference external" href="http://www.eventid.net/display.asp?eventid=7045&amp;source=service+control+manager">“A service was installed in the system”</a></p>
<p>Lets turn this query into an event query:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe query "SELECT EventData, System.TimeCreated.SystemTime from</span>
<span class="go">   watch_evtx(filename='c:/windows/system32/winevt/logs/system.evtx') where</span>
<span class="go">   System.EventId.value = '7045'" --max_wait 1</span>
<span class="go">[</span>
<span class="go">  "EventData": {</span>
<span class="go">    "AccountName": "",</span>
<span class="go">    "ImagePath": "C:\\Users\\test\\AppData\\Local\\Temp\\pmeFF0E.tmp",</span>
<span class="go">    "ServiceName": "pmem",</span>
<span class="go">    "ServiceType": "kernel mode driver",</span>
<span class="go">    "StartType": "demand start"</span>
<span class="go">  },</span>
<span class="go">  "System.TimeCreated.SystemTime": "2018-11-10T04:57:35Z"</span>
<span class="go">  }</span>
<span class="go">]</span>
</pre></div>
</div>
<p>The watch_evtx() plugin is the event watcher equivalent of the
parse_evtx() plugin. If you ran the above query, you will notice that
Velociraptor does not terminate. Instead it will show all existing
service installation events in the log file, and then just wait in the
console.</p>
<p>If you then install a new service (in another terminal), for example
using <cite>winpmem.exe -L</cite>, a short time later you should see the event
reported by Velociraptor as in the above example. You will notice that
the watch_evtx() plugin emits event logs as they occur, but
Velociraptor will try to group the events into batches. The max_wait
flag controls how long to wait before releasing a partial result set.</p>
</div>
<div class="section" id="employing-event-queries-for-client-monitoring">
<h2>Employing event queries for client monitoring</h2>
<p>The above illustrates how event queries work, but to actually be able
to use these we had to implement the Velociraptor event monitoring
framework.</p>
<p>Normally, when we launch a CollectVQL flow, the client executes the
query and returns the result to the flow. Clearly since event queries
never terminate, we can not run them in series (because the client
will never be able to do anything else). The Velociraptor client has a
table of executing event queries which are run in a separate
thread. As these queries return more results, the results are sent
back to the server.</p>
<p>We also wanted to be able to update the events the clients are
monitoring on the fly (without a client restart). Therefore we needed
a way to be able to update the client’s event table. This simply
cancels current event queries, and installs new queries in their
place.</p>
<img alt="../../../_images/2.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/2.png"/>
<p>As events are generated by the Event Table, they are sent back to the
server into the Monitoring flow. This flow is automatically created
for each client. The monitoring flow simply writes events into the
client’s VFS. Therefore, events are currently simply recorded for each
client. In future there will be a mechanism to post process event and
produce alerts based on these.</p>
</div>
<div class="section" id="process-execution-logs">
<h2>Process Execution logs</h2>
<p>One of the most interesting event plugins is the WMI eventing
plugin. This allows Velociraptor to install a temporary WMI event
listener. For example, we can install a listener for new process
creation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">// Convert the timestamp from WinFileTime to Epoch.</span>
<span class="go">SELECT timestamp(epoch=atoi(</span>
<span class="go">  string=Parse.TIME_CREATED) / 10000000 - 11644473600 ) as Timestamp,</span>
<span class="go">  Parse.ParentProcessID as PPID,</span>
<span class="go">  Parse.ProcessID as PID,</span>
<span class="go">  Parse.ProcessName as Name, {</span>
<span class="go">    SELECT CommandLine</span>
<span class="go">    FROM wmi(</span>
<span class="go">      query="SELECT * FROM Win32_Process WHERE ProcessID = " +</span>
<span class="go">          format(format="%v", args=Parse.ProcessID),</span>
<span class="go">      namespace="ROOT/CIMV2")</span>
<span class="go">  } AS CommandLine</span>
<span class="go">  FROM wmi_events(</span>
<span class="go">       query="SELECT * FROM __InstanceCreationEvent WITHIN 1 WHERE</span>
<span class="go">              TargetInstance ISA 'Win32_Process'",</span>
<span class="go">       wait=5000000,   // Do not time out.</span>
<span class="go">       namespace="ROOT/CIMV2")</span>
</pre></div>
</div>
<p>The wmi_events() plugin installs an event listener into WMI and
therefore receives events from the OS about new process creation
events. Unfortunately these events, do not contain a lot of
information about the process. They only provide the ProcessID but not
the full command line. The above query executes a second subquery to
retrieve the command line for the process. We also parse the timestamp
and convert it into a more standard epoch based timestamp.</p>
</div>
<div class="section" id="specifying-what-should-the-client-monitor">
<h2>Specifying what should the client monitor</h2>
<p>We have seen how Event VQL queries can generate events for the
server. However, this is difficult for Velociraptor’s end users to
directly use. Who can really remember the full query?</p>
<p>As we have shown previously, Velociraptor’s Artifacts are specifically
designed to solve this issue. Artifacts encapsulate a VQL query so it
can be called by name alone.</p>
<p>For example, the Windows.Events.ProcessCreation artifact encapsulates
the above query in one easy to remember name.</p>
<p>To specify what clients should collect, users simply need to name the
event artifacts that should be monitored. Currently this is done in
the server configuration (in future this may be done via the GUI).</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">Events</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">artifacts</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Windows.Events.ServiceCreation</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Windows.Events.ProcessCreation</span>
  <span class="l l-Scalar l-Scalar-Plain">version</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
</pre></div>
</div>
<p>The event table version should be incremented each time the monitored
event list is updated. This forces all clients to refresh their event
tables.</p>
</div>
<div class="section" id="how-does-it-look-like-in-the-gui">
<h2>How does it look like in the GUI?</h2>
<p>The Monitoring flow simply writes files into the client’s VFS. This
allows these to be downloaded and post processed outside of
Velociraptor.</p>
<img alt="../../../_images/3.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/3.png"/>
</div>
<div class="section" id="conclusions">
<h2>Conclusions</h2>
<p>Adding event monitoring to Velociraptor is a great step forward. Even
just keeping the logs around is extremely helpful for incident
response. There is a lot of value in things like process execution
logging, and remote event log forwarding. We will cover some more
examples of event log monitoring in future blog posts. Until then,
have a play and provide feedback as usual by filing issues and feature
requests.</p>
</div>
]]></description>
             <pubDate>Fri, 09 Nov 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/09/29/detecting_powershell_persistence_with_velociraptor_and_yara.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/09/29/detecting_powershell_persistence_with_velociraptor_and_yara.html</guid>
            <title><![CDATA[Detecting powershell persistence with Velociraptor and Yara]]></title>
            <description><![CDATA[<h1>Detecting powershell persistence with Velociraptor and Yara</h1>
<p>I was watching the SANS DFIR Summit 2018 videos on youtube and came
across Mari DeGrazia’s talk titled <a class="reference external" href="https://www.youtube.com/watch?v=JWC7fzhvAY8">“Finding and Decoding Malicious Powershell Scripts”</a>.
This is an excellent talk and it really contains
a wealth of information. It seems that Powershell is really popular
these days, allowing attacker to “live off the land” by installing
fully functional reverse shells and backdoors, in a few lines of
obfuscated scripts.</p>
<div id="more"> </div><p>Mari went through a number of examples and also expanded on some in
her blog post <a class="reference external" href="http://az4n6.blogspot.com/2018/06/malicious-powershell-in-registry.html">Malicious PowerShell in the Registry: Persistence</a>, where
she documents persistence through an autorun key launching powershell
to execute a payload within another registry key.</p>
<p>A similar persistence mechanism is documented by David Kennedy from
Binary defence in his post <a class="reference external" href="https://blog.binarydefense.com/powershell-injection-diskless-persistence-bypass-techniques">PowerShell Injection with Fileless Payload Persistence and Bypass Techniques</a>. In that case an msha.exe link was
stored in the user’s Run key which executed a payload from another
registry key.</p>
<p>I was eager to write a Velociraptor artifact to attempt to detect such
keys using a YARA signature. Of course signature based detection is
not as robust as behavioural analysis but it is quick and usually
quite effective.</p>
<p>I thought it was still quite instructive to document how one can
develop the VQL queries for a simple Velociraptor artifact. We will be
developing the artifact interactively on a Windows system.</p>
<div class="section" id="preparation">
<h2>Preparation</h2>
<p>Our artifact will attempt to detect the persistence mechanism detailed
in the above posts. We start by adding a value to our test user
account under the key</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">Key: "HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Run"</span>
<span class="go">Value: "C:\Windows\system32\mshta.exe"</span>
<span class="go">Data:</span>
<span class="go">  about:&lt;script&gt;c1hop="X642N10";R3I=new%20ActiveXObject("WScript.Shell");</span>
<span class="go">  QR3iroUf="I7pL7";k9To7P=R3I.RegRead("HKCU\\software\\bkzlq\\zsdnhepyzs");</span>
<span class="go">  J7UuF1n="Q2LnLxas";eval(k9To7P);JUe5wz3O="zSfmLod";&lt;/script&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="defining-the-artifact">
<h2>Defining the Artifact.</h2>
<p>We create a directory called “artifacts” then create a new file inside
it called powershell_persistence.yaml. Velociraptor artifacts are just
YAML files that can be loaded at runtime using the –definitions flag.</p>
<p>Every artifact has a name, by convention the name is separated into
its major categories. We will call ours
Windows.Persistence.Powershell:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Windows.Persistence.Powershell</span>
</pre></div>
</div>
<p>This is the minimum required for Velociraptor to identify it. We can
see a listing of all artifacts Velociraptor knows about using the
“artifacts list” command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe --definitions artifacts artifacts list</span>
<span class="go">INFO:2018/09/28 07:59:40 Loaded 34 built in artifacts</span>
<span class="go">Linux.Applications.Chrome.Extensions</span>
<span class="go">Linux.Applications.Chrome.Extensions.Upload</span>
<span class="go">…</span>
<span class="go">Windows.Persistence.Powershell</span>
<span class="go">...</span>
<span class="go">Windows.Sys.Users</span>
</pre></div>
</div>
<p>We can collect the artifact simply by using the “artifacts collect”
command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe --definitions artifacts artifacts collect Windows.Persistence.Powershell</span>
<span class="go">INFO:2018/09/28 20:01:32 Loaded 34 built in artifacts</span>
</pre></div>
</div>
<p>Ok so Velociraptor can load and collect this new artifact, but as yet
it does nothing! We need to think about what exactly we want to
collect.</p>
<p>We know we want to search for all values in the Run/RunOnce hive of
all the users. Let’s first see if we can retrieve all the values using
a glob:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Windows.Persistence.Powershell</span>
<span class="l l-Scalar l-Scalar-Plain">parameters</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">keyGlob</span>
    <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="s">"HKEY_USERS\\*\\Software\\Microsoft\\Windows\</span>
    <span class="s">\\CurrentVersion\\{Run,RunOnce}\\*"</span>
<span class="l l-Scalar l-Scalar-Plain">sources</span><span class="p p-Indicator">:</span>
 <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">precondition</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">SELECT OS from info() where OS = "windows"</span>
   <span class="l l-Scalar l-Scalar-Plain">queries</span><span class="p p-Indicator">:</span>
   <span class="p p-Indicator">-</span> <span class="p p-Indicator">|</span>
    <span class="no">SELECT FullPath from glob(</span>
       <span class="no">globs=keyGlob,</span>
       <span class="no">accessor="reg"</span>
    <span class="no">)</span>
</pre></div>
</div>
<p>This artifact demonstrates a few concepts:</p>
<ol class="arabic simple">
<li>We can define parameters by name, and reference them from within
the VQL query. This keeps the VQL query clean and more readable.</li>
<li>We can define a precondition on the artifact. If the precondition
is not met, the VQL query will not be run.</li>
</ol>
<p>Lets run this artifact:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe --definitions artifacts artifacts collect Windows.Persistence.Powershell</span>
<span class="go">INFO:2018/09/28 20:51:47 Loaded 34 built in artifacts</span>
<span class="go">+--------------------------------+</span>
<span class="go">|            FullPath            |</span>
<span class="go">+--------------------------------+</span>
<span class="go">| HKEY_USERS\S-1-5-19\Software\M |</span>
<span class="go">| icrosoft\Windows\CurrentVersio |</span>
<span class="go">| n\Run\OneDriveSetup            |</span>
<span class="go">| HKEY_USERS\S-1-5-20\Software\M |</span>
<span class="go">| icrosoft\Windows\CurrentVersio |</span>
<span class="go">| n\Run\OneDriveSetup            |</span>
<span class="go">| HKEY_USERS\S-1-5-21-546003962- |</span>
<span class="go">| 2713609280-610790815-1001\Soft |</span>
<span class="go">| ware\Microsoft\Windows\Current |</span>
<span class="go">| Version\Run\"C:\Windows\system |</span>
<span class="go">| 32\mshta.exe"                  |</span>
<span class="go">+--------------------------------+</span>
<span class="go">Artifact:</span>
<span class="go">Windows.Persistence.Powershell</span>
</pre></div>
</div>
<p>It returns a couple of results so there are two Run/RunOnce values
defined. For this artifact, we only want to return those entries which
match a specific yara signature. We can work later on improving the
yara signature, but for now let’s just detect uses of the eval()
powershell command within 500 characters of an ActiveXObject
instantiation. We will try to match each value returned from the Run
keys with this object:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Windows.Persistence.Powershell</span>
<span class="l l-Scalar l-Scalar-Plain">parameters</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">keyGlob</span>
    <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="s">"HKEY_USERS\\*\\Software\\Microsoft\\Windows\</span>
             <span class="s">\\CurrentVersion\\{Run,RunOnce}\\*"</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">yaraRule</span>
    <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
      <span class="no">rule Powershell {</span>
        <span class="no">strings:</span>
        <span class="no">$ = /ActiveXObject.{,500}eval/ nocase</span>
        <span class="no">$ = /ActiveXObject.{,500}eval/ wide nocase</span>
        <span class="no">condition:</span>
        <span class="no">any of them</span>
      <span class="no">}</span>
<span class="l l-Scalar l-Scalar-Plain">sources</span><span class="p p-Indicator">:</span>
 <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">precondition</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">SELECT OS from info() where OS = "windows"</span>
   <span class="l l-Scalar l-Scalar-Plain">queries</span><span class="p p-Indicator">:</span>
   <span class="p p-Indicator">-</span> <span class="p p-Indicator">|</span>
     <span class="no">// This is a stored query</span>
     <span class="no">LET file = SELECT FullPath from glob(</span>
       <span class="no">globs=keyGlob,</span>
       <span class="no">accessor="reg"</span>
     <span class="no">)</span>
   <span class="p p-Indicator">-</span> <span class="p p-Indicator">|</span>
     <span class="no">SELECT * FROM yara(</span>
       <span class="no">rules=yaraRule,</span>
       <span class="no">files=file.FullPath,   // This will expand to a list of paths.</span>
       <span class="no">accessor="reg")</span>
</pre></div>
</div>
<p>This version recovers the FullPath of all the Run/RunOnce values and
stores them in a stored query. We then issue another query that
applies the yara rule on these values:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe --definitions artifacts artifacts collect Windows.Persistence.Powershell</span>
<span class="go">INFO:2018/09/28 21:29:10 Loaded 34 built in artifacts</span>
<span class="go">+------------+------+------+--------------------------------+--------------------------------+</span>
<span class="go">|    Rule    | Meta | Tags |            Strings             |              File              |</span>
<span class="go">+------------+------+------+--------------------------------+--------------------------------+</span>
<span class="go">| Powershell |      |      | {"Name":"$","Offset":40,"HexDa | {"FullPath":"HKEY_USERS\\S-1-5 |</span>
<span class="go">|            |      |      | ta":["00000000  41 63 74 69 76 | -21-546003962-2713609280-61079 |</span>
<span class="go">|            |      |      |  65 58 4f  62 6a 65 63 74 28 2 | 0815-1001\\Software\\Microsoft |</span>
<span class="go">|            |      |      | 2 57  |ActiveXObject(\"W|","00 | \\Windows\\CurrentVersion\\Run |</span>
<span class="go">|            |      |      | 000010  53 63 72 69 70 74 2e 5 | \\\"C:\\Windows\\system32\\msh |</span>
<span class="go">|            |      |      | 3  68 65 6c 6c 22 29 3b 51  |S | ta.exe\"","Type":"SZ","Data":{ |</span>
<span class="go">|            |      |      | cript.Shell\");Q|","00000020   | "type":"SZ","value":"about:\u0 |</span>
<span class="go">|            |      |      | 52 33 69 72 6f 55 66 3d  22 49 | 03cscript\u003ec1hop=\"X642N10 |</span>
<span class="go">|            |      |      |  37 70 4c 37 22 3b  |R3iroUf=\ | \";R3I=new%20ActiveXObject(\"W |</span>
<span class="go">|            |      |      | "I7pL7\";|","00000030  6b 39 5 | Script.Shell\");QR3iroUf=\"I7p |</span>
<span class="go">|            |      |      | 4 6f 37 50 3d 52  33 49 2e 52  | L7\";k9To7P=R3I.RegRead(\"HKCU |</span>
<span class="go">|            |      |      | 65 67 52 65  |k9To7P=R3I.RegRe | \\\\software\\\\bkzlq\\\\zsdnh |</span>
<span class="go">|            |      |      | |","00000040  61 64 28 22 48 4 | epyzs\");J7UuF1n=\"Q2LnLxas\"; |</span>
<span class="go">|            |      |      | b 43 55  5c 5c 73 6f 66 74 77  | eval(k9To7P);JUe5wz3O=\"zSfmLo |</span>
<span class="go">|            |      |      | 61  |ad(\"HKCU\\\\softwa|","00 | d\";\u003c/script\u003e"},"Mti |</span>
<span class="go">|            |      |      | 000050  72 65 5c 5c 62 6b 7a 6 | me":{"sec":1538191253,"usec":1 |</span>
<span class="go">|            |      |      | c  71 5c 5c 7a 73 64 6e 68  |r | 538191253231489700},"Ctime":{" |</span>
<span class="go">|            |      |      | e\\\\bkzlq\\\\zsdnh|","0000006 | sec":1538191253,"usec":1538191 |</span>
<span class="go">|            |      |      | 0  65 70 79 7a 73 22 29 3b  4a | 253231489700},"Atime":{"sec":1 |</span>
<span class="go">|            |      |      |  37 55 75 46 31 6e 3d  |epyzs\ | 538191253,"usec":1538191253231 |</span>
<span class="go">|            |      |      | ");J7UuF1n=|","00000070  22 51 | 489700}}                       |</span>
</pre></div>
</div>
<p>We can see that the last query returns 5 columns, but each column
actually contains objects with quite a lot of additional
information. For example, the File column returns information about
the file that matched the yara rule (its filename, timestamps
etc). The output is a bit confusing so we just return the relevant
columns. We can replace the * in the last query with a curated list of
columns to return:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">File</span><span class="p">.</span><span class="n">FullPath</span> <span class="k">as</span> <span class="n">ValueName</span><span class="p">,</span> <span class="n">File</span><span class="p">.</span><span class="k">Data</span><span class="p">.</span><span class="n">value</span> <span class="k">as</span> <span class="n">Contents</span><span class="p">,</span>
  <span class="k">timestamp</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">File</span><span class="p">.</span><span class="n">Mtime</span><span class="p">.</span><span class="n">Sec</span><span class="p">)</span> <span class="k">as</span> <span class="n">ModTime</span>
<span class="k">FROM</span> <span class="n">yara</span><span class="p">(</span><span class="n">rules</span><span class="o">=</span><span class="n">yaraRule</span><span class="p">,</span>
          <span class="n">files</span><span class="o">=</span><span class="n">file</span><span class="p">.</span><span class="n">FullPath</span><span class="p">,</span>
          <span class="n">accessor</span><span class="o">=</span><span class="ss">"reg"</span><span class="p">)</span>
</pre></div>
</div>
<p>Which results in the quite readable:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe --definitions artifacts artifacts collect Windows.Persistence.Powershell</span>
<span class="go">INFO:2018/09/28 21:42:18 Loaded 34 built in artifacts</span>
<span class="go">+--------------------------------+--------------------------------+---------------------------+</span>
<span class="go">|           ValueName            |            Contents            |          ModTime          |</span>
<span class="go">+--------------------------------+--------------------------------+---------------------------+</span>
<span class="go">| HKEY_USERS\S-1-5-21-546003962- | about:&lt;script&gt;c1hop="X642N10"; | 2018-09-28T20:20:53-07:00 |</span>
<span class="go">| 2713609280-610790815-1001\Soft | R3I=new%20ActiveXObject("WScri |                           |</span>
<span class="go">| ware\Microsoft\Windows\Current | pt.Shell");QR3iroUf="I7pL7";k9 |                           |</span>
<span class="go">| Version\Run\"C:\Windows\system | To7P=R3I.RegRead("HKCU\\softwa |                           |</span>
<span class="go">| 32\mshta.exe"                  | re\\bkzlq\\zsdnhepyzs");J7UuF1 |                           |</span>
<span class="go">|                                | n="Q2LnLxas";eval(k9To7P);JUe5 |                           |</span>
<span class="go">|                                | wz3O="zSfmLod";&lt;/script&gt;       |                           |</span>
<span class="go">+--------------------------------+--------------------------------+---------------------------+</span>
<span class="go">Artifact: Windows.Persistence.Powershell</span>
</pre></div>
</div>
<p>Great! This works and only returns values that match the yara
signature we developed.</p>
</div>
<div class="section" id="testing-the-artifact">
<h2>Testing the artifact</h2>
<p>Let’s test this artifact for real now. We restart the frontend with
the –definition flag and this makes the new artifact available in the
GUI under the Artifact Collector flow. The GUI also shows the entire
artifact we defined so we can see what VQL will be run:</p>
<img alt="../../../_images/powershell1.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/powershell1.png"/>
<p>Launching the flow appears to work and shows exactly the same result
as we collected on the command line:</p>
<img alt="../../../_images/powershell2.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/powershell2.png"/>
</div>
<div class="section" id="but-wait-there-is-a-problem">
<h2>But wait! There is a problem!</h2>
<p>When we log out of the machine, and then rerun the artifact it returns
no results!</p>
<img alt="../../../_images/powershell3.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/powershell3.png"/>
<p>Why is that? Experienced incident responders would recognize that any
artifact that works from the <cite>HKEY_USERS</cite> registry hive is inherently
unreliable. This is because the <cite>HKEY_USERS</cite> hive is not a real hive -
it is a place where Windows mounts the user’s hive when the user logs
in.</p>
<div class="section" id="how-does-hkey-users-hive-work">
<h3>How does HKEY_USERS hive work?</h3>
<p>Windows implements the concept of user profiles. Each user has a
personal registry hive that stores user specific settings. It is
actually a file stored on their home directory called ntuser.dat. When
a user logs into the workstation, the file may be synced from the
domain controller and then it is mounted under the <cite>HKEY_USERS&lt;sid&gt;</cite>
registry hive.</p>
<p>This means that when the user logs out, their user registry hive is
unmounted and does not appear in <cite>HKEY_USERS</cite> any longer. Any
artifacts based around the <cite>HKEY_USERS</cite> hive will work only if the
collection is run when a user is logged in.</p>
<p>This is obviously not what we want when we hunt for persistence! We
want to make sure that none of the users on the system have this
persistence mechanism installed. You can imagine a case where a system
has been cleaned up but then a user logs into the machine, thereby
reinfecting it!</p>
</div>
<div class="section" id="how-to-fix-this">
<h3>How to fix this?</h3>
<p>Yara is a very powerful tool because it allows us to search for
patterns in amorphous data (such as process memory and structured
files) without having to fully understand the structure of the data we
are searching for. Of course this has its limitations, but yara can
raise a red flag if the signature matches the file, and we can analyse
this file more carefully later.</p>
<p>In this case, we can not rely on globbing the <cite>HKEY_USER</cite> registry
hive, so maybe we can just search the files that back these hives? We
know that each user on the system has an <cite>NTUSER.DAT</cite> file in their
home directory (usually <cite>C:\Users\&lt;username&gt;</cite>), so let’s write an
artifact to find these files. We can reuse the artifact
Windows.Sys.Users that reports all user accounts on a system (we
display it as JSON to enhance readability):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe artifacts collect Windows.Sys.Users --format json</span>
<span class="go">INFO:2018/09/28 22:44:26 Loaded 34 built in artifacts</span>
<span class="go">{</span>
<span class="go"> "Description": "",</span>
<span class="go"> "Directory": "C:\\Users\\test",</span>
<span class="go"> "Gid": 513,</span>
<span class="go"> "Name": "test",</span>
<span class="go"> "Type": "local",</span>
<span class="go"> "UUID": "S-1-5-21-546003962-2713609280-610790815-1001",</span>
<span class="go"> "Uid": 1001</span>
<span class="go">},</span>
<span class="go">{</span>
<span class="go"> "Description": "",</span>
<span class="go"> "Directory": "C:\\Users\\user1",</span>
<span class="go"> "Gid": 513,</span>
<span class="go"> "Name": "user1",</span>
<span class="go"> "Type": "local",</span>
<span class="go"> "UUID": "S-1-5-21-546003962-2713609280-610790815-1003",</span>
<span class="go"> "Uid": 1003</span>
<span class="go">},</span>
</pre></div>
</div>
<p>So we just want to YARA scan the NTUSER.DAT file in each home directory:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">SELECT * from foreach(</span>
<span class="go">row={</span>
<span class="go">   SELECT Name, Directory as HomeDir</span>
<span class="go">     FROM Artifact.Windows.Sys.Users()</span>
<span class="go">    WHERE Directory.value and Gid</span>
<span class="go">},</span>
<span class="go">query={</span>
<span class="go">  SELECT File.FullPath As FullPath,</span>
<span class="go">         Strings.Offset AS Off,</span>
<span class="go">         Strings.HexData As Hex,</span>
<span class="go">          upload(file=File.FullPath, accessor="ntfs") AS Upload</span>
<span class="go">      FROM yara(</span>
<span class="go">            files="\\\\.\\" + HomeDir + "\\ntuser.dat",</span>
<span class="go">            accessor="ntfs",</span>
<span class="go">            rules=yaraRule, context=10)</span>
<span class="go">      })</span>
</pre></div>
</div>
<p>This query:</p>
<ol class="arabic simple">
<li>Selects all the usernames and their home directory from the
Windows.Sys.Users artifact.</li>
<li>For each directory prepends <cite>\.\</cite> and appends “ntuser.dat”. For
example <cite>c:\Users\test</cite> becomes
<cite>\.\c:\Users\test\NTUSER.dat</cite></li>
<li>The file is accessed using the NTFS filesystem accessor. This is
necessary because the registry hive is locked if the user is logged
in. Therefore we must access it using raw NTFS parsing to bypass
the OS locking.</li>
<li>For each file that matches the yara expression, we upload the file
to the server for further analysis.</li>
</ol>
<p>Lets run this new artifact on the server:</p>
<img alt="../../../_images/powershell5.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/powershell5.png"/>
<p>Unlike the previous artifact, this one simply returns the YARA hit,
but because we do not have any context on which value contained the
signature, or even if it had been deleted. Luckily we uploaded the raw
registry hive for further analysis, and we can use a tool such as
RegRipper to extract more information from the hive:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="gp">$</span> wine rip.exe -p user_run -r
<span class="go">/tmp/velociraptor/clients/C.c916a7e445eb0868/uploads/F.078739d6/ntfs/</span>
<span class="gp">%</span>5C%5C.%5CC%3A%5CUsers%5Cuser1%5CNTUSER.DAT
<span class="go">Launching user_run v.20140115</span>
<span class="go">user_run v.20140115</span>
<span class="go">(NTUSER.DAT) [Autostart] Get autostart key contents from NTUSER.DAT hive</span>

<span class="go">Software\Microsoft\Windows\CurrentVersion\Run</span>
<span class="go">LastWrite Time Thu Sep 27 01:19:08 2018 (UTC)</span>
<span class="go"> OneDrive: "C:\Users\user1\AppData\Local\Microsoft\OneDrive\OneDrive.exe"</span>
<span class="go">   /background</span>
<span class="go"> c:\windows\system32\mshta.exe: about:&lt;script&gt;c1hop="X642N10";</span>
<span class="go">   R3I=new%20ActiveXObject("WScript.Shell");</span>
<span class="go">   QR3iroUf="I7pL7";k9To7P=R3I.RegRead("HKCU\\software\\</span>
<span class="go">   bkzlq\\zsdnhepyzs");J7UuF1n="Q2LnLxas";eval(k9To7P);JUe5wz3O="zSfmLod";&lt;/script&gt;</span>
</pre></div>
</div>
<p>Note above how we can simply retrieve the uploaded file from
Velociraptor’s filestore. Velociraptor stores uploaded files on the
filesystem within the flow’s directory.</p>
</div>
<div class="section" id="conclusions">
<h3>Conclusions</h3>
<p>In this blog post we saw how to utilize YARA to find suspicious
powershell persistence mechanisms. YARA is a powerful tool and using
Velociraptor’s artifacts we can apply it to files, registry values,
and raw NTFS files such as locked registry hives and the pagefile.</p>
<p>We also saw some of the inherent problems with relying on the
<cite>HKEY_USERS</cite> registry hive for detection - the hive is only present
when a user is logged in so when we hunt, we might miss those users
who are currently logged out. We saw how <cite>YARA</cite> can be used to detect
suspicious patterns in raw registry hive files and how artifacts may
retrieve those files for further analysis.</p>
</div>
</div>
]]></description>
             <pubDate>Sat, 29 Sep 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/09/30/velorciraptor_s_filesystem_s_accessors.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/09/30/velorciraptor_s_filesystem_s_accessors.html</guid>
            <title><![CDATA[Velorciraptor’s filesystem’s accessors]]></title>
            <description><![CDATA[<h1>Velorciraptor’s filesystem’s accessors</h1>
<p>The latest release of Velociraptor introduces the ability to access
raw NTFS volumes, allowing users to read files which are normally
locked by the operating system such as registry hives, pagefile and
other locked files. In addition, Velociraptor can now also read
<a class="reference external" href="https://docs.microsoft.com/en-us/windows/desktop/vss/volume-shadow-copy-service-portal">Volume Shadow Copy</a>
snapshots. The gives a kind of time-machine ability to allow the
investigator to look through the drive content at a previous point in
the past.</p>
<p>This blog post introduces the new features and describe how
Velociraptor’s filesystem accessors work to provide data from multiple
sources to VQL queries.</p>
<div id="more"> </div><p>We have previously seen that Velociraptor can list and download files
from the client’s filesystem, as well as registry keys and values. The
client’s filesystem is made available to VQL plugins such as glob()
allowing many Artifacts to be written that work on files, registry
keys and raw NTFS volumes.</p>
<p>While Velociraptor is a great remote response tool, everything that it
can do remotely, it can also do locally using a command line
interface. This gives the user an opportunity to interactively test
their VQL queries while writing artifacts.</p>
<p>The latest release adds a couple of convenient command line options
which allow the user to interact with the filesystem accessors. For
example, to list the files in a directory we can use the “velociraptor
fs ls” command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe fs ls</span>
<span class="go">+------+------+------------+---------------------------+---------------------------------+</span>
<span class="go">| Name | Size |    Mode    |           mtime           |              Data               |</span>
<span class="go">+------+------+------------+---------------------------+---------------------------------+</span>
<span class="go">| C:   |    0 | d--------- | 1969-12-31T16:00:00-08:00 | Description: Local Fixed Disk   |</span>
<span class="go">|      |      |            |                           | DeviceID: C:                    |</span>
<span class="go">|      |      |            |                           | FreeSpace: 12686422016          |</span>
<span class="go">|      |      |            |                           | Size: 33833349120               |</span>
<span class="go">|      |      |            |                           | SystemName: DESKTOP-IOME2K5     |</span>
<span class="go">|      |      |            |                           | VolumeName:                     |</span>
<span class="go">|      |      |            |                           | VolumeSerialNumber: 9459F443    |</span>
<span class="go">| D:   |    0 | d--------- | 1969-12-31T16:00:00-08:00 | Description: CD-ROM Disc        |</span>
<span class="go">|      |      |            |                           | DeviceID: D:                    |</span>
<span class="go">|      |      |            |                           | FreeSpace: 0                    |</span>
<span class="go">|      |      |            |                           | Size: 57970688                  |</span>
<span class="go">|      |      |            |                           | SystemName: DESKTOP-IOME2K5     |</span>
<span class="go">|      |      |            |                           | VolumeName: VBox_GAs_5.2.11     |</span>
<span class="go">|      |      |            |                           | VolumeSerialNumber: A993F576    |</span>
<span class="go">+------+------+------------+---------------------------+---------------------------------+</span>
<span class="go">SELECT Name, Size, Mode.String AS Mode, timestamp(epoch=Mtime.Sec) AS mtime,</span>
<span class="go">   Data FROM glob(globs=path, accessor=accessor)</span>
</pre></div>
</div>
<p>The “fs ls” command instructs Velociraptor to list directories using
its internal filesystem accessors. By default it will use the “file”
accessor - which simply uses the usual Win32 api filesystem calls
(i.e. CreateFile, FindFirstFile etc).</p>
<p>On windows, the file accessor lists the drive letters at the root of
the filesystem, then allows subdirectories to be listed under each
letter. The above output shows some metadata for each drive letter
(like its size etc) and below the table we can see the VQL query that
was used to generate the table. To be clear, the “fs ls” command is
simply a shortcut for producing a VQL query that ultimately uses the
filesystem accessor in the glob() VQL plugin. Therefore, we can enter
any glob expression to find files:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe fs ls -v "c:\program files\**\*.exe"</span>
<span class="go">+--------------------------------+----------+------------+---------------------------+------+</span>
<span class="go">|            FullPath            |   Size   |    Mode    |           mtime           | Data |</span>
<span class="go">+--------------------------------+----------+------------+---------------------------+------+</span>
<span class="go">| C:\Program Files\Windows Defen |  4737448 | -rw-rw-rw- | 2018-07-14T17:56:49-07:00 |      |</span>
<span class="go">| der Advanced Threat Protection |          |            |                           |      |</span>
<span class="go">| \MsSense.exe                   |          |            |                           |      |</span>
<span class="go">| C:\Program Files\Windows Defen |   791384 | -rw-rw-rw- | 2018-07-14T17:56:43-07:00 |      |</span>
<span class="go">| der Advanced Threat Protection |          |            |                           |      |</span>
<span class="go">| \SenseCncProxy.exe             |          |            |                           |      |</span>
<span class="go">| C:\Program Files\Windows Defen |  3832016 | -rw-rw-rw- | 2018-07-14T17:56:50-07:00 |      |</span>
<span class="go">| der Advanced Threat Protection |          |            |                           |      |</span>
<span class="go">| \SenseIR.exe                   |          |            |                           |      |</span>
<span class="go">| C:\Program Files\Windows Defen |  2147192 | -rw-rw-rw- | 2018-07-14T18:05:00-07:00 |      |</span>
<span class="go">| der Advanced Threat Protection |          |            |                           |      |</span>
<span class="go">| \SenseSampleUploader.exe       |          |            |                           |      |</span>
<span class="go">........</span>
<span class="go">+--------------------------------+----------+------------+---------------------------+------+</span>
<span class="go">SELECT FullPath, Size, Mode.String AS Mode, timestamp(epoch=Mtime.Sec) AS mtime, Data FROM</span>
<span class="go">glob(globs=path, accessor=accessor)</span>
</pre></div>
</div>
<p>When using the registry filesystem accessor, the registry appears like
a filesystem, allowing us to run glob expressions against registry
keys and values (Note that the registry accessor provides the value in
the metadata):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe fs --accessor reg ls "HKEY_USERS\*\Software\Microsoft\Windows\CurrentVersion\{Run,RunOnce}\*"</span>
<span class="go">+---------------+------+------------+---------------------------+---------------------------------+</span>
<span class="go">|     Name      | Size |    Mode    |           mtime           |             Data                |</span>
<span class="go">+---------------+------+------------+---------------------------+---------------------------------+</span>
<span class="go">| OneDriveSetup |  104 | -rwxr-xr-x | 2018-09-03T02:48:53-07:00 | type: SZ                        |</span>
<span class="go">|               |      |            |                           | value: C:\Windows\SysWOW64\     |</span>
<span class="go">|               |      |            |                           | OneDriveSetup.exe /thfirstsetup |</span>
<span class="go">| OneDriveSetup |  104 | -rwxr-xr-x | 2018-09-03T02:48:47-07:00 | type: SZ                        |</span>
<span class="go">|               |      |            |                           | value:   C:\Windows\SysWOW64\   |</span>
<span class="go">|               |      |            |                           | OneDriveSetup.exe /thfirstsetup |</span>
<span class="go">+---------------+------+------------+---------------------------+---------------------------------+</span>
<span class="go">SELECT Name, Size, Mode.String AS Mode, timestamp(epoch=Mtime.Sec) AS mtime,</span>
<span class="go">Data FROM glob(globs=path, accessor=accessor)</span>
</pre></div>
</div>
<p>Finally, the NTFS accessor can access files by parsing the NTFS
filesystem directly. At the top level, the accessor shows all NTFS
formatted partitions. These include regular drives as well as Volume
Shadow Copies:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe fs --accessor ntfs ls</span>
<span class="go">+--------------------------------+------+------------+---------------------------------------------------------+</span>
<span class="go">|              Name              | Size |    Mode    |                             Data                        |</span>
<span class="go">+--------------------------------+------+------------+---------------------------------------------------------+</span>
<span class="go">| \\.\C:                         |    0 | d--------- | Description: Local Fixed Disk                           |</span>
<span class="go">|                                |      |            | DeviceID: C:                                            |</span>
<span class="go">|                                |      |            | FreeSpace: 11802157056                                  |</span>
<span class="go">|                                |      |            | Size: 33833349120                                       |</span>
<span class="go">|                                |      |            | SystemName: DESKTOP-IOME2K5                             |</span>
<span class="go">|                                |      |            | VolumeName:                                             |</span>
<span class="go">|                                |      |            | VolumeSerialNumber: 9459F443                            |</span>
<span class="go">| \\?\GLOBALROOT\Device\Harddisk |    0 | d--------- | DeviceObject: \\?\GLOBALROOT\Device\                    |</span>
<span class="go">|                                |      |            |             HarddiskVolumeShadowCopy1                   |</span>
<span class="go">| VolumeShadowCopy1              |      |            | ID: {CAF25144-8B70-4F9E-B4A9-5CC702281FA1}              |</span>
<span class="go">|                                |      |            | InstallDate: 20180926154712.490617-420                  |</span>
<span class="go">|                                |      |            | OriginatingMachine: DESKTOP-IOME2K5                     |</span>
<span class="go">|                                |      |            | VolumeName: \\?\Volume{3dc4b590-0000-000-501f00000000}\ |</span>
<span class="go">| \\?\GLOBALROOT\Device\Harddisk |    0 | d--------- | DeviceObject: \\?\GLOBALROOT\Device\                    |</span>
<span class="go">|                                |      |            |            HarddiskVolumeShadowCopy2                    |</span>
<span class="go">| VolumeShadowCopy2              |      |            | ID: {E48BFDD7-7D1D-40AE-918C-36FCBB009941}              |</span>
<span class="go">|                                |      |            | InstallDate: 20180927174025.893104-420                  |</span>
<span class="go">|                                |      |            | OriginatingMachine: DESKTOP-IOME2K5                     |</span>
<span class="go">|                                |      |            | VolumeName: \\?\Volume{3dc4b590-0000-000-501f00000000}\ |</span>
<span class="go">+--------------------------------+------+------------+---------------------------------------------------------+</span>
<span class="go">SELECT Name, Size, Mode.String AS Mode, timestamp(epoch=Mtime.Sec) AS mtime,, Data FROM glob(globs=path, accessor=accessor) WHERE Sys.name_type != 'DOS'</span>
</pre></div>
</div>
<p>The above example shows two volume shadow copies that Windows has
takens on two different dates (highlighted above). We can browse these
snapshots just like they were another drive (We can also apply any
glob expressions to this path):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">F:\&gt;velociraptor.exe fs --accessor ntfs ls "\\?\GLOBALROOT\Device\HarddiskVolumeShadowCopy1\</span>
<span class="go">Users\test\*.exe"</span>
<span class="go">+------------------+----------+------------+---------------------------+------------------+</span>
<span class="go">|       Name       |   Size   |    Mode    |           mtime           |       Data       |</span>
<span class="go">+------------------+----------+------------+---------------------------+------------------+</span>
<span class="go">| velociraptor.exe | 12521472 | -rwxr-xr-x | 2018-08-19T23:37:01-07:00 | mft: 39504-128-0 |</span>
<span class="go">|                  |          |            |                           | name_type: Win32 |</span>
<span class="go">| winpmem.exe      |  3619260 | -rwxr-xr-x | 2017-12-28T21:17:50-08:00 | mft: 39063-128-1 |</span>
<span class="go">|                  |          |            |                           | name_type: POSIX |</span>
<span class="go">+------------------+----------+------------+---------------------------+------------------+</span>
<span class="go">SELECT Name, Size, Mode.String AS Mode, timestamp(epoch=Mtime.Sec) AS mtime, Data FROM</span>
<span class="go">glob(globs=path, accessor=accessor) WHERE Sys.name_type != 'DOS'</span>
</pre></div>
</div>
<p>Volume shadow copies are like a time machine - they can reveal data
that was stored on the drive days or weeks prior to the time we
inspected it which makes them very useful for some investigations.</p>
<div class="section" id="using-filesystem-accessors-remotely-the-velociraptor-vfs">
<h2>Using filesystem accessors remotely - The Velociraptor VFS</h2>
<p>The above description shows how Velociraptor’s command line interface
can be used to interact with the various filesystem accessors. This is
important for writing and collecting artifacts for triage and general
system state exploration.</p>
<p>However, how do filesystem accessors appear in the Velociraptor GUI?</p>
<img alt="../../../_images/vfs1.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/vfs1.png"/>
<p>The nice thing about Velociraptor’s GUI is that it is just a way to
present the same information that the “fs ls” command is getting by
using the same VQL queries. Therefore the view is very familiar:</p>
<ol class="arabic simple">
<li>The top level of the Velociraptor VFS represents all the filesystem
accessors implemented in the client.</li>
<li>Each of these accessors shows its own view:<ol class="arabic">
<li>The file accessor uses the OS APIs to list files and
directories. Its top level is a list of mounted drives (which
may be CDROM’s or even network shares).</li>
<li>The NTFS accessor shows all NTFS volumes accessible, including
local drives and Volume Shadow Copies.</li>
<li>The registry accessor uses Win32 APIs to access the registry and
shows at the top level a list of all system hives currently
attached.</li>
</ol>
</li>
<li>For each file listed, the accessor also includes a Data
attribute. This contains accessor specific metadata about the file
(for example the MFT entry).</li>
</ol>
<p>In the below screenshot we can see how the user may navigate into the
Volume Shadow Copy and retrieve files from it:</p>
<img alt="../../../_images/vfs2.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/vfs2.png"/>
</div>
<div class="section" id="a-note-about-filenames">
<h2>A note about filenames.</h2>
<p>NTFS can have several different names to the same file. Typically, a
short DOS 8.3 style filename (e.g. PROGRA~1), as well as a Win32 long
filename (e.g. Program Files). You can see the short name for a file
using the API GetShortPathName() (or the command dir /x), but a
program needs to deliberately ask for it. Most programs do not
explicitly collect or show the short filename of a file.</p>
<p>This can cause problems for DFIR applications. For example, Imagine we
discovered a Run key to <cite>C:\Users\test\runme.exe</cite>. If we only
considered the long filename (as for example returned by the Win32API
FindFile() or the output of the dir command), then we would assume the
file has been removed and the run key is not active. In reality
however, the file may be called “This is some long filename.exe” with
a DOS name of “runme.exe”. Explorer (and most tools) will only show
the long filename by default, but the runkey will still execute by
referring to the DOS filename!</p>
<p>Usually the short filename is some variation of the long filename with
a ~1 or ~2 at the end. In reality it can be anything. In the snippet
below, I am setting the short filename for the velociraptor.exe binary
to be something completely unrelated, then I am running the binary
using the unrelated filename:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">C:\Users\test&gt;fsutil file setshortname velociraptor.exe runme.exe</span>
<span class="go">C:\Users\test&gt;dir /x *.exe</span>
<span class="go"> Volume in drive C has no label.</span>
<span class="go"> Volume Serial Number is 9459-F443</span>

<span class="go"> Directory of C:\Users\test</span>

<span class="go">08/19/2018  11:37 PM        12,521,472 RUNME.EXE    velociraptor.exe</span>
<span class="go">               2 File(s)     16,140,732 bytes</span>
<span class="go">               0 Dir(s)  11,783,704,576 bytes free</span>
<span class="go">C:\Users\test&gt;runme.exe -h</span>
<span class="go">usage: velociraptor [&lt;flags&gt;] &lt;command&gt; [&lt;args&gt; ...]</span>

<span class="go">An advanced incident response and monitoring agent.</span>
</pre></div>
</div>
<p>You can see that Windows explorer shows no trace of the runme.exe file
since it only displays the Win32 long file name:</p>
<img alt="../../../_images/vfs3.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/vfs3.png"/>
<p>It is important for DFIR investigators to be aware of this and test
your tools! You can see that sysinternals’ autoruns program won’t have
any of these shenanigans when I added a runkey to “runme.exe”. It
shows the real filename velociraptor.exe even though the runkey
indicates runme.exe:</p>
<img alt="../../../_images/vfs4.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/vfs4.png"/>
<p>Velocirpator treats a file’s DOS name and Win32 Name as distinct
entries in the NTFS directory listing. This allows us to find any
references to the file by it’s DOS name as well as its Win32 name.</p>
</div>
<div class="section" id="conclusions">
<h2>Conclusions</h2>
<p>As Velociraptor gains more functionality, we envision more filesystem
accessors to become available. The nice thing about these accessors is
that they just slot in to the rest of the VQL plugins. By providing a
new accessor, we are able to glob, hash, yara scan etc the new
abstraction. For example, to yara scan a registry key one simply calls
the VQL plugin yara with an accessor of reg: <cite>yara(rules=myRules,
files=my_reg_keys, accessor=”reg”)</cite></p>
</div>
]]></description>
             <pubDate>Sun, 30 Sep 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/09/03/velociraptor_walk_through_and_demo.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/09/03/velociraptor_walk_through_and_demo.html</guid>
            <title><![CDATA[Velociraptor walk through and demo]]></title>
            <description><![CDATA[<h1>Velociraptor walk through and demo</h1>
<p>I just uploaded a screencast of the latest Velociraptor - check it out
and play with it, and please provide feedback at
<a class="reference external" href="mailto:velociraptor-discuss%40googlegroups.com">velociraptor-discuss<span>@</span>googlegroups<span>.</span>com</a></p>
<div id="more"> </div><div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/ecP-TeUvSEY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""/>
</div>]]></description>
             <pubDate>Mon, 03 Sep 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/09/03/velociraptor_s_client_communications.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/09/03/velociraptor_s_client_communications.html</guid>
            <title><![CDATA[Velociraptor’s client communications]]></title>
            <description><![CDATA[<h1>Velociraptor’s client communications</h1>
<p>In the latest point release of the Velociraptor IR tool (0.2.3) we
have improved upon GRR’s client communications protocol to deliver a
fast and efficient, yet extremely responsive client
communication. This post explains the design of the client
communication and how it solves the problems with the old GRR’s client
communication.</p>
<div id="more"> </div><div class="section" id="how-does-the-grr-client-communicate">
<h2>How does the GRR client communicate?</h2>
<p>The GRR client protocol is depicted below.</p>
<img alt="../../../_images/comms1.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/comms1.png"/>
<p>Due to network realities such as NAT, firewalls etc, it is not
possible to directly connect to the client, so GRR relies on the
client connecting to the server in order to communicate with it.</p>
<p>The GRR client makes periodic POST requests to the server to both send
replies and receive new instructions. Since POST requests are very
short lived (most client polls carry no data) the client has to repeat
the polls periodically.</p>
<p>There are two parameters which determine how the GRR client behaves -
poll_max and poll_min. When there is some requests sent to the client,
the client will reduce its poll wait time to poll_min (default 0.2
seconds). When nothing happens, the client will increase its poll time
gradually up to poll_max (default 10 minutes).</p>
<p>Having long poll times means that any new flows launched on an idle
client must wait for up to 10 minutes before the client polls again in
order to send the new requests to the client. Unfortunately reducing
the poll_max setting actually increases server load, as the server
needs to hit the database more often to serve each poll. This scheme
essentially poses a trade off - for a responsive client, we must have
a low poll_max (i.e. more frequent polls) but this increases the load
on the frontend so it can not be too low.</p>
<p>When GRR is normally deployed it produces 2 types of clients on the
web interface: the debug client has max_poll set to 5 seconds making
testing easier because it is more responsive, but the non-debug
version has max_poll set to 10 minutes. For example at Velocidex, one
of our clients had once accidentally deployed the debug version and
the server was slammed with 5 second polls from several thousand
clients! This rendered the server useless, returning HTTP 500 status
codes for most client polls. The only way to recover was to push new
config to the clients and restart their GRR service in order to lower
the poll frequency and recover control over the deployment.</p>
</div>
<div class="section" id="catastrophic-failure-under-load">
<h2>Catastrophic failure under load</h2>
<p>The other problem with GRR’s client communication protocol is that it
tends to exhibit catastrophic failure under load. When the client
makes a HTTP POST operation, the server goes through the following
steps in order:</p>
<ol class="arabic simple">
<li>Unpack and decrypts any replies the client sends in its POST
message</li>
<li>Queue these replies on a worker queue</li>
<li>Read the client’s job queue for any outstanding requests to the client.</li>
<li>Pack and encrypt these requests to the client.</li>
<li>Write them as the body response of the HTTP POST with hopefully a
200 HTTP status.</li>
</ol>
<p>In previous posts we have seen that GRR’s overuse of queuing leads to
extreme loads on the database, so under load (e.g. when a large hunt
is taking place), the above process may take some time until the
server can obtain a lock on the database row, write and read the
messages, and compose its response.</p>
<p>What tends to happen under load, is that the client will time the
request out if the server takes too long, or the server itself may
timeout the request with a HTTP 500 code. The client, thinking it has
not got through will try to POST the same data again (this time it
will wait longer though).</p>
<p>This essentially makes things worse, because the replies are probably
already mostly queued so the next retry will re-queue the same
requests (these will be discarded by the worker anyway but they are
still queued), increasing database pressure and server load. This
manifests in a critical meltdown of the frontends who pretty soon
serve mostly 500 errors (making things worse again).</p>
<p>This is the reason why resource provision is so important with GRR, if
the frontends are just too slow to be able to keep up, the connections
will start to timeout, and load increases (rather than decreases)
causing a catastrophic failure.</p>
</div>
<div class="section" id="how-can-we-fix-this">
<h2>How can we fix this?</h2>
<p>The main problem with a polling scheme is that the user experience is
terrible - even if we reduce the poll wait times to few seconds, users
will have to wait to view the results of their actions - leading to an
overall experience of a slow and sluggish system. For a resposive user
interface we need to have client round trips of a second or less and
having poll_max set this low will just use up too many resources. This
is particularly noticeable in the VFS browser since it takes so long
to navigate to the desired directory and download files interactively.</p>
<p>Other endpoint monitoring systems use distributed pub/sub systems like
RabbitMQ or Firebase realtime database to inform the clients of new
requests. In those systems, the client makes a TCP connection to an
endpoint and holds the connection open for long periods of time, the
server can then immediately push new requests to the client as soon as
they are published. This seems like the way to go but we did not want
to introduce another dependency on Velociraptor (we really like it
being a self contained - working out of the box binary).</p>
<p>In particular we also wanted to solve the catastrophic failure we saw
with GRR clients under load (described above). This means that we need
to make sure that the clients are not sending data faster than the
server can process it. We definitely want to avoid the POST timing out
with a 500 error and the client retrying the same POST since this is
the main cause for the catastrophic failures we experienced with GRR.</p>
<p>We can do this by keeping the client’s connection open for as long as
we need, but in order to not time it out, we send the HTTP status code
immediately, then process the POST data, while sending the client
keepalive data periodically using HTTP chunked transfer encoding.</p>
<p>To the client, and any proxies in the way, it simply looks like the
POST request was received immediately, and the response body is
downloaded slowly (there is always some pad data flowing so none of
the TCP or HTTP timers are triggered since the connection is always
active). This is illustrated in the diagram below.</p>
<img alt="../../../_images/comms2.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/comms2.png"/>
<p>This scheme has the two main advantages:</p>
<ol class="arabic simple">
<li>By returning a 200 status to the client before we begin processing,
the client knows we received the data. They are then able to
de-queue these messages and will not transmit them again.</li>
<li>By keeping the client connected while the server is processing the
request we avoid any additional data from being sent to the server
while it is busy. The client will be blocked on the HTTP connection
and will actually pause its running VQL query while the server is
processing the current responses. This mechanism actually throttles
the clients to allow the server to keep up.</li>
</ol>
<div class="section" id="making-the-client-more-responsive">
<h3>Making the client more responsive</h3>
<p>We really wanted to make clients more responsive. We were frankly sick
of having to wait up to 10 minutes to access a client that we knew was
online in our IR work. To make the client more responsive we wanted to
use the same technique to keep the client connection open for long
periods of time, and then send instructions to the client as soon as
the user issues a new flow.</p>
<p>In the GRR scheme new requests are sent on the same connections as
client replies are received. This won’t work if the client connection
is held open for long periods of time because while the client is
blocked reading new responses from the server, it can not send any
replies (the POST header was already sent).</p>
<p>To fix this we switched to two separate POST connections on two server
handlers, a reader handler and a writer handler. The writer handler
only receives messages from the client to the server (i.e. replies to
client requests), while the reader handler blocks the client for
prolonged time and sends client requests as soon as new flows are
launched.</p>
<p>This scheme allows a full duplex, responsive communication protocol,
with no polling overheads. This can be seen in the diagram below.</p>
<img alt="../../../_images/comms3.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/comms3.png"/>
<p>The client establishes the reader channel by sending a HTTP POST
request to the reader handler. The server checks for any messages for
the client, and sees that there are none pending. It will then keep
the client’s connection open as before, trickle sending pad data
(using HTTP chunked transfer encoding) to keep the connection open for
as long as possible.</p>
<p>When the user launches a new flow, the server can immediately forward
the client’s requests on the open channel, completing the POST
operation. The client will then process the requests and send the
responses with a separate HTTP POST to the writer channel. In the
meantime the reader channel will re-POST to the reader handler and
become blocked and ready for the next request.</p>
<p>This scheme has the following advantages:</p>
<ol class="arabic simple">
<li>The user’s flow is executed instantly by the client. This makes for
example, the VFS browser instant - as soon as the user clicks the
“refresh directory listing” button, the directory is refreshed. As
soon as the user wants to view a file, the file is downloaded etc.</li>
<li>There is hardly any polling activity. The clients open a reader
connection once and hold it for many minutes. The server need only
check the queue at the beginning of the connection and then only if
it knows there is a new flow launched for this client. This means
server load is really low.</li>
</ol>
<p>However, the scheme also has some disadvantages:</p>
<ol class="arabic simple">
<li>TCP connections are held for long periods of time tying up server
resources. In particular the open sockets count towards the
process’s open file descriptor limit. It is typically necessary to
increase this limit (by default it is 1024 which is very low).</li>
<li>Deploying over multiple servers is a bit more complex because a
client may be blocked on one server and the flow is launched on
another server. Velociraptor now has a notification API to allow
inter server RPCs to propagate notifications between servers.</li>
</ol>
<p>We believe that these limitations can be easily managed. They are no
different from typical limitations of large scale pub/sub systems
(they too need to hold many TCP connections open). In our testing we
have not seen a problem scaling to many thousands of connected clients
with very low resource use.</p>
<p>Velociraptor now also has a pool client that allows spinning up
several thousand clients at the same time. This helps with testing a
deployment to make sure it can handle the increased open file limit
and test how large scale hunts can be handled.</p>
</div>
<div class="section" id="conclusions">
<h3>Conclusions</h3>
<p>The new responsive client communications protocol allows for near
instantaneous access to clients. This actually reduces the overall
load on the system because we do not need to perform frequent client
polls just to check if a new flow is launched. User experience is much
better as users can interact with clients immediately.</p>
</div>
</div>
]]></description>
             <pubDate>Mon, 03 Sep 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/20/velociraptor_artifacts.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/20/velociraptor_artifacts.html</guid>
            <title><![CDATA[Velociraptor Artifacts]]></title>
            <description><![CDATA[<h1>Velociraptor Artifacts</h1>
<p>We are super excited to introduce this point release of Velociraptor
(0.2.2) which introduces the concept of Velociraptor Artifacts for the
first time. This post is about what artifacts are, what they do and
how can you use them.</p>
<div id="more"> </div><p>First a bit of history. When we first started writing endpoint
monitoring tools (With GRR then Rekall Agent) we implemented the
ability to collect files, registry keys and other data. If an analyst
wanted to collect, say the chrome extensions, they would need to know
where chrome extensions typically reside (
<span class="docutils literal"><span class="pre">%homedir%/.config/google-chrome/Extensions/**</span></span>) and enter that in
each time.</p>
<p>We soon realized this was error prone and required too much mental
overhead for analysts to constantly remember these details. GRR
inspired the creation of the Forensic Artifacts project. It was
created in order to solve the problem of documenting and sharing
knowledge about forensic evidence file and registry location.</p>
<p>Further, since GRR can only collect files and has limited parsing
support, the parsing and interpretation of the artifacts is not
specified. GRR Artifacts can only specify file sets (via globs),
registry key/value sets and collections of other artifacts. These are
a bit limited in their expressiveness, and so it means that GRR has to
augment forensic artifacts with a lot of GRR specific things (like
post processing, parsing etc) to make them useful. Although Forensic
Artifacts are supposed to be tool agnostic they carry over a lot of
GRR implementation details (e.g. the knowledge base interpolations,
glob patterns etc).</p>
<p>Next came OSQuery with their SQL like syntax. This was a huge
advancement at the time because it allows users to customize the data
they obtained from their endpoint, and ask questions from the entire
enterprise at once. For the first time it was possible to combine data
from multiple sources (i.e. OSQuery “tables”) in an intelligent way
and customize the output to fit a processing pipeline, rather than
write a lot of interface glue code to filter and extract data.</p>
<p>Currently OSQuery has grown many tables - each table typically
implements a specific parser to extract one set of data. In this sense
OSQuery also solves the same problem as GRR’s artifacts - they provide
a single named entity (called a table in OSQuery) which produces
results about one type of thing (e.g. arp_cache table produces results
about the arp cache entries). The user can then just ask for the arp
cache and doesn’t care how we get it.</p>
<p>The next logical development was the development of Velociraptor Query
Language (VQL). VQL is not pure SQL - instead it is an SQL like
language with a severely reduced feature set. The main difference with
regular SQL is the ability to provide arguments to table names - that
is a VQL plugin is a data source that can receive arbitrary arguments.</p>
<p>This changes the entire game - since we can now provide high level
functions to control plugin execution. Combined with the VQL ability
to combine multiple queries into subqueries this opens the door for
very complex types of queries.</p>
<p>For example, consider the OSQuery users table. This table reads the
system’s /etc/passwd file and parses out the different columns. It is
hard coded into the OSQuery binary. While this is a very simple table,
it shares its operation with many other similar tables. Other tables
open similar files, parse them line by line and return each field as
the query’s columns. There are many similar files that contain useful
information on a system. If one was to add a parser for each one in
OSQuery, then they need to write a small amount of code, recompile the
binary and push it out to clients.</p>
<p>Re-deploying new code to endpoints is a difficult task in
practice. There is testing and release processes to
employ. Furthermore if a local modification is made to OSQuery one
needs to submit PRs upstream, otherwise the codebases may diverge and
maintainance would be difficult.</p>
<p>Rather than have a built in plugin for each such table, Velociraptor
simply includes a number of generic parsers which may be reused for
parsing different files. For example, consider the following VQL
Query:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="k">User</span><span class="p">,</span> <span class="k">Desc</span><span class="p">,</span> <span class="n">Uid</span><span class="p">,</span> <span class="n">Gid</span><span class="p">,</span> <span class="n">Homedir</span><span class="p">,</span> <span class="n">Shell</span> <span class="k">FROM</span> <span class="n">parse_records_with_regex</span><span class="p">(</span>
      <span class="n">file</span><span class="o">=</span><span class="ss">"/etc/passwd"</span><span class="p">,</span>
      <span class="n">regex</span><span class="o">=</span><span class="s1">'(?m)^(?P&lt;User&gt;[^:]+):([^:]+):'</span> <span class="o">+</span>
            <span class="s1">'(?P&lt;Uid&gt;[^:]+):(?P&lt;Gid&gt;[^:]+):(?P&lt;Desc&gt;[^:]*):'</span> <span class="o">+</span>
            <span class="s1">'(?P&lt;Homedir&gt;[^:]+):(?P&lt;Shell&gt;[^:\\s]+)'</span><span class="p">)</span>
</pre></div>
</div>
<p>The <span class="docutils literal"><span class="pre">parse_records_with_regex()</span></span> plugin simply applies one or more
regex to a file and each match is sent as a record. In this case, each
line is matched and parsed into its components automatically. Note how
the query produces the same results as OSQuery’s users table, but uses
completely generic parsers.</p>
<p>The generic parser can be used to parse many other file types. Here is query which parses debian apt-source lines:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">parse_records_with_regex</span><span class="p">(</span>
   <span class="n">file</span><span class="o">=</span><span class="ss">"/etc/apt/sources.list"</span><span class="p">,</span>
   <span class="n">regex</span><span class="o">=</span><span class="ss">"(?m)^ *(?P&lt;Type&gt;deb(-src)?) "</span><span class="o">+</span>
         <span class="ss">"(?:\\[arch=(?P&lt;Arch&gt;[^\\]]+)\\] )?"</span> <span class="o">+</span>
         <span class="ss">"(?P&lt;URL&gt;https?://(?P&lt;base_uri&gt;[^ ]+))"</span> <span class="o">+</span>
         <span class="ss">" +(?P&lt;components&gt;.+)"</span><span class="p">)</span>
</pre></div>
</div>
<p>Having the ability to control parsing directly in the query opens up
many possibilities. What if we need to parse new files which do not
have an OSQuery parser yet (maybe an enterprise application
configuration file)? We can easily construct a query using the generic
parsers and issue it to the endpoint to support new file format.</p>
<div class="section" id="id1">
<h2>Velociraptor Artifacts</h2>
<p>In the previous section we saw how we can express very complex queries
to support novel parsing scenarios. However it is hard for users to
directly issue the queries - who can remember this complex regex and
type it in every time?</p>
<p>We clearly need some way to record the queries in a simple, reusable
way. This sounds a lot like GRR’s Artifacts! What if we could just
write the complex query in a YAML file and then just said to
Velociraptor - go collect that artifact and the correct queries would
be issued to the client automatically.</p>
<p>Rather than try to make artifacts generic, we define Velociraptor
Artifacts as YAML files which simply bundle together a bunch of VQL
statements that together run a particular query. In a sense,
Velociraptor’s artifacts are similar to OSQuery’s table definition
(since they specify output columns), except they are defined
completely by the YAML definition file, using generic reusable VQL
plugins, put together with VQL queries.</p>
<p>Here is an example of the the Linux.Sys.Users artifact - this is the
equivalent artifact to OSQuery’s users table:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Linux.Sys.Users</span>
<span class="l l-Scalar l-Scalar-Plain">description</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Get User specific information like homedir, group etc from /etc/passwd.</span>
<span class="l l-Scalar l-Scalar-Plain">parameters</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">PasswordFile</span>
    <span class="l l-Scalar l-Scalar-Plain">default</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/passwd</span>
    <span class="l l-Scalar l-Scalar-Plain">description</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">The location of the password file.</span>
<span class="l l-Scalar l-Scalar-Plain">sources</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">precondition</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
     <span class="no">SELECT OS From info() where OS = 'linux'</span>
    <span class="l l-Scalar l-Scalar-Plain">queries</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">SELECT User, Desc, Uid, Gid, Homedir, Shell</span>
         <span class="l l-Scalar l-Scalar-Plain">FROM parse_records_with_regex(</span>
           <span class="l l-Scalar l-Scalar-Plain">file=PasswordFile,</span>
           <span class="l l-Scalar l-Scalar-Plain">regex='(?m)^(?P&lt;User&gt;[^:]+):([^:]+):' +</span>
                 <span class="l l-Scalar l-Scalar-Plain">'(?P&lt;Uid&gt;[^:]+):(?P&lt;Gid&gt;[^:]+):(?P&lt;Desc&gt;[^:]*):' +</span>
                 <span class="l l-Scalar l-Scalar-Plain">'(?P&lt;Homedir&gt;[^:]+):(?P&lt;Shell&gt;[^:\\s]+)')</span>
</pre></div>
</div>
<p>The artifact has a specific name (Linux.Sys.Users) and a
description. The Artifact will only run if the precondition is
satisfied (i.e. if we are running on a linux system). Running the
artifact locally produces the following output:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="gp">$</span> velociraptor artifacts collect Linux.Sys.Users
<span class="go">+-------------------+-------------------------+-------+-------+--------------------------+</span>
<span class="go">|       USER        |              DESC       |  UID  |  GID  |         HOMEDIR          |</span>
<span class="go">+-------------------+-------------------------+-------+-------+--------------------------+</span>
<span class="go">| root              | root                    |     0 |     0 | /root                    |</span>
<span class="go">| daemon            | daemon                  |     1 |     1 | /usr/sbin                |</span>
<span class="go">| bin               | bin                     |     2 |     2 | /bin                     |</span>
<span class="go">| sys               | sys                     |     3 |     3 | /dev                     |</span>
<span class="go">| sync              | sync                    |     4 | 65534 | /bin                     |</span>
<span class="go">| games             | games                   |     5 |    60 | /usr/games               |</span>
<span class="go">| man               | man                     |     6 |    12 | /var/cache/man           |</span>
<span class="go">| lp                | lp                      |     7 |     7 | /var/spool/lpd           |</span>
<span class="go">| mail              | mail                    |     8 |     8 | /var/mail                |</span>
</pre></div>
</div>
</div>
<div class="section" id="why-would-i-want-to-use-artifacts">
<h2>Why would I want to use Artifacts?</h2>
<p>We just demonstrated that Velociraptor’s artifact produces the same
output as OSQuery’s users table - so what? Why use an artifact over
hard coding the table in the executable?</p>
<p>Velociraptor is inherently a remote endpoint monitoring agent. Agents
are installed on many end points and once installed it is often
difficult to remotely update them. For various reasons, endpoints are
often difficult to upgrade - for example, they might be off the
corporate LAN, or have a broken update agent.</p>
<p>In particular, when responding to a major incident, we often have to
rapidly deploy a new hunt to search for an indicator of compromise. In
most cases we don’t have time to go through proper software deployment
best practice and upgrade our endpoint agent in rapid succession (it
typically takes weeks to have endpoint agents upgraded).</p>
<p>However, Velociraptor’s artifacts allow us to write a new type of
parser immediately since it is just a YAML file with VQL statements,
we can push it immediately to the clients with no code changes,
rebuild, or redeploy scripts. That is very powerful!</p>
<p>Not only can we add new artifacts, but we can adapt artifacts on the
fly to different systems - perhaps there is a slightly different
version of Linux which keeps files in different locations? Or maybe a
slightly different format of the file we are trying to parse. Being
able to adapt rapidly is critical.</p>
</div>
<div class="section" id="so-how-do-i-use-artifacts">
<h2>So how do I use Artifacts?</h2>
<p>Velociraptor exposes artifacts via two main mechanisms. The first is
the Artifact Collector flow. This flow presents a special GUI which
allows us to view the different artifacts, choose which ones we want
to launch and describes them:</p>
<img alt="../../../_images/artifacts_how_to.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/artifacts_how_to.png"/>
<p>As we can see in the screenshot above, the artifact collector flow
allows the user to inspect the artifacts, before issuing the VQL to
the client. The responses are received by the server and displayed as
part of the same flow:</p>
<img alt="../../../_images/artifacts2.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/artifacts2.png"/>
<p>This is a pretty easy set and forget type system. However,
Velociraptor makes artifacts available within any VQL query too. The
artifact simply appears as another VQL plugin. Consider the following
VQL Query that filters only user accounts which have a real shell:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="gp">$</span> velociraptor query --format text <span class="s2">"SELECT * FROM Artifact.Linux.Sys.Users() where Shell =~ 'bash'"</span>
<span class="go">+------+------+------+------+-----------+-----------+</span>
<span class="go">| USER | DESC | UID  | GID  |  HOMEDIR  |   SHELL   |</span>
<span class="go">+------+------+------+------+-----------+-----------+</span>
<span class="go">| root | root |    0 |    0 | /root     | /bin/bash |</span>
<span class="go">| mic  |      | 1000 | 1000 | /home/mic | /bin/bash |</span>
<span class="go">+------+------+------+------+-----------+-----------+</span>
<span class="go">SELECT * FROM Artifact.Linux.Sys.Users() WHERE Shell =~ 'bash'</span>
</pre></div>
</div>
<p>An artifact definition can use other artifacts by simply issuing
queries against these artifact plugins. This forms a natural system of
interdependency between artifacts, and leads to artifact reuse.</p>
<div class="section" id="how-powerful-are-velociraptor-artifacts">
<h3>How powerful are Velociraptor Artifacts?</h3>
<p>Previously we described Velociraptor artifacts as having some
properties in common with GRR’s artifacts (pure YAML, reusable and
server side) and OSQuery’s tables (very detailed and potentially
complex parsers, directly using APIs and libraries). We said that
Velociraptor attempts to replace many of the specific “one artifact
per table” model in OSQuery with a set of YAML files referencing
generic plugins.</p>
<p>Velociraptor’s artifacts can never fully emulate all OSQuery’s tables
because some OSQuery tables call specific APIs and have very complex
operation. However, most of OSQuery’s tables are fairly simple and can
be easily emulated by Velociraptor artifacts. In this sense -
Velociraptor lies somewhere in between GRR’s simple collect all files
and registry keys without parsing them, and OSQuery’s specialized
parsers. However VQL is quite capable, as we shall see. Although we
can not implement all tables using pure VQL queries, the ability to
implement many artifacts this way provides us with unprecedented
flexibility and enables rapid response to evolving threats.</p>
<p>Let’s looks at some artifacts that demonstrate this flexiblity.</p>
</div>
<div class="section" id="parsing-debian-packages">
<h3>Parsing debian packages.</h3>
<p>Debian packages keep a manifest file with records delimited by an
empty line. Each record consists of possible fields.</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/> <span class="o">-</span> <span class="n">LET</span> <span class="n">packages</span> <span class="o">=</span> <span class="k">SELECT</span> <span class="n">parse_string_with_regex</span><span class="p">(</span>
      <span class="n">string</span><span class="o">=</span><span class="n">Record</span><span class="p">,</span>
      <span class="n">regex</span><span class="o">=</span><span class="p">[</span><span class="s1">'Package:\\s(?P&lt;Package&gt;.+)'</span><span class="p">,</span>
             <span class="s1">'Installed-Size:\\s(?P&lt;InstalledSize&gt;.+)'</span><span class="p">,</span>
             <span class="s1">'Version:\\s(?P&lt;Version&gt;.+)'</span><span class="p">,</span>
             <span class="s1">'Source:\\s(?P&lt;Source&gt;.+)'</span><span class="p">,</span>
             <span class="s1">'Architecture:\\s(?P&lt;Architecture&gt;.+)'</span><span class="p">])</span> <span class="k">as</span> <span class="n">Record</span>
      <span class="k">FROM</span> <span class="n">parse_records_with_regex</span><span class="p">(</span>
             <span class="n">file</span><span class="o">=</span><span class="n">linuxDpkgStatus</span><span class="p">,</span>
             <span class="n">regex</span><span class="o">=</span><span class="s1">'(?sm)^(?P&lt;Record&gt;Package:.+?)\\n\\n'</span><span class="p">)</span>
<span class="o">-</span> <span class="k">SELECT</span> <span class="n">Record</span><span class="p">.</span><span class="n">Package</span> <span class="k">as</span> <span class="n">Package</span><span class="p">,</span>
         <span class="n">Record</span><span class="p">.</span><span class="n">InstalledSize</span> <span class="k">as</span> <span class="n">InstalledSize</span><span class="p">,</span>
         <span class="n">Record</span><span class="p">.</span><span class="k">Version</span> <span class="k">as</span> <span class="k">Version</span><span class="p">,</span>
         <span class="n">Record</span><span class="p">.</span><span class="k">Source</span> <span class="k">as</span> <span class="k">Source</span><span class="p">,</span>
         <span class="n">Record</span><span class="p">.</span><span class="n">Architecture</span> <span class="k">as</span> <span class="n">Architecture</span> <span class="k">from</span> <span class="n">packages</span>
</pre></div>
</div>
<p>The above query uses the parse_records_with_regex() plugin to split
the file into records (anything between the Package: and the next
empty line). Each record is then parsed separately using the
parse_string_with_regex() VQL function. Being able to parse in two (or
more) passes makes writing regexes much easier since they can be
simplified greatly.</p>
</div>
<div class="section" id="complex-multi-query-example-chrome-extensions">
<h3>Complex multi-query example: Chrome extensions.</h3>
<p>An example of a sophisticated artifact is the chrome extensions
artifact. It implements the following algorithm:</p>
<ol class="arabic simple">
<li>For each user on the system, locate all chrome extension manifest
files by using a glob expression.</li>
<li>Parse the manifest file as JSON</li>
<li>If the manifest contains a “default_locale” item, then locate the locale message file.</li>
<li>Parse the locale message file.</li>
<li>Extract the extension name - if the extension has default locale
then return the string from the locale file, otherwise from the
manifest file.</li>
</ol>
<p>The full artifact is rather long so will not be listed here in full,
but are a couple of interesting VQL plugins which make writing
artifacts more powerful.</p>
<p>The foreach() plugin runs a query and for each row produced, a second
query is run (with the first row present in the scope). This is
similar to SQL’s JOIN operator but more readable. For example the
following query executes a glob on each user’s home directory (as
obtained from the password file):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">LET extension_manifests = SELECT * from foreach(</span>
<span class="go"> row={</span>
<span class="go">    SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()</span>
<span class="go"> },</span>
<span class="go"> query={</span>
<span class="go">    SELECT FullPath, Mtime, Ctime, User, Uid from glob(</span>
<span class="go">      globs=Homedir + '/' + extensionGlobs)</span>
<span class="go"> })</span>
</pre></div>
</div>
<p>Note how the query is assigned to the variable “extension_manifests”
which can be used as an input to other queries.  The if() plugin
evaluates a condition (or a query) and runs the “then” query if true,
or the “else” query:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">LET maybe_read_locale_file = SELECT * from if(</span>
<span class="go">     condition={</span>
<span class="go">        select * from scope() where Manifest.default_locale</span>
<span class="go">     },</span>
<span class="go">     query={</span>
<span class="go">        SELECT Manifest, Uid, User, Filename as LocaleFilename,</span>
<span class="go">               ManifestFilename, parse_json(data=Data) AS LocaleManifest</span>
<span class="go">        FROM read_file(</span>
<span class="go">                -- Munge the filename to get the messages.json path.</span>
<span class="go">                filenames=regex_replace(</span>
<span class="go">                  source=ManifestFilename,</span>
<span class="go">                  replace="/_locales/" + Manifest.default_locale + "/messages.json",</span>
<span class="go">                  re="/manifest.json$"))</span>
<span class="go">     },</span>
<span class="go">     else={</span>
<span class="go">         -- Just fill in empty Locale results.</span>
<span class="go">         SELECT Manifest, Uid, User, "" AS LocaleFilename, "" AS ManifestFilename,</span>
<span class="go">                "" AS LocaleManifest FROM scope()</span>
<span class="go">     })</span>
</pre></div>
</div>
</div>
<div class="section" id="parsing-binary-data-wtmp-file-parser">
<h3>Parsing binary data: Wtmp file parser.</h3>
<p>It is also possible to parse binary files with VQL. For example,
consider the wtmp file parser implemented in the
Linux.Sys.LastUserLogin artifact. This artifact uses the
binary_parser() VQL plugin which accepts a Rekall style profile string
to instantiate an iterator over the file. Since the wtmp file is
simply a sequence of wtmp structs, we can iterate over them in a
query.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">SELECT * from foreach(</span>
<span class="go">         row={</span>
<span class="go">           SELECT FullPath from glob(globs=split(string=wtmpGlobs, sep=","))</span>
<span class="go">         },</span>
<span class="go">         query={</span>
<span class="go">           SELECT ut_type, ut_id, ut_host as Host, ut_user as User,</span>
<span class="go">                 timestamp(epoch=ut_tv.tv_sec) as login_time</span>
<span class="go">           FROM binary_parse(</span>
<span class="go">                  file=FullPath,</span>
<span class="go">                  profile=wtmpProfile,</span>
<span class="go">                  iterator="Array",</span>
<span class="go">                  Target="wtmp"</span>
<span class="go">                )</span>
<span class="go">         })</span>
</pre></div>
</div>
</div>
<div class="section" id="the-future">
<h3>The future</h3>
<p>We started implementing many of the simpler OSQuery tables using
VQL. For the remaining tables (the ones that need to call out to
libraries or more complex APIs), we will integrate these using a set
of specialized VQL plugins over time.</p>
</div>
</div>
]]></description>
             <pubDate>Mon, 20 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/files_files_everything_is_just_a_file.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/files_files_everything_is_just_a_file.html</guid>
            <title><![CDATA[Files, files everything is just a file!]]></title>
            <description><![CDATA[<h1>Files, files everything is just a file!</h1>
<p>GRR’s original design abstracted the data storage to a simple
key/value store originally based around Bigtable. For open source
deployments various key value stores were used starting from MongoDB,
to SQLite and finally MySQL. Although the original idea was to use a
simple key/value implementation, due to locking requirements the data
store implementation became very complex.</p>
<p>As Velociraptor introduced a major redesign of the underlying data
store architecture, we are now able to relax our demands of the
datastore and use a true key/value model (since we have no
requirements for locking and synchronization). The default data store
is now the FileBasedDataStore which stores all data in flat files.</p>
<div id="more"> </div><p>Using flat files over a database has many advantages, including ease
of deployment, and simplification of the data model. Having flat files
allows one to use standard tools to visualize Velociraptor’s
data structures (e.g. with less), archive old data (e.g. with tar/zip)
and clean up old data (e.g. with find/rm). Velociraptor also includes
an inspect command which allows users to decode the stored files and
provides context as to what these files actually mean. This simplicity
increases the transparency in the system and makes it more accessible
for deployers, while increasing reliability, stability and speed.</p>
<p>In the following section we examine some of the files in the datastore
and see how they relate to the features we discuss elsewhere in this
document.</p>
<div class="section" id="file-organization">
<h2>File organization</h2>
<p>The Velociraptor data store needs to provide only two types of
operations: Read and Write complete files and list files in a
directory. Using only these primitives we can implement the entire
filestore. Most modern file systems provide very fast file creation,
reading and deletion, as well as fast directory listing, even when
containing millions of files. Modern file systems also provide
advanced features like caching, journaling and rollbacks so it is not
such a crazy idea to use the file systems themselves as a data store.</p>
<p>Let’s begin by listing the files in a typical Velociraptor file store
using the find command. We then use the velociraptor inspect command
to view the file’s content.</p>
<div class="section" id="searching">
<h3>Searching</h3>
<p>Searching for clients is implemented by simply creating empty files in
directories based on the search term. For example in order to retrieve
all clients which have the user “mic”, we simply list the directory
“client_index/user%3Amic”:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="gp"> $</span> find ./client_index/
<span class="go">./client_index/c.84216c7aab97557d</span>
<span class="go">./client_index/c.84216c7aab97557d/C.84216c7aab97557d.db./client_index/user%3Amic</span>
<span class="go">./client_index/user%3Amic/C.84216c7aab97557d.db</span>
<span class="go">./client_index/user%3Amic/C.1b0cddfffbfe40f5.db./client_index/all</span>
<span class="go">./client_index/all/C.84216c7aab97557d.db</span>
<span class="go">./client_index/all/C.1b0cddfffbfe40f5.db</span>
</pre></div>
</div>
<p>Modern file systems can hold many thousands of files in the same
directory and list these very quickly. This feature is only really
used in the GUI’s search box but can also be used to script or post
process collected data.</p>
</div>
<div class="section" id="client-information">
<h3>Client information</h3>
<p>Information about each client is kept in a directory based on the
client’s ID:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">./C.0fc63b45671af1a6/ping.db                   &lt;- Last ping stats.</span>
<span class="go">./C.0fc63b45671af1a6/key.db                    &lt;- Client's public key</span>
<span class="go">./C.0fc63b45671af1a6/flows</span>
<span class="go">./C.0fc63b45671af1a6/flows/F.a8787c26.db       &lt;- Flows running on this client.</span>
<span class="go">./C.0fc63b45671af1a6/flows/F.e05952ff.db</span>
<span class="go">./C.0fc63b45671af1a6/tasks</span>
<span class="go">./C.0fc63b45671af1a6/tasks/1533517805834284.db &lt;- Client messages waiting to be collected.</span>
<span class="go">./C.0fc63b45671af1a6/tasks/1533517805834283.db</span>
<span class="go">./C.0fc63b45671af1a6/tasks/1533517206859989.db</span>
<span class="go">./C.0fc63b45671af1a6/tasks/1533517206860477.db</span>
<span class="go">./C.84216c7aab97557d.db                        &lt;- Client information (from Interrogate).</span>
</pre></div>
</div>
<p>Each piece of data is kept in its own file as an encoded
protobuf. Files all have their names end with “.db”. Velociraptor has
an inspect command which decodes the protobuf and displays it in a
human friendly way. For example let us see what information we keep
about each s last poll:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="gp">$</span> velociraptor --config server.yaml inspect /tmp/velociraptor/C.2d406f47d80f5583/ping.db
<span class="go">{</span>
<span class="go">  "ipAddress": "127.0.0.1:33600","ping": "1533517053018582"</span>
<span class="go">}</span>
</pre></div>
</div>
</div>
<div class="section" id="the-flow-s-results">
<h3>The Flow’s results.</h3>
<p>Velociraptor’s flows typically only produce VQL results. As described
above, the VQL results are typically split into parts by the client
(by default 10000 rows per part), and Velociraptor simply writes these
in the flow’s directory:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">./C.1b0cddfffbfe40f5/flows/F.a31255a1</span>
<span class="go">./C.1b0cddfffbfe40f5/flows/F.a31255a1/results</span>
<span class="go">./C.1b0cddfffbfe40f5/flows/F.a31255a1/results/0.db   &lt;- VQL result part 1.</span>
<span class="go">./C.1b0cddfffbfe40f5/flows/F.a31255a1.db             &lt;- Flow information.</span>
</pre></div>
</div>
<p>Velociraptor’s inspect command understands that VQL collections
represent a table of results, and so it displays these in a more
friendly way.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="gp">$</span> velociraptor --config server.yaml inspect /tmp/velociraptor/C.1b0cddfffbfe40f5/flows/F.a31255a1/results/0.db
<span class="go">+-------+----------------+---------+------+-----------------------------+----------------------------+</span>
<span class="go">| ISDIR |    FULLPATH    |  SIZE   | MODE |            MTIME            |            ATIME           |</span>
<span class="go">+-------+----------------+---------+------+-----------------------------+----------------------------+</span>
<span class="go">| false |  /bin/bash     | 1037528 |  493 |  2017-05-16T22:49:55+10:00  |  2018-01-22T12:47:25+10:00 |</span>
<span class="go">| false |  /bin/busybox  | 1964536 |  493 |  2015-08-19T22:07:39+10:00  |  2018-01-23T15:41:46+10:00 |</span>
<span class="go">+-------+----------------+---------+------+-----------------------------+----------------------------+</span>
<span class="go">File Finder Response: SELECT IsDir , FullPath , Size , Mode , mtime , atime , ctime,</span>
<span class="go">   upload(file=FullPath)as Upload FROM files</span>
</pre></div>
</div>
<p>We can also see the original VQL query which was run to produce this
output. The bottom line, though, is that the entire flow’s result is
just a flat JSON encoded file. You can easily decode the data using
any programming language and post process it in whatever way is
appropriate (e.g. export the results to BigQuery or
ElasticSearch). Velociraptor does not really do anything with the
result other than just store it on disk.</p>
</div>
<div class="section" id="the-virtual-file-system">
<h3>The Virtual File System</h3>
<p>As described above, Velociraptor’s VFS consists of VQL tables
for each directory on the client, listing the entire directory
content:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="go">./C.1b0cddfffbfe40f5/vfs/usr/share/doc/gir1.2-freedesktop.db</span>
<span class="go">./C.1b0cddfffbfe40f5/vfs/usr/share/doc/libdatrie1.db</span>
<span class="go">./C.1b0cddfffbfe40f5/vfs/usr/share/doc/dh-strip-nondeterminism.db</span>
<span class="go">./C.1b0cddfffbfe40f5/vfs/usr/share/doc/libcap2-bin.db</span>
<span class="go">./C.1b0cddfffbfe40f5/vfs/usr/share/doc/libsoup2.4-1.db</span>
<span class="go">./C.1b0cddfffbfe40f5/vfs/usr/share/doc/libgphoto2-port12.db</span>
<span class="go">./C.1b0cddfffbfe40f5/vfs/usr/share/doc/libsodium18.db</span>
</pre></div>
</div>
<p>Inspecting each of these shows it is just a simple VQL table. This
particular VFS entry was produced from a recursive directory listing
of /usr (of depth 5).</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span/><span class="gp">$</span> velociraptor --config server.yaml inspect .../vfs/usr/share/doc/libcap2-bin.db
<span class="go">+-------+--------------------------------+---------------------+------+-----------+--------------------</span>
<span class="go">| ISDIR |            FULLPATH            |        NAME         | SIZE |   MODE    |           MTIME</span>
<span class="go">+-------+--------------------------------+---------------------+------+-----------+--------------------</span>
<span class="go">| false | /usr/share/doc/libcap2-bin/REA | README.Debian       | 1149 |       420 | 2015-10-02T23:34:07</span>
<span class="go">|       | DME.Debian                     |                     |      |           |</span>
<span class="go">| false | /usr/share/doc/libcap2-bin/cha | changelog.Debian.gz |   30 | 134218239 | 2015-10-24T07:11:34</span>
<span class="go">|       | ngelog.Debian.gz               |                     |      |           |</span>
<span class="go">| false | /usr/share/doc/libcap2-bin/cop | copyright           | 4367 |       420 | 2015-10-02T23:34:07</span>
<span class="go">|       | yright                         |                     |      |           |</span>
<span class="go">+-------+--------------------------------+---------------------+------+-----------+--------------------</span>
<span class="go">/usr: SELECT IsDir, FullPath as _FullPath, Name, Size, Mode, timestamp(epoch=Sys.Mtim.Sec) as mtime,</span>
<span class="go">  timestamp(epoch=Sys.Atim.Sec) as ys.Ctim.Sec) as ctime FROM glob(globs=path + '/**5')</span>
</pre></div>
</div>
</div>
</div>
]]></description>
             <pubDate>Fri, 10 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/browsing_around_the_filesystem.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/browsing_around_the_filesystem.html</guid>
            <title><![CDATA[Browsing around the filesystem.]]></title>
            <description><![CDATA[<h1>Browsing around the filesystem.</h1>
<p>Browsing the client’s filesystem is probably the first thing
responders do. Both GRR and Velociraptor have a nice VFS abstraction
that allows users to browse files interactively. However, in order to
make Velociraptor much faster we made some tradeoffs and improved the
way that the VFS is stored in the datastore.</p>
<div id="more"> </div><div class="section" id="the-virtual-file-system">
<h2>The Virtual File System</h2>
<p>Like GRR, Velociraptor also maintains a virtual file system view (VFS)
of the client’s filesystem. GRR’s VFS view is generated by adding a
row for each file into the database. In order to refresh the view of a
certain directory, GRR issues a ListDirectory request and updates the
database by storing each newly discovered file in its own row.</p>
<p>Velociraptor models the client’s VFS as a per-directory VQL query. In
order to refresh the view of a certain directory, a new VQL query is
issued to the client, essentially collecting the glob information for
that directory in a single VQL response table. The VQL result is then
stored in a single database row. Therefore Velociraptor stores a
single row per directory (as compared to GRR’s single row per file
approach).  This leads to a huge reduction in database rows.</p>
<p>The tradeoff however, is that the Velociraptor VFS view can only show
the state of the entire directory listing at a single point in
time. GRR’s VFS viewer can show old files (which have been removed)
mixed in with current files because it can merge the output of
different ListDirectory operations that occurred in different
times. We decided this feature was not often useful and sometimes
actually led to confusion since files that are removed from a
directory are shown together with files currently
present. Velociraptor therefore shows the VFS directory at the latest
timestamp the entire directory was fetched.</p>
</div>
<div class="section" id="recursive-vfs-refresh">
<h2>Recursive VFS refresh</h2>
<p>Users who are more familiar with traditional forensic tools (or GUI
file managers like Windows Explorer) usually attempt to browse the
client’s VFS view interactively, searching for files and directories
relevant to the case. However, since the VFS view is only a cached
database view of the real client’s file system, we need to go to the
client to refresh the cache whenever we try to view a directory in the
VFS which had not yet been fetched from the client.</p>
<p>Since clients are not always online, some users attempt to just
recursively refresh the entire VFS view (i.e. recursively list all
client directories from the root). This is however, an expensive
operation (This is at least as expensive as running a recursive “find
/ -ls” command on the commandline). Due to GRR’s extensive data model
and complex multi-round trip flow model, performing a recursive VFS
refresh with GRR is unlikely to work in any reasonable time (typically
the flow will run for a while then hang due to race conditions in the
frontend).</p>
<p>On the other hand, Velociraptor issues a single VQL request as a
recursive directory glob and stores the entire directory content in a
single VQL response taken at an instance in time. The response is
streamed back to the server. The server simply splits the response
table into directory specific tables, and then stores a single VQL
response table for each directory in the database.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The VQL glob() plugin is guaranteed to generate results in breadth
first order. This means that it emits information about all files
in the same directory first, before recursing into sub
directories. This feature makes it simple to split the result table
into directory specific sub-tables by simply watching the FullPath
column and noting when its directory changes.</p>
</div>
<img alt="../../../_images/image9.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image9.png"/>
</div>
<div class="section" id="very-large-vql-queries">
<h2>Very large VQL queries</h2>
<p>While we claimed above that Velociraptor simply issues a single VQL
query and stores its result in a single database row, this was an
oversimplification. If the VQL query generates too many rows, the
Velociraptor client splits the response into parts (by default 10000
rows per part). This allows data to be uploaded immediately to the
server and processed while the query is still executing on the client.</p>
<p>Consider the VFSListDirectoryflow was issued with a glob of <cite>/**10</cite>
(i.e. refresh the entire VFS view from the root directory, recursively
into a depth of 10 directories). The VQL query executed was:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span> <span class="k">AS</span> <span class="n">_FullPath</span><span class="p">,</span>
    <span class="n">Name</span><span class="p">,</span> <span class="k">Size</span><span class="p">,</span> <span class="k">Mode</span><span class="p">,</span>
    <span class="k">timestamp</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">Sys</span><span class="p">.</span><span class="n">Mtim</span><span class="p">.</span><span class="n">Sec</span><span class="p">)</span> <span class="k">AS</span> <span class="n">mtime</span><span class="p">,</span>
    <span class="k">timestamp</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">Sys</span><span class="p">.</span><span class="n">Atim</span><span class="p">.</span><span class="n">Sec</span><span class="p">)</span> <span class="k">AS</span> <span class="n">atime</span><span class="p">,</span>
    <span class="k">timestamp</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">Sys</span><span class="p">.</span><span class="n">Ctim</span><span class="p">.</span><span class="n">Sec</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ctime</span>
<span class="k">FROM</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="s1">'/**10'</span><span class="p">)</span>
</pre></div>
</div>
<p>The query was issued to a Velociraptor client running on a
Chromebook. This particular system has approximately 500k files in its
root filesystem, and so the response consists of 500k rows. However,
as the query executes, the response is split into multiple parts, each
being 10k rows, and uploaded (each part is about 3mb in total).</p>
<img alt="../../../_images/image3.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image3.png"/>
<p>Total execution time for this query is about 4 minutes and consists of
about 50 parts (around 2.5mb each). It is still an expensive query,
but depending on the urgency of the case, it may well be warranted.</p>
<p>It is very convenient to just take a snapshot of the entire
filesystem, especially when the client is offline. We can issue the
flow and then when the client comes back online we can review all the
files.</p>
</div>
<div class="section" id="file-uploads">
<h2>File uploads</h2>
<p>The VFS view is just a local cache in the data store of what is really
going on the client. While we can see the file in each directory we
cant transfer all the file content. Velociraptor represents downloaded
files differently from just listed files. Files with the floppy disk
next to them represent files that we have a local cache for. We can
view the Hexview or just download them.</p>
<p>You can always initiate a download of a VFS file by selecting the
Download tab. Unlike GRR, Velociraptor does not keep previous versions
of files - a re-download will overwrite the previous file.</p>
</div>
]]></description>
             <pubDate>Fri, 10 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/hunting_what_velociraptors_do_best.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/hunting_what_velociraptors_do_best.html</guid>
            <title><![CDATA[Hunting - What Velociraptors do best!]]></title>
            <description><![CDATA[<h1>Hunting - What Velociraptors do best!</h1>
<p>A hunt is a feature where a single flow may be run on multiple clients
at the same time. Typically a hunt looks for a particular indicator of
compromise across the entire deployment, or maybe collect the same
files from every deployed agent. By their nature, hunts cause multiple
flows to run simultaneously and so this creates a large contention of
shared state.</p>
<p>Velociraptor has completely redesigned the way that hunts are
implemented in order to avoid database locking and increase hunt
processing efficiency.</p>
<div id="more"> </div><p>Now we hunt like this:</p>
<img alt="../../../_images/image4.jpg" class="align-center" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image4.jpg"/>
<div class="section" id="how-are-hunts-scheduled">
<h2>How are hunts scheduled?</h2>
<p>GRR allows hunts to be scheduled by a few client properties such as OS
type, label, users etc. This works because GRR has an extensive data
model of endpoint properties. However, this requires that the data
model be refreshed periodically to be kept accurate. For example, to
run a hunt of all machines with a suspected compromised user account
we can schedule the run on all machines where the user has logged in,
but because GRR uses its data model to decide if a machine should be
issued the hunt, the data model may be out of date and GRR will not
schedule the hunt on machines which have only recently been logged
into. For this reason we typically run the Interrogate hunt very
frequently causing a lot of extra load on the system and clients
hoping to minimize the time window where the data model is out of date
with reality.</p>
<p>Velociraptor’s approach is different - since Velociraptor does not
really maintain a data model server side, we check the client’s
information for every hunt, before we even decide if the hunt should
be scheduled for this client. This is done by issuing a VQL query to
the client.</p>
<p>Sometimes we don’t necessarily want the client to know exactly why we
are scheduling the hunt (e.g. in the compromised user account case we
don’t want to advertise the exact username we are looking for). In
these cases we run another VQL query on the server side.</p>
<p>So hunt selection is managed by two different VQL queries - a client
side one and a server side on.</p>
<p>The default client side VQL queries simply collects the usual facts
like OS version, Username etc, while the server side query filters the
results with more specific conditions. This approach does not reveal
to the client the hunt’s condition:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="n">Client</span> <span class="n">side</span> <span class="n">VQL</span><span class="p">:</span>
    <span class="k">SELECT</span> <span class="n">OS</span><span class="p">,</span> <span class="n">Architecture</span><span class="p">,</span> <span class="n">Fqdn</span><span class="p">,</span> <span class="n">Platform</span><span class="p">,</span>
      <span class="n">config</span><span class="p">.</span><span class="n">Client_labels</span> <span class="k">AS</span> <span class="n">Labels</span>
      <span class="k">FROM</span> <span class="n">info</span><span class="p">()</span>

<span class="n">Server</span> <span class="n">side</span> <span class="n">VQL</span><span class="p">:</span>
    <span class="k">SELECT</span> <span class="o">*</span> <span class="k">from</span> <span class="k">rows</span>
      <span class="k">WHERE</span> <span class="n">Fqdn</span> <span class="o">=~</span> <span class="s1">'(?i)myhostname.+'</span> <span class="k">AND</span> <span class="s1">'MY_LABEL'</span> <span class="k">IN</span> <span class="n">Labels</span>
</pre></div>
</div>
</div>
<div class="section" id="the-hunt-s-life-cycle">
<h2>The hunt’s life cycle</h2>
<p>When the hunt is started, the server updates its in-memory list of
active hunts managed by the Foreman. Clients then poll the foreman for
new hunts they should participate in. Clients remember the last hunt
they participated in and so they present this hunt’s timestamp to the
foreman. If a new hunt is available, the foreman can immediately
launch the CheckHuntCondition flow on the client.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The clients themselves are actively keeping track of the hunts they
participated in. This avoids the server having to check the
client’s DB record.</p>
</div>
<p>The CheckHuntCondition flow issues the client side VQL queries and
then runs the server side query on the results. If the query matches
(i.e. the hunt should be scheduled for this client), the client’s
record is written into the hunt’s “pending” queue.</p>
</div>
<div class="section" id="the-hunt-manager">
<h2>The hunt manager</h2>
<p>Each hunt specifies its own client recruitment rate (i.e. how many
clients will be started per minute). The hunt manager is a component
which periodically reads all hunts and schedules flows for these hunts
if the hunts’ client rate allows for more clients to be scheduled. It
does this by moving clients from the pending queue to the running
queue and starting respective flows for them.</p>
<p>Once each of those flows completes, the record is moved from the
running queue to the completed queue or the results queue if the flow
produced any results. We can observe how many clients exist in each
queue using the GUI.</p>
<img alt="../../../_images/image2.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image2.png"/>
<p>The flows that hunts launch arn the client. However, when they
complete, a small record is made in the hunts’s results queue pointing
to the flow. It is therefore possible to retrieve all results from the
hunt from all client’s. For example, the GUI allows downloading a zip
file of all the results and files uploaded:</p>
<img alt="../../../_images/image7.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image7.png"/>
<p>Since hunts invoke regular flows, and Velociraptor flows are much
lighter than GRR’s flows, hunts are much cheaper to run in terms of
resources consumed.</p>
</div>
]]></description>
             <pubDate>Fri, 10 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/interrogation_make_the_endpoint_tell_us_what_it_knows.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/interrogation_make_the_endpoint_tell_us_what_it_knows.html</guid>
            <title><![CDATA[Interrogation - Make the endpoint tell us what it knows!]]></title>
            <description><![CDATA[<h1>Interrogation - Make the endpoint tell us what it knows!</h1>
<p>Interrogation is the process of learning general information about the
endpoint we are monitoring. Each endpoint is automatically
interrogated when it first joins the Velociraptor server, and the GUI
shows this general information about each client.</p>
<p>When writing Velociraptor we decided to keep things very simple - we
did away with a lot of the information gathered during interrogate in
favor of a much simpler data model.</p>
<div id="more"> </div><div class="section" id="data-modelling-the-interrogate-flow">
<h2>Data Modelling - The Interrogate Flow</h2>
<p>GRR maintains an elaborate model of client data. For example, GRR
collects and maintains a list of clients’ network interfaces, users,
user’s home directory etc. This information is maintained in elaborate
protobufs and stored in the database in many rows.</p>
<p>While some of this information is needed for client searching, GRR
maintains vastly more information than necessary in this data
model. The client data model is built during the interrogate phase (A
periodic flow run on the clients to refresh server side data).</p>
<p>Maintaining such a complex data model results in a very rigid
design. For example, if a user wanted to collect more information from
clients they would need to modify protobufs, update the interrogate
flow, recompile the code and redeploy. These modifications are also
very invasive as once code has been heavily modified, there is an
overhead of keeping these modifications in sync with newer upstream
versions.</p>
<p>Velociraptor also maintains client information via its Interrogate
flow. However, Velociraptor’s interrogate flow simply issues a series
of VQL queries, and these responses are stored directly in the
database with minimal interpretation. Indexes are maintained for some
information which users should be able to search on, but there is no
attempt to build or maintain a client data model at all (You can see
details of the model described below in the FileBaseDataStore post).</p>
<p>The advantage of this approach is that users can simply add extra VQL
queries to the interrogate phase to collect more tailored site
specific information. This does not require compiling of any code or
redeploying the server. The following example illustrates the power of
this technique.</p>
</div>
<div class="section" id="customizing-the-interrogate-flow">
<h2>Customizing the Interrogate flow.</h2>
<p>Normally Velociraptor collects minimal information from the client
upon interrogation (i.e. when the client first enrols or when
interrogated periodically). However it is very easy to customize this
collection depending on local site requirements. In this section we
work through a step by step example of extending the Velociraptor
interrogate flow.</p>
<p>Suppose that in our deployment we wanted to check if a machine is able
to be logged into remotely. For a Linux machine we want to see all
authorized_keys files on every machine that enrolls. Collecting this
information allows us to quickly see which machines a compromised user
account could spread to.</p>
<p>We know we need to issue a VQL query but we are not 100% sure which
one. Luckily we can use Velociraptor itself to run the query locally
using the syntax “velociraptor query &lt;query&gt;”.</p>
<p>Start with a simple glob query to find all authorized_keys files:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/home/*/.ssh/authorized_keys"</span><span class="p">)</span>
</pre></div>
</div>
<p>Suppose we now want to actually grab a copy of all files so we can
archive them on the server This will keep a record of the authorized
keys on the server for each Interrogate flow. If we run the flow
periodically we will end up with a time based evolution of the
authorized keys files on each host. Pretty handy!</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span><span class="p">,</span>
   <span class="k">timestamp</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">Sys</span><span class="p">.</span><span class="n">Mtim</span><span class="p">.</span><span class="n">Sec</span><span class="p">)</span> <span class="k">as</span> <span class="n">Mtime</span><span class="p">,</span>
   <span class="n">upload</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">FullPath</span><span class="p">)</span> <span class="k">as</span> <span class="n">Upload</span>
<span class="k">FROM</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/home/*/.ssh/authorized_keys"</span><span class="p">)</span>
</pre></div>
</div>
<p>We can run the query locally using the Velociraptor tool:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span/>mic@localhost:/tmp&gt; velociraptor query <span class="s2">"select FullPath, \</span>
<span class="s2">   timestamp(epoch=Sys.Mtim.Sec) as Mtime, \</span>
<span class="s2">   upload(file=FullPath) as Upload \</span>
<span class="s2">   FROM glob(globs=['/home/*/.ssh/authorized_keys'])"</span>

velociraptor: Uploaded home/mic/.ssh/authorized_keys <span class="o">(</span><span class="m">395</span> bytes<span class="o">)</span>
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">"FullPath"</span>: <span class="s2">"/home/mic/.ssh/authorized_keys"</span>,
  <span class="s2">"Mtime"</span>: <span class="s2">"2018-08-03T18:20:19+10:00"</span>,
  <span class="s2">"Upload"</span>: <span class="o">{</span>
    <span class="s2">"Path"</span>: <span class="s2">"home/mic/.ssh/authorized_keys"</span>,
    <span class="s2">"Size"</span>: <span class="m">395</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p>Velociraptor’s query command enables us to run the query directly on
the local host and observe the results. When the same query is issued
to the Velociraptor client, the same result will be generated and sent
to the server. This enables us to interactively develop and test our
queries without needing to run a full client/server.</p>
<p>Note the upload() VQL function which causes the file to be uploaded to
the server. (When run locally the file will be copied to the upload
directory as can be seen by the upload confirmation message), but when
run within the Velociraptor client, the file will be uploaded to the
server and stored within the flow.</p>
<p>We can now add the query to all Interrogate flows that will be run
from now on. We simply add it to the configuration file under the
Interrogate.additional_queries key:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">Interrogate.additional_queries</span><span class="p p-Indicator">:</span>
 <span class="l l-Scalar l-Scalar-Plain">Query</span><span class="p p-Indicator">:</span>
   <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">Name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Authorized Keys</span>
     <span class="l l-Scalar l-Scalar-Plain">VQL</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">&gt;</span>
       <span class="no">select FullPath, timestamp(epoch=Mtime.Sec) as Mtime,</span>
       <span class="no">upload(file=FullPath) as Upload</span>
       <span class="no">from glob(globs='/home/*/.ssh/authorized_keys')</span>
</pre></div>
</div>
<p>From now on the additional query will be recorded for all clients. The
GUI shows it in the client information page:</p>
<img alt="../../../_images/image6.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image6.png"/>
</div>
]]></description>
             <pubDate>Fri, 10 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/design_differences_between_velociraptor_and_grr.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/design_differences_between_velociraptor_and_grr.html</guid>
            <title><![CDATA[Design differences between Velociraptor and GRR]]></title>
            <description><![CDATA[<h1>Design differences between Velociraptor and GRR</h1>
<p>One of the main motivators for developing Velociraptor is the
opportunity to try different approaches than GRR. Velociraptor has a
number of fundamental design differences in contrast with the GRR
design which improve overall performance and scalability.  We tried to
keep it light weight cutting out the features we think we did not need
and leaving behind a fast, lean and mean raptor!</p>
<div id="more"> </div><div class="section" id="velociraptor-clients-run-full-vql-queries">
<h2>Velociraptor Clients run full VQL queries</h2>
<p>GRR’s design started off with the assumption that the client should be
minimalist and only support a few simple primitives (such as
ListDirectory, ListProcesses etc). The intention was that most of the
processing would be executed on the server inside a “Flow”. The main
motivation for this design choice was the observation that it is
difficult to upgrade the client in practice, and so with a minimal
client, it would be possible to develop more sophisticated Flows,
server side, without needing to update the clients.</p>
<p>After running GRR for a while we noticed that this design choice was
problematic, since it leads to many client round trips. For example
the FileFinder flow searches the client’s filesystem for files by
name, date etc. GRR’s original file finder uses a complex algorithm to
issue ListDirectory requests to the client, receive their responses,
filter and recurse into directories by communicating with the client
again. This leads to many round trips and has a huge performance hit
on both the server and client.</p>
<p>Velociraptor does away with all that by including rich client side
functionality (through VQL plugins), and implementing VQL queries to
perform the filtering. This means that in reality, Velociraptor has
very few client round trips, generally just one: The VQL query is sent
to the client, and the result is received by the server.</p>
<p>Some types of analysis require the results of one operation to feed
into the next operation. For example, suppose we wanted to upload all
executables that are run from a temp directory. This requires listing
all processes, then filtering the ones running from a temp directory,
and finally uploading those to the server.</p>
<p>GRR’s model requires writing a new flow for this - the flow first
issues a ListProcesses request to the client, then receives all
processes where the filtering happens on the server. The server then
issues upload commands for each matching process. Performing this
analysis requires writing and deploying new code making it difficult
to adapt rapidly to changing threats.</p>
<p>With Velociraptor one simply issues the following VQL query:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="n">LET</span> <span class="n">files</span> <span class="o">=</span> <span class="k">SELECT</span> <span class="n">Exe</span><span class="p">,</span> <span class="n">Cmdline</span><span class="p">,</span> <span class="n">Username</span> <span class="k">FROM</span> <span class="n">pslist</span><span class="p">()</span>
        <span class="k">WHERE</span> <span class="n">Exe</span> <span class="o">=~</span> <span class="s1">'(?i)temp'</span>
<span class="k">SELECT</span> <span class="n">Exe</span><span class="p">,</span> <span class="n">Cmdline</span><span class="p">,</span> <span class="n">Username</span><span class="p">,</span> <span class="n">upload</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">Exe</span><span class="p">)</span> <span class="k">AS</span> <span class="n">Upload</span>
  <span class="k">FROM</span> <span class="n">files</span>
</pre></div>
</div>
<p>VQL avoids this round trip completely, since VQL queries can be nested
and chained together. Therefore one simply runs the first query (list
all processes running from temp directory), and sends the results to
the next query (download the matching files) inside the same VQL
client request. It is rare that Velociraptor flows run multiple client
round trips, resulting in lightweight and fast completing flows.</p>
</div>
<div class="section" id="worker-and-database-queues">
<h2>Worker and Database queues.</h2>
<p>The GRR model of long running flows with multiple client/server
interactions required more complex design. Since client messages can
be delivered in multiple POST requests, and a single request can
result in multiple responses, GRR must queue responses somewhere until
they are all ready to be processed. Otherwise writing GRR flows would
be difficult because one would need to account for incomplete
responses.</p>
<p>GRR uses a complex request/response protocol to ensure messages are
delivered in order, reminiscent of the TCP stack’s packet reassembling
algorithms.</p>
<p>Consider the simple request “ListDirectory”. The client request may
elicit thousands of responses (one for each file) and may span
multiple POST operations. The GRR frontend queues all the responses in
the database until it receives a STATUS response, and then fet
once. So even if the client sends the responses over multiple packets,
the flow only sees a single list. When a status message is seen by the
frontend, it notifies the worker via a worker queue, which collects
all responses, orders them by response ID and delivers to the flow
object.</p>
<p>This design is necessary if flows are long lived and need to handle
thousands of responses for each request. However in practice this
design has a couple of serious problems:</p>
<ol class="arabic simple">
<li>The frontend receives responses and just writes them into the
database in special queue rows, then the worker reads them from the
queue rows for processing (after which they must be deleted from
the database). This leads to a lot of unnecessary read/write/delete
cycles and extra load on the database.</li>
<li>The worker queue rows are used by all clients and all flows. This
leads to a lot of database contention on these rows. Extra care
must be taken to ensure no race conditions, through careful
management of database locks. Extra locks slow down the database
and typically for a busy system queue contention is a huge
bottleneck.</li>
</ol>
<p>This is easy to observe in practice on a busy GRR system (i.e. one
that is running many flows or hunts) by simply looking at the output
from top. Typically the mysql process uses as much CPU or more than
the frontends and workers combined. This indicates a huge load on the
database and limits scalability. Increasing the number of frontends
only helps marginally because the database throughput becomes the
limiting factor. In fact, increasing the number of workers can
deteriorate performance because workers poll on their queues while
holding locks thereby increasing row lock contention even more.</p>
<p>Velociraptor takes a different approach. Since Velociraptor flows are
very simple and typically only consist of a few request/response
cycles, the server does not bother to reorder replies that come in
different packets. Therefore there is no need to temporarily store or
queue responses. Responses can be delivered to the flow as soon as
they are received - and flows typically just write them to the
database in their final storage location.</p>
<p>Therefore Velociraptor does not have a dedicated worker, nor does it
have database queues. The frontend itself runs the flows directly on
the received packets while serving the client’s poll request. This
completely eliminates the need for worker queues and their associated
database contention issues. Removing the worker queues eliminates a
significant amount of very complex and delicate code. Additionally,
since the responses are not written/read to the queue, the total load
on the database is significantly reduced. (In fact because database
lock contention is so low, Velociraptor can work very well with plain
files through the FileBaseDataStore, even at large scale!)</p>
<p>The following illustration demonstrates how significant this is for
the simple example of a ListDirectory request of a directory with 1000
files in it (e.g. the c:windows directory). The equivalent VQL is
<cite>select * from glob(paths=’c:/windows/*’)</cite> and only produces a single
response packet containing all the files in the one table, whereas
GRR’s ListDirectory client action produces a single response for each
file, which is then queued and stored independently in the database.</p>
<p>The overall effect, in the GRR case, is that 2000 database rows are
created, of which 1000 rows are immediately deleted - a significant
database load. Compare this with the Velociraptor equivalent flow -
the VQL request is sent to the client once, then the response is
returned to the frontend in a single POST operation. Since
Velociraptor does not have a separate worker and does not need to
queue messages to it, the frontend immediately runs the flow which
just writes the result into a single DB row - total database
operations: 1 row written.</p>
<img alt="../../../_images/image1.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image1.png"/>
<p>Eliminating the need for a separate worker process also simplifies
deployment significantly. GRR needs to deploy separate frontends and
worker processes, and it is often difficult to know which one to scale
up. Scaling up the frontend will allow more packets to be received but
actually increases the load on the database. Not having sufficient
workers will leave many requests on the queue for a long time and will
prolong the execution of the flow since a worker must run the flow in
order to issue the next set of requests. This leads to flows which
take many hours to complete and even hung flows (if the client reboots
or disconnects before the flow finished).</p>
<p>Velociraptor deployment is much simpler - there is only a single
binary and it can be scaled and load balanced as needed. Since
database load is much lower, the frontend can handle a much larger
load. Furthermore, the flows typically execute in very short time
(since there is only one round trip). The overall result is that flow
throughput is much increased and resource usage is reduced.</p>
</div>
]]></description>
             <pubDate>Fri, 10 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/the_velocidex_query_language.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/the_velocidex_query_language.html</guid>
            <title><![CDATA[Velocidex Query Language (VQL)]]></title>
            <description><![CDATA[<h1>Velocidex Query Language (VQL)</h1>
<p>Velociraptor is powered by VQL and VQL is the killer feature which
makes it so powerful. But what exactly is VQL? This section is a quick
overview of VQL.</p>
<div id="more"> </div><div class="section" id="vql-overview">
<h2>VQL Overview</h2>
<p>VQL is only loosely based around SQL in the sense that the general
statement structure is similar. However, VQL is a very simple
dialect. Like SQL, a VQL query produces a table of results with
specific columns and multiple rows. Unlike SQL, the data inside each
cell is not limited to simple primitive types (like string, integer
etc). In fact any JSON serializable object can be generated in a
table’s cell. It is not uncommon to generate an entire JSON
object with additional fields in each row for a single column.</p>
<p>The basic structure of a VQL statement is:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">Column1</span><span class="p">,</span> <span class="n">Column2</span><span class="p">,</span> <span class="n">Column3</span> <span class="k">from</span> <span class="n">plugin</span><span class="p">(</span><span class="n">arg</span><span class="o">=</span><span class="n">value</span><span class="p">)</span> <span class="k">WHERE</span> <span class="n">Column1</span> <span class="o">&gt;</span> <span class="mi">5</span>
</pre></div>
</div>
<p>There are three main parts: Column selectors, Plugin and Filter Conditions.</p>
<div class="section" id="plugins">
<h3>Plugins</h3>
<p>The VQL plugin is VQL’s data source. Plugins are specific pieces of
code which may accept arguments and generate a sequence of rows. VQL’s
strength is that these plugins are very easy to write and can be added
to Velociraptor in order to add extra functionality.</p>
<p>Unlike SQL, VQL plugins take keyword arguments. This allows
Velociraptor plugins to be easily customizable and adaptable. For
example, a plugin may list all chrome extensions, and receive an
argument pointing it to the user’s home directory so it can flexibly
be applied to different situations. The ability to provide arguments
to plugins encourages writing more generic plugins which can be reused
in multiple situations.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">VQL plugins currently only accept keyword arguments. It is a syntax
error to pass args without naming them - <cite>glob(“/bin/*”)</cite> is not
valid syntax, it should be <cite>glob(globs=”/bin/*”)</cite></p>
</div>
<p>It is important to appreciate that Plugins generate data
dynamically. The data is not stored in a database table first! Plugins
may begin generating data immediately and the VQL query will begin
processing this data, even if the total amount of data is very
large. The Plugin’s data is not stored in memory all at once!  This
allows for plugins to produce an unbounded number of rows and the
query will proceed until the required number of results is achieved.</p>
<p>Plugins may also be cancelled when the query completes, even if the
plugin itself is not exhausted.</p>
</div>
<div class="section" id="column-selectors">
<h3>Column selectors</h3>
<p>The Column selectors are a group of expressions specifying which
columns will be produced in the output table. As mentioned previously,
the values produced in each column are not limited to simple types -
it is common to produce entire JSON objects (and even additional
tables), lists of values etc.</p>
<p>The column selectors specify a transformation to be performed on the
output of the plugin in producing the query’s columns. The simplest
transformation is a single “*”, which means no transformation at all
(i.e. relay to the output table exactly the output of the plugin).</p>
<p>Since plugins may produce any object (for example, a JSON object with
nested fields), VQL column specifications can dereference nested
fields within the produced data.</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">Sys</span><span class="p">.</span><span class="n">Mtim</span><span class="p">.</span><span class="n">Sec</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span>
</pre></div>
</div>
<p>Specifying only selected columns can limit the number of columns
produced and make the output more useful by removing unneeded
fields. For example the following will produce a result table with two
columns named FullPath and SIze and a row per file found in the /bin/
directory:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span><span class="p">,</span> <span class="k">Size</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span>
</pre></div>
</div>
<p>Column specifications can consist of arbitrary expressions - for
example addition, comparisons:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span> <span class="o">+</span> <span class="s1">'.bindir'</span><span class="p">,</span> <span class="k">Size</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">Size</span> <span class="o">&lt;</span> <span class="mi">1000</span>
</pre></div>
</div>
<p>In this case it is often useful to add a Column Alias (Note that
column aliases can also be used in the WHERE clause):</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span> <span class="o">+</span> <span class="s1">'.bindir'</span> <span class="k">as</span> <span class="n">Santized</span><span class="p">,</span> <span class="k">Size</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span>
</pre></div>
</div>
<p>VQL Functions provide a way to extend VQL expressions. Unlike full
plugins they do not produce a sequence of rows, but simply produce a
single value (which can be an arbitrary o function formats a timestamp
as a string. This is useful since many plugins produce times in
seconds since epoch time:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span><span class="p">,</span> <span class="k">timestamp</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">Sys</span><span class="p">.</span><span class="n">Mtim</span><span class="p">.</span><span class="n">Sec</span><span class="p">)</span> <span class="k">as</span> <span class="n">mtimefrom</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Some VQL functions have side effects, or are more expensive to
run. It is important to understand that VQL transforms the columns
emitted from a plugin BEFORE it applies filtering conditions. This
is needed in order to allow for column transformations to
participate in the filter condition (via the alias).</p>
<p>Due to this order of operations the following query will upload all
files, ignoring the WHERE condition because the upload() function
will be evaluated on each row, even if the WHERE clause causes the
row to be ignored:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span><span class="p">,</span> <span class="n">upload</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">FullPath</span><span class="p">)</span>
 <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span>
      <span class="k">WHERE</span> <span class="n">Name</span> <span class="o">=~</span> <span class="ss">"bash"</span>
</pre></div>
</div>
<p>To upload only the files matching the expression, the query must be
split into two - the first query applies the filtering condition
and the second query does the upload:</p>
<div class="last highlight-sql notranslate"><div class="highlight"><pre><span/><span class="n">LET</span> <span class="n">files</span> <span class="o">=</span> <span class="k">SELECT</span> <span class="n">FullPath</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span>
    <span class="k">WHERE</span> <span class="n">Name</span> <span class="o">=~</span> <span class="ss">"bash"</span>
<span class="k">SELECT</span> <span class="n">FullPath</span><span class="p">,</span> <span class="n">upload</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">FullPath</span><span class="p">)</span> <span class="k">from</span> <span class="n">files</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="vql-subselects">
<h3>VQL Subselects</h3>
<p>Unlike SQL, VQL does not have a join operator. SQL is designed to work
with databases, and databases have multiple strategies for optimizing
query execution (like adding table indexes, query planners
etc). Traditionally, SQL authors prefers joins over subselects because
in a real database JOIN operations are more optimized to use the
database’s indexes and query optimizer. However JOIN operations are
arguably harder to read and it is hard to predict the order at where
operations will be run (e.g. which table will use an index and which
will use a row scan).</p>
<p>Since VQL has no indexes nor does it have a query optimizer,
implementing JOIN operations does not make sense. Instead, VQL
implements subselects and multi-statement queries and using these
tools it is possible for VQL authors to precisely control the query
execution plan so it is most efficient.</p>
<p>In this sense VQL authors are left to specify the most efficient
course of query execution themselves instead of relying on a query
optimizer. This is normally done by dividing the query into smaller
queries and combining their results in the best order.</p>
<p>Consider the following query that attempts to search small files for
the keyword “foobar”:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span> <span class="k">where</span>
   <span class="n">grep</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">FullPath</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="ss">"foobar"</span><span class="p">])</span> <span class="k">and</span> <span class="k">Size</span> <span class="o">&lt;</span> <span class="mi">1000</span>
</pre></div>
</div>
<p>Velociraptor will execute the following steps:</p>
<ol class="arabic simple">
<li>Run the glob() plugin to produce all the files in the /bin/ directory</li>
<li>Transform each row to produce the FullPath.</li>
<li>Evaluate the Filter condition on each row. The filter condition
requires running the grep() plugin on each file looking for the
keyword and evaluating if the SIze of the file is less than 1000.</li>
<li>If both conditions are TRUE then Velociraptor will emit the row into the result table.</li>
</ol>
<p>It is obvious that this is an inefficient query because each and every
file will be searched for the keyword regardless of its size. However,
there is no point even trying if the file size is not less than 1000
bytes!</p>
<p>The problem here is that there are two conditions which both must be
true - but each condition has a different cost associated with
it. Clearly the grep() condition is more expensive since it requires
opening the file and reading it completely. The Size condition is
extremely cheap since it is just an integer comparison.</p>
<p>However, VQL is not aware of the relative cost of the two conditions -
it does not know that grep() is inherently an expensive operation
since to VQL it just looks like another function. Although VQL does
some shortcutting (for example it will cancel the grep() function if
Size &gt;= 1000) this shortcut cancellation may arrive too late to stop
grep() from doing a significant amount of work. The VQL author must be
aware of the relative costs of the different operations and how the
query should be structured for maximum efficiency.</p>
<p>What we would really like is for VQL to evaluate the cheap condst, and
only for those files smaller than 1000 bytes, evaluate the grep()
condition. This allows us to eliminate most files immediately (since
most files are larger than 1000 bytes) such that we only bother to
grep() very few files.</p>
<p>This can be achieved by splitting the query into two and chaining them
together:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="n">LET</span> <span class="n">file</span> <span class="o">=</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">Size</span> <span class="o">&lt;</span> <span class="mi">1000</span>

<span class="k">SELECT</span> <span class="n">FullPath</span> <span class="k">from</span> <span class="n">file</span> <span class="k">WHERE</span> <span class="n">grep</span><span class="p">(</span>
   <span class="n">path</span><span class="o">=</span><span class="n">FullPath</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="ss">"foobar"</span><span class="p">])</span>
</pre></div>
</div>
<p>The LET keyword allows us to define a “stored query”. A Stored Query
is a query which is assigned into a variable name - you can think of
the statement as running the entire query and storing the output into
a single variable.</p>
<p>The second query then takes the result of this query and applies
further transformations and filtering on it. By ensuring that the
cheap conditions are evaluated in the stored query, we can ensure that
the number of rows stored in the LET expression is smaller than the
total number of rows produced by the glob() plugin, and therefore the
grep() function will be applied on few rows.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can think of stored queries as running in multiple steps: First
the LET query is executed, then all its rows are stored in the
files variable, while the second query reads each row and applies
its own filtering on it. In reality though, the LET query is lazy
in its evaluation and will only produce results when
required. Velociraptor does not store the entire result table of
the LET query in memory at once! It is quite safe therefore to run
a very large query in the LET clause without fear of memory
overrun.</p>
</div>
</div>
<div class="section" id="escaping-parameters">
<h3>Escaping parameters</h3>
<p>VQL queries often need to take user input. For example consider the
query:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="ss">"/bin/*"</span><span class="p">)</span>
</pre></div>
</div>
<p>We might want to allow the user to specify the glob expression and
create the query programmatically. While it is possible to ensure user
input is escaped this is inefficient and tedious.</p>
<p>VQL queries have an “Environment”. The Environment is essentially the
evaluation scope of the query - in other words it contains all the
values which can be accessed by name. For example when we call a VQL
function like timestamp(), it is placed in the evaluation scope. It is
possible to place anything in the environment (or the evaluation
scope) and in particular, user parameters can also be placed there. In
this case there is no need to escape user input as it is treated as a
part of the environment and not the query. For example placing
<cite>PATH=”/bin/*”</cite> into the environment, will allow the following query to
run successfully:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span/><span class="k">SELECT</span> <span class="n">FullPath</span> <span class="k">from</span> <span class="n">glob</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p>You should always try to write VQL queries referring to parameters in
the environment because this makes them reusable - the scope
parameters become inputs to your query and the query becomes a
reusable function.</p>
</div>
</div>
]]></description>
            <category><![CDATA[ Design ]]></category>
             <pubDate>Fri, 10 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
        <item>
            <link>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/introducing_velociraptor.html</link>
            <guid>https://docs.velociraptor.velocidex.com/blog/html/2018/08/10/introducing_velociraptor.html</guid>
            <title><![CDATA[Introducing Velociraptor]]></title>
            <description><![CDATA[<h1>Introducing Velociraptor</h1>
<div class="section" id="hunting-and-responding-like-a-raptor">
<h2>Hunting and responding like a raptor!</h2>
<p>At Velocidex we have been running open source endpoint monitoring
tools for our clients in order to detect and respond to incidents.
One of our favorite tools is GRR, developed by Google internally and
then released as open source. GRR is a very powerful tool, with a
polished UI and good documentation.</p>
<p>Unfortunately the open source version released by Google suffers from
some shortcomings and so we have decided to develop a new project,
built on the shoulders of giants called Velociraptor.</p>
<div id="more"> </div><p>These are Velociraptor’s design goals:</p>
<blockquote>
<div><ul class="simple">
<li>Focus on data collection. Velociraptor’s primary use case is to
collect data and export it to other systems. Velociraptor does no
analysis itself and therefore has no need for a complex data model.</li>
<li>Flexibility - Velociraptor can adapt easily to new requirements
without needing to redeploy either clients or servers. Using VQL
(Velocidex Query Language) provides flexibility in the type and
number of queries that are used to rapidly adapt to changing
requirements. VQL allows us to collect just the information needed
and no more in an adaptive way.</li>
<li>Remove abstractions. Velociraptor aims to be as simple to
understand as possible. The default data store simply stores files
in the file system which may be easily inspected by the user. No
special tooling is required to script or manage Velociraptor.
Reduce demand on the data store. Rather than increase the data
store requirements, we want to simplify the design to the point
that requirements on the data store are so low, one can run a
medium to large sized deployment with very few resources (down to
perhaps a single server machine). In fact the default data store
does not even use a database, but simply uses flat files.</li>
<li>Simplify everything!  Velociraptor aims to be very simple to run
and administer. We remove a lot of the GRR functionality that we
dont find we use often. Velociraptor ships as a single, statically
linked executable which can perform all actions necessary for
deployers.</li>
</ul>
</div></blockquote>
<p>In short we really wanted something like this:</p>
<img alt="../../../_images/image5.png" class="align-center" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image5.png"/>
</div>
<div class="section" id="quick-start">
<h2>Quick Start</h2>
<p>In this section we go through a typical deployment scenario of
Velociraptor.</p>
<div class="section" id="download-the-binary">
<h3>Download the binary</h3>
<p>Velociraptor ships as a single statically compiled binary. It has no
external dependencies and does not require installing as a
package. Simply download the binary from the release page for the OS
you will be deploying on. The same binary is used for the client and
the server.</p>
</div>
<div class="section" id="generate-a-configuration-file">
<h3>Generate a configuration file</h3>
<p>Velociraptor needs a configuration file to start serving requests. You
can generate a new configuration file using the velociraptor config
generate command. Note that this prints a new configuration into
stdout so you might want to redirect it into a new file (NOTE: The
file contains key material so ensure it has appropriate
permissions). Below we highlight the parameters you will probably want
to change:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">$ velociraptor config generate | tee /etc/velociraptor.config.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">Client</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">server_urls</span><span class="p p-Indicator">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">http://localhost:8000/</span>
  <span class="l l-Scalar l-Scalar-Plain">writeback_linux</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/velociraptor.writeback.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">writeback_windows</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/Program Files/Velociraptor/velociraptor.writeback.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">Datastore</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">filestore_directory</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/tmp/velociraptor</span>
  <span class="l l-Scalar l-Scalar-Plain">implementation</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">FileBaseDataStore</span>
  <span class="l l-Scalar l-Scalar-Plain">location</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/tmp/velociraptor</span>
<span class="l l-Scalar l-Scalar-Plain">Frontend</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">bind_address</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">127.0.0.1</span>
  <span class="l l-Scalar l-Scalar-Plain">bind_port</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">8000</span>
<span class="l l-Scalar l-Scalar-Plain">GUI</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">bind_address</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">127.0.0.1</span>
  <span class="l l-Scalar l-Scalar-Plain">bind_port</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">8889</span>
</pre></div>
</div>
<p>The configuration file contains default values for most settings and
new keys for cryptographic material so it is expected that you edit
the file to customize it for your local deployment. The config file is
divided into sections. Here is a quick overview:</p>
<ul class="simple">
<li>The Client section is used to configure clients.<ul>
<li>Server_urls is a list of URLs the client will attempt to connect
to. If a connection to one fails it will try the others
repeatedly. It is wise to include several URLs here or at least a
DNS name so the server may be easily t just use a single IP
address here). This will usually be different from Frontend bind
address in a proper deployment but for testing it may be the same.</li>
<li>Writeback: The writeback path is where clients will write their
local persistent state (for example, their private keys). You can
specify a different location for windows, osx and linux clients.</li>
</ul>
</li>
<li>The Datastore section specifies where to store the data for the
server. Be sure to update the location to a more permanent
path. The filestore_location is a path that receives uploaded
files which may be large.</li>
<li>The Frontend is the server component which receives poll messages
from clients. It should be exposed to the internet on a public
interface so clients may reach it. This section also contains the
server’s certificate as signed by the CA (you can rotate server keys
using the velociraptor config rotate_keys command.</li>
<li>The GUI is the Velociraptor web admin UI. Do not expose this on a
public interface without enabling TLS! We recommend to only enable
it on the loopback interface and use SSH tunneling to access it over
HTTP.server</li>
</ul>
</div>
<div class="section" id="client-configuration">
<h3>Client configuration</h3>
<p>Clients receive a subset of the complete configuration which enables
them to connect to the server. You can extract the client’s
configuration using the <cite>velociraptor config client</cite> command.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span/><span class="l l-Scalar l-Scalar-Plain">$ velociraptor --config /etc/velociraptor.config.yaml config client</span>
<span class="l l-Scalar l-Scalar-Plain">Client</span><span class="p p-Indicator">:</span>
 <span class="l l-Scalar l-Scalar-Plain">ca_certificate</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">|</span>
   <span class="no">-----BEGIN CERTIFICATE-----</span>
   <span class="no">MIIDIDCCAgigAwIBAgIQEPaF6CPMLOlixEmpgHhvsTANBgkqhkiG9w0BAQsFADAa</span>
   <span class="no">abIwLMojhIxVFXZOZ0p2ZhYkeKJwNGbiA9rBJR2iKxeJOa0B</span>
   <span class="no">-----END CERTIFICATE-----</span>

 <span class="l l-Scalar l-Scalar-Plain">nonce</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">UwtTRfezXIU=</span>
  <span class="l l-Scalar l-Scalar-Plain">server_urls</span><span class="p p-Indicator">:</span>
 <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">http://localhost:8000/</span>
  <span class="l l-Scalar l-Scalar-Plain">writeback_linux</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/velociraptor.writeback.yaml</span>
 <span class=" -Error"> </span><span class="l l-Scalar l-Scalar-Plain">writeback_windows</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/Program Files/Velociraptor/velociraptor.writeback.yaml</span>
</pre></div>
</div>
</div>
<div class="section" id="running-the-server">
<h3>Running the server</h3>
<p>Start the server using the frontend command:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span/>$ velociraptor --config velociraptor.config.yaml frontend

INFO:2018/08/08 <span class="m">15</span>:39:09 Launched gRPC API server on <span class="m">127</span>.0.0.1:8888
INFO:2018/08/08 <span class="m">15</span>:39:09 GUI is ready to handle requests at <span class="m">127</span>.0.0.1:8889
INFO:2018/08/08 <span class="m">15</span>:39:09 Frontend is ready to handle client requests at <span class="m">127</span>.0.0.1:8000
</pre></div>
</div>
<p>You can now verify the server is working by connecting to the GUI with
a web browser:</p>
<img alt="../../../_images/image10.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image10.png"/>
</div>
<div class="section" id="running-the-client">
<h3>Running the client</h3>
<p>The client is run using the s configuration</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span/>$ velociraptor --config /etc/velociraptor.client.config.yaml client
velociraptor: error: Unable to load writeback file: open /etc/velociraptor.writeback.yaml: no such file or directory
Genering new private key....
Wrote new config file  /etc/velocirpator.writeback.yaml
INFO:2018/08/08 <span class="m">16</span>:02:22 Starting Crypto <span class="k">for</span> client C.039f18494e6dae95
INFO:2018/08/08 <span class="m">16</span>:02:22 Starting HTTPCommunicator: <span class="o">[</span>http://localhost:8000/<span class="o">]</span>
INFO:2018/08/08 <span class="m">16</span>:02:22 Sending unsolicited ping.
INFO:2018/08/08 <span class="m">16</span>:02:22 Updated server serial number in config file /etc/velociraptor.writeback.yaml to <span class="m">1</span>
INFO:2018/08/08 <span class="m">16</span>:02:22 Received PEM <span class="k">for</span> VelociraptorServer from http://localhost:8000/
INFO:2018/08/08 <span class="m">16</span>:02:22 Received response with status: <span class="m">406</span> Not Acceptable
INFO:2018/08/08 <span class="m">16</span>:02:22 Enrolling
INFO:2018/08/08 <span class="m">16</span>:02:23 Received response with status: <span class="m">406</span> Not Acceptable
INFO:2018/08/08 <span class="m">16</span>:02:25 Sending unsolicited ping.
INFO:2018/08/08 <span class="m">16</span>:02:25 Received response with status: <span class="m">200</span> OK
INFO:2018/08/08 <span class="m">16</span>:02:25 Checking foreman
INFO:2018/08/08 <span class="m">16</span>:02:26 Received response with status: <span class="m">200</span> OK
INFO:2018/08/08 <span class="m">16</span>:02:27 Sending unsolicited ping.
INFO:2018/08/08 <span class="m">16</span>:02:27 Received response with status: <span class="m">200</span> OK
</pre></div>
</div>
<p>We can see that when a new client starts for the first time it goes
through a number of steps:</p>
<ol class="arabic simple">
<li>The writeback file is created with a new client private key (and a
client ID).</li>
<li>The client communicates with the server but receives a 406
status. This initiates the enrolment flow.</li>
<li>The server schedules an Interrogate flow on the client, which
issues a number of VQL queries.</li>
<li>We can now search for the client using the GUI search box.</li>
</ol>
<img alt="../../../_images/image8.png" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image8.png"/>
</div>
<div class="section" id="id1">
<h3>Introducing Velociraptor</h3>
<p>This post introduces Velociraptor - a new end point monitoring and IR
tool built upon GRR’s groundwork and experience.  To be clear, we
reused some of GRR’s code and some design elements, but Velociraptor
is a new project and is largely a rewrite of GRR’s codebase. Like GRR,
Velociraptor is released under an open source license and is a
community project hosted on <a class="reference external" href="https://gitlab.com/velocidex/velociraptor">https://gitlab.com/velocidex/velociraptor</a>.</p>
<p>It is still very early days and we would love to receive feedback and
suggestions. This is the first technology preview release and we hope
to make a more stable and comprehensive release in the coming
months. As Velociraptor becomes more battle tested we hope the
codebase will stabilize.</p>
<p>The near term roadmap is:</p>
<ul class="simple">
<li>Improve support for more operating systems. Especially Windows:</li>
<li>Registry based VQL plugins.</li>
<li>NTFS support for raw disk access.</li>
<li>Memory scanning and rudimentary Memory analysis</li>
<li>Design a more efficient client/server communication mechanism - long
polling is problematic since clients only poll infrequently
(e.g. every 10 minutes). We want to be able to control all clients
quickly.</li>
<li>Develop a library of VQL expressions which may be reusable. This
should be similar to GRR’s idea of Artifacts but be more geared
towards VQL.</li>
</ul>
<p>Please play with it and send feedback to <a class="reference external" href="mailto:velociraptor-discuss%40googlegroups.com">velociraptor-discuss<span>@</span>googlegroups<span>.</span>com</a></p>
<img alt="../../../_images/image11.png" class="align-center" src="https://docs.velociraptor.velocidex.com/blog/html/_images/image11.png"/>
</div>
</div>
]]></description>
             <pubDate>Fri, 10 Aug 2018 00:00:00 +1000</pubDate>
        </item>
    
    </channel>
</rss>